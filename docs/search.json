[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "A propos",
    "section": "",
    "text": "L‚ÄôInstitut Agro Rennes-Angers est un √©tablissement public d‚Äôenseignement sup√©rieur et de recherche en agronomie, environnement et alimentation. Il forme des ing√©nieurs et chercheurs capables de relever les d√©fis li√©s √† la durabilit√© des syst√®mes agricoles et alimentaires.\nLe Master Math√©matiques Appliqu√©es, Statistique est co-accr√©dit√©e par plusieurs √©tablissements d‚Äôenseignement sup√©rieur rennais, notament l‚ÄôUniversit√© Rennes 2 et l‚Äô√âcole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation (ENSAI).\nAu sein de l‚ÄôInstitut Agro Rennes-Angers, les √©tudiants suivent le parcours Data Science pour la biologie, qui vise √† d√©velopper des comp√©tences avanc√©es en analyse de donn√©es et en mod√©lisation statistique appliqu√©es aux domaines de l‚Äôagriculture, de l‚Äôagroalimentaire, des sciences de l‚Äôenvironnement et de la biologie."
  },
  {
    "objectID": "infos.html",
    "href": "infos.html",
    "title": "Infos pratiques",
    "section": "",
<<<<<<< Updated upstream
    "text": "Horaires :\nvendredi 21 novembre 2025 entre 13h30 et 16h30\n\n\nLieu\nInstitut Agro Rennes 65 Rue de Saint-Brieuc, 35042 Rennes.\nSalle 5√®me ann√©e du B√¢timent 24\n\n\nCode\nlibrary(leaflet)\n\nleaflet() %&gt;%  addTiles() %&gt;%    addMarkers( lat=48.11349, lng=-1.70613, popup=\"Institut Agro Rennes\")\n\n\n\n\n\n\n\n\nD√©tails d‚Äôacc√®s et plan\nAmphi Paul Matagrin (B√¢timent N¬∞5)"
=======
    "text": "Horaires :\nVendredi 21 novembre 2025 entre 13h30 et 16h30.\n\n\nLieu\nSalle 5√®me ann√©e du B√¢timent 24 de l‚ÄôInstitut Agro Rennes-Angers (Campus de Rennes)\n\n\n\n\n\n\n\n\nPlan\n\n\n\nLes acteurs de la conf√©rence\n\nEncadrants p√©dagogiques :\n\n\n\n Mathieu Emily\n\nProfesseur titulaire de statistique et responsable du d√©partement de recherche en statistique.\nLaboratoire : D√©partement statistique, IRMAR (UMR CNRS 6625)\nContact : mathieu.emily@agrocampus-ouest.fr\n\n\n Laetitia Chapel\n\nProfesseure titulaire en Computeur Science et chercheuse.\nLaboratoire : √âquipe OBELIX, IRISA (UMR CNRS 6074)\nContact : laetitia.chapel@agrocampus-ouest.fr\n\n\n\n\n\n√âtudiants participants :\n\nLes √©tudiants de la promotion 2025 du parcours Sciences des Donn√©es sont pr√©sent√©s dans la rubrique √Ä propos du site, avec leurs photos, noms et liens vers GitHub et LinkedIn."
>>>>>>> Stashed changes
  },
  {
    "objectID": "projets/Template_presentation_projets.html",
    "href": "projets/Template_presentation_projets.html",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "",
    "text": "BOULET Faustine Etudiante ing√©nieure Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n BEAUFILS Constance Etudiante ing√©nieure Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n PLACIER Mo√Øse Etudiant ing√©nieur Agronome Institut Agro Rennes & ENSAT GitHub ‚Ä¢ LinkedIn"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#lien-vers-le-code-github",
    "href": "projets/Template_presentation_projets.html#lien-vers-le-code-github",
    "title": "D√©coder la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#lien-vers-les-slides",
    "href": "projets/Template_presentation_projets.html#lien-vers-les-slides",
    "title": "D√©coder la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#description-projet",
    "href": "projets/Template_presentation_projets.html#description-projet",
    "title": "D√©coder la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "description Projet",
    "text": "description Projet\nblablabla\n\n\n BOULET Faustine Etudiante ing√©nieure Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n BEAUFILS Constance Etudiante ing√©nieure Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n PLACIER Mo√Øse Etudiant ing√©nieur Agronome Institut Agro Rennes & ENSAT GitHub ‚Ä¢ LinkedIn"
  },
  {
    "objectID": "projets/Projet_exemple_2.html",
    "href": "projets/Projet_exemple_2.html",
    "title": "cancer prediction",
    "section": "",
    "text": "This project focuses on mapping crop types at the pixel level using multispectral satellite image time series. By leveraging both temporal and spatial information through a hybrid CNN architecture, we aim to accurately classify agricultural parcels across diverse French landscapes. The approach combines 1D convolutions for temporal encoding and a simplified U-Net for spatial segmentation.\n\n\n\n\n\n\nFor ground truth values, we utilize the 2023 Graphical Parcel Register (RPG) as the reference source. This dataset, provided as a shapefile, consists of polygons that precisely delineate agricultural parcels. Each polygon corresponds to an individual field and contains essential information: a unique identifier, its surface area measured in hectares (HA), and the identifier of the predominant crop grown on it during the 2023 cultivation season. The area covered is the entire contry with a total number of 9 797 405 parcels.\n\nonline visualisation\ndownloading link\n\n\n\n\nWe needed to clean the predominant crop identifier from the Registre Parcellaire Graphique (RPG) data. While the RPG encoding is useful for the Common Agricultural Policy (PAC), it isn‚Äôt ideal for our classification task.\nFor instance, the RPG distinguishes between ‚Äúsweet maize‚Äù and ‚Äúmaize‚Äù with separate crop IDs. However, these two share a nearly identical spectral signature, making their separation irrelevant for our classification purposes. This initial RPG classification also results in an excessively large number of classes.\nBy using the classes defined by Turkoglu et al., we leverage an expert-crafted set of more meaningful and spectrally distinct crop categories. This approach effectively addresses the over-granularity of the RPG, merging spectrally similar crops (like sweet maize and maize) into single, relevant categories, and significantly reducing the total number of classes to a practical size for our classification.\nWe also reprojected the CRS of parcel geometries (Lambert 93 : EPSG:2154) to match Sentinel-2‚Äôs projection system (WGS84: reproject each tile to its native UTM zone ), guaranting accurate overlay.\n\n\n\n\nWe rely on Sentinel-2 Level-2A (Surface Reflectance)\nWe leverages 4 spectral bands from Sentinel-2 satellites to perform crop detection. These bands allow us to extract detailed information about vegetation based on light reflectance at specific wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n\nBand\nName\nResolution\nWavelength (S2A / S2B)\nDescription\n\n\n\n\nB2\nBlue\n10 m\n496.6 / 492.1 nm\nChlorophyll detection, cloud cover analysis\n\n\nB3\nGreen\n10 m\n560 / 559 nm\nVegetation contrast, plant health analysis\n\n\nB4\nRed\n10 m\n664.5 / 665 nm\nNDVI calculation, vegetation growth tracking\n\n\nB8\nNIR\n10 m\n835.1 / 833 nm\nBiomass detection, distinguishes soil vs vegetation\n\n\n\n\n\n\nTo effectively manage clouds in our satellite imagery, we leverage the Scene Classification Layer (SCL) provided by Sentinel-2. The SCL is a band within the Sentinel-2 Level-2A product that classifies each pixel based on its content (e.g., cloud, shadow, vegetation, water, snow). We use this layer to mask out all pixels not classified as vegetation, bare soil, or water (SCL classes 4 to 7), ensuring that clouds, cloud shadows, and other atmospheric artifacts are excluded from our analysis.\nFollowing the SCL masking, we compute a pixel-wise median for each month. Since each month provides between 6 and 15 images per band for a given area, the median composite is highly robust. We choose the median over the mean because it is significantly less impacted by outliers that might persist even after SCL masking (e.g., residual cloud edges or noise). This process also reduces the probability of having ‚Äúabsent pixels‚Äù due to clouds in our monthly composites.\nWhile median compositing greatly minimizes cloud-induced gaps, some might still occur. To address these, we implemented a pixel-wise temporal interpolation strategy:\n\nFor a missing pixel value in a given month: The new value is calculated as the mean of the corresponding pixel‚Äôs value from the previous month and the next month.\nFor missing values in the first month of the time series: We use the next available monthly value for that pixel.\nFor missing values in the last month of the time series: We use the last available previous monthly value for that pixel.\n\nAlthough this interpolation involves a nasty function with many for loops, it proves to be quite powerful in generating a complete and continuous time series of satellite imagery.\n\n\n\n\nDue to the extensive size of the covered area in France, we had to reduce the dataset used for modeling. To achieve this, we selected specific zones representing distinct agricultural landscapes, characterized by predominant crops and farming practices influenced by varying pedoclimatic conditions.\nThe following table lists these key agricultural zones across France, alongside nearby towns for geographic reference:\n\n\n\n\n\n\n\n\n\nZone\nRegion\nNearby Town (Map Reference)\nNotes\n\n\n\n\nNord-Picardie\nHauts-de-France\nSaint-Quentin (Aisne)\nSurrounded by large-scale crops (wheat, sugar beet, potatoes)\n\n\nParis Basin\n√éle-de-France / Centre\nChartres (Eure-et-Loir)\nHeart of the Beauce, vast cereal plains\n\n\nBrittany / Pays de la Loire\nBrittany / Vend√©e\nVitr√© (Ille-et-Vilaine)\nMixed zone: livestock, silage maize, hedgerows\n\n\nSouthwest\nNouvelle-Aquitaine\nAuch (Gers)\nCereal polyculture, maize, sunflower\n\n\nSoutheast\nProvence, Rh√¥ne-Alpes\nCarpentras (Vaucluse)\nVineyards, orchards, greenhouse vegetable farming\n\n\nMassif Central\nAuvergne\nRiom (Puy-de-D√¥me)\nLimagne plain: polyculture on volcanic plains\n\n\nAlsace / Lorraine\nGrand Est\nColmar (Haut-Rhin)\nHillside vineyards + lowland crop farming\n\n\nMediterranean\nOccitanie, PACA\nB√©ziers (H√©rault)\nVineyards, olive trees, vegetable crops, dry climate\n\n\n\nWe used ESA WorldCover (10 m resolution, global) to identify highly cultivated areas for sampling. From these representative landscapes, we selected five 10¬†km√ó10¬†km zones around each. This resulted in a total dataset covering 40 zones (8 regions √ó 5 zones each), each spanning 100¬†km^2.\nWe then extracted all parcels from the 2023 RPG that intersect with these zones, totaling 130,000 parcels with an average size of 1.5 HA. And retrieve computed median satellites images of teh studied zones for each month via the google earth engine API.\nDespite this effort to ensure geographical diversity, we still face a highly imbalanced class distribution across crop types ‚Äî some crops are vastly overrepresented while others have very few examples.\nThe figure below illustrates this imbalance (note the logarithmic scale on the y-axis).\nThis skew can significantly affect evaluation metrics: in particular, accuracy may be misleading, as the model can achieve high accuracy by favoring dominant classes. Therefore, we also report macro-averaged metrics (precision, recall, F1-score) that treat all classes equally, regardless of frequency.\n\n\n\nFor each of the eight agricultural regions described above, we selected one 10√ó10 km zone out of the five available to serve as the test dataset. So 20% of the dataset is held out for testing, and that each region is represented in the test set.\nThis allows us to evaluate the model‚Äôs ability to generalize to completely unseen geographic areas across diverse agro-climatic contexts.\nThe remaining 32 zones were used for training and validation. To optimize model performance while managing computational cost, we adopted a 3-fold cross-validation (CV) approach on the training set. A higher number of folds (e.g., K &gt; 3) was avoided due to the long training times associated with deep learning models on large spatial-temporal datasets.\nThis spatially-aware split avoide any data leakage between training and test areas."
  },
  {
    "objectID": "projets/Projet_exemple_2.html#dataset-description",
    "href": "projets/Projet_exemple_2.html#dataset-description",
    "title": "cancer prediction",
    "section": "",
    "text": "For ground truth values, we utilize the 2023 Graphical Parcel Register (RPG) as the reference source. This dataset, provided as a shapefile, consists of polygons that precisely delineate agricultural parcels. Each polygon corresponds to an individual field and contains essential information: a unique identifier, its surface area measured in hectares (HA), and the identifier of the predominant crop grown on it during the 2023 cultivation season. The area covered is the entire contry with a total number of 9 797 405 parcels.\n\nonline visualisation\ndownloading link\n\n\n\n\nWe needed to clean the predominant crop identifier from the Registre Parcellaire Graphique (RPG) data. While the RPG encoding is useful for the Common Agricultural Policy (PAC), it isn‚Äôt ideal for our classification task.\nFor instance, the RPG distinguishes between ‚Äúsweet maize‚Äù and ‚Äúmaize‚Äù with separate crop IDs. However, these two share a nearly identical spectral signature, making their separation irrelevant for our classification purposes. This initial RPG classification also results in an excessively large number of classes.\nBy using the classes defined by Turkoglu et al., we leverage an expert-crafted set of more meaningful and spectrally distinct crop categories. This approach effectively addresses the over-granularity of the RPG, merging spectrally similar crops (like sweet maize and maize) into single, relevant categories, and significantly reducing the total number of classes to a practical size for our classification.\nWe also reprojected the CRS of parcel geometries (Lambert 93 : EPSG:2154) to match Sentinel-2‚Äôs projection system (WGS84: reproject each tile to its native UTM zone ), guaranting accurate overlay.\n\n\n\n\nWe rely on Sentinel-2 Level-2A (Surface Reflectance)\nWe leverages 4 spectral bands from Sentinel-2 satellites to perform crop detection. These bands allow us to extract detailed information about vegetation based on light reflectance at specific wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n\nBand\nName\nResolution\nWavelength (S2A / S2B)\nDescription\n\n\n\n\nB2\nBlue\n10 m\n496.6 / 492.1 nm\nChlorophyll detection, cloud cover analysis\n\n\nB3\nGreen\n10 m\n560 / 559 nm\nVegetation contrast, plant health analysis\n\n\nB4\nRed\n10 m\n664.5 / 665 nm\nNDVI calculation, vegetation growth tracking\n\n\nB8\nNIR\n10 m\n835.1 / 833 nm\nBiomass detection, distinguishes soil vs vegetation\n\n\n\n\n\n\nTo effectively manage clouds in our satellite imagery, we leverage the Scene Classification Layer (SCL) provided by Sentinel-2. The SCL is a band within the Sentinel-2 Level-2A product that classifies each pixel based on its content (e.g., cloud, shadow, vegetation, water, snow). We use this layer to mask out all pixels not classified as vegetation, bare soil, or water (SCL classes 4 to 7), ensuring that clouds, cloud shadows, and other atmospheric artifacts are excluded from our analysis.\nFollowing the SCL masking, we compute a pixel-wise median for each month. Since each month provides between 6 and 15 images per band for a given area, the median composite is highly robust. We choose the median over the mean because it is significantly less impacted by outliers that might persist even after SCL masking (e.g., residual cloud edges or noise). This process also reduces the probability of having ‚Äúabsent pixels‚Äù due to clouds in our monthly composites.\nWhile median compositing greatly minimizes cloud-induced gaps, some might still occur. To address these, we implemented a pixel-wise temporal interpolation strategy:\n\nFor a missing pixel value in a given month: The new value is calculated as the mean of the corresponding pixel‚Äôs value from the previous month and the next month.\nFor missing values in the first month of the time series: We use the next available monthly value for that pixel.\nFor missing values in the last month of the time series: We use the last available previous monthly value for that pixel.\n\nAlthough this interpolation involves a nasty function with many for loops, it proves to be quite powerful in generating a complete and continuous time series of satellite imagery.\n\n\n\n\nDue to the extensive size of the covered area in France, we had to reduce the dataset used for modeling. To achieve this, we selected specific zones representing distinct agricultural landscapes, characterized by predominant crops and farming practices influenced by varying pedoclimatic conditions.\nThe following table lists these key agricultural zones across France, alongside nearby towns for geographic reference:\n\n\n\n\n\n\n\n\n\nZone\nRegion\nNearby Town (Map Reference)\nNotes\n\n\n\n\nNord-Picardie\nHauts-de-France\nSaint-Quentin (Aisne)\nSurrounded by large-scale crops (wheat, sugar beet, potatoes)\n\n\nParis Basin\n√éle-de-France / Centre\nChartres (Eure-et-Loir)\nHeart of the Beauce, vast cereal plains\n\n\nBrittany / Pays de la Loire\nBrittany / Vend√©e\nVitr√© (Ille-et-Vilaine)\nMixed zone: livestock, silage maize, hedgerows\n\n\nSouthwest\nNouvelle-Aquitaine\nAuch (Gers)\nCereal polyculture, maize, sunflower\n\n\nSoutheast\nProvence, Rh√¥ne-Alpes\nCarpentras (Vaucluse)\nVineyards, orchards, greenhouse vegetable farming\n\n\nMassif Central\nAuvergne\nRiom (Puy-de-D√¥me)\nLimagne plain: polyculture on volcanic plains\n\n\nAlsace / Lorraine\nGrand Est\nColmar (Haut-Rhin)\nHillside vineyards + lowland crop farming\n\n\nMediterranean\nOccitanie, PACA\nB√©ziers (H√©rault)\nVineyards, olive trees, vegetable crops, dry climate\n\n\n\nWe used ESA WorldCover (10 m resolution, global) to identify highly cultivated areas for sampling. From these representative landscapes, we selected five 10¬†km√ó10¬†km zones around each. This resulted in a total dataset covering 40 zones (8 regions √ó 5 zones each), each spanning 100¬†km^2.\nWe then extracted all parcels from the 2023 RPG that intersect with these zones, totaling 130,000 parcels with an average size of 1.5 HA. And retrieve computed median satellites images of teh studied zones for each month via the google earth engine API.\nDespite this effort to ensure geographical diversity, we still face a highly imbalanced class distribution across crop types ‚Äî some crops are vastly overrepresented while others have very few examples.\nThe figure below illustrates this imbalance (note the logarithmic scale on the y-axis).\nThis skew can significantly affect evaluation metrics: in particular, accuracy may be misleading, as the model can achieve high accuracy by favoring dominant classes. Therefore, we also report macro-averaged metrics (precision, recall, F1-score) that treat all classes equally, regardless of frequency.\n\n\n\nFor each of the eight agricultural regions described above, we selected one 10√ó10 km zone out of the five available to serve as the test dataset. So 20% of the dataset is held out for testing, and that each region is represented in the test set.\nThis allows us to evaluate the model‚Äôs ability to generalize to completely unseen geographic areas across diverse agro-climatic contexts.\nThe remaining 32 zones were used for training and validation. To optimize model performance while managing computational cost, we adopted a 3-fold cross-validation (CV) approach on the training set. A higher number of folds (e.g., K &gt; 3) was avoided due to the long training times associated with deep learning models on large spatial-temporal datasets.\nThis spatially-aware split avoide any data leakage between training and test areas."
  },
  {
    "objectID": "projets/Projet_exemple_2.html#deep-learning-approach",
    "href": "projets/Projet_exemple_2.html#deep-learning-approach",
    "title": "cancer prediction",
    "section": "Deep Learning approach :",
    "text": "Deep Learning approach :\nOur model classifies each pixel of a multispectral time-series image into crop types by combining temporal and spatial feature extraction in a hybrid CNN architecture.\nInput: X ‚àà ‚Ñù1 ‚Äî a batch of multispectral sequences with 4 channels (e.g., Red, Green, Blue, NIR), T time steps, and spatial dimensions H√óW.\n\nStep 1: Temporal Encoding (Pixel-wise)\nReshape input to [B √ó H √ó W, C, T]. Apply a 1D CNN independently on each pixel‚Äôs temporal sequence. This captures temporal patterns per pixel across spectral bands and outputs D-dimensional embeddings.\n\n\nStep 2: Reshape to Spatial Grid\nReshape back to [B, D, H, W], forming a pseudo-image from the temporal embeddings.\n\n\nStep 3: Spatial Encoding (Image-wise)\nPass through a 2D CNN backbone (a simplified U-Net). This captures spatial context and relationships between neighboring pixels.\n\n\nStep 4: Classification\nThe final output is per-pixel class logits with shape [B, num_classes, H, W].\n\n\nResults :\nGlobal Accuracy = The ratio of correctly classified pixels over the total number of pixels\nPrecision, Recall, and F1-score (Macro) = averages across all classes (i.e., unweighted mean over classes):\n\n\n\nMetric\nScore\n\n\n\n\nAverage Loss\n0.5222\n\n\nGlobal Accuracy\n0.8721\n\n\nMacro Precision\n0.4099\n\n\nMacro Recall\n0.3544\n\n\nMacro F1-score\n0.3516"
  },
  {
    "objectID": "projets/Projet_exemple_2.html#xgboost-approach-pixel-wise-classification",
    "href": "projets/Projet_exemple_2.html#xgboost-approach-pixel-wise-classification",
    "title": "cancer prediction",
    "section": "XGBoost approach (Pixel-wise Classification)",
    "text": "XGBoost approach (Pixel-wise Classification)\nIn addition to the deep learning model, we implemented a classical machine learning pipeline using XGBoost to classify pixels individually based on their temporal and spectral profiles.\nWe use a flattened pixel-wise data. Each input vector represents the spectral evolution of a pixel over time.\n\nResults :\n\n\n\nMetric\nScore\n\n\n\n\nAverage Loss\n0.7358\n\n\nGlobal Accuracy\n0.8045\n\n\nMacro Precision\n0.3543\n\n\nMacro Recall\n0.2303\n\n\nMacro F1-score\n0.2524"
  },
  {
    "objectID": "projets/Projet_exemple_2.html#biblio",
    "href": "projets/Projet_exemple_2.html#biblio",
    "title": "cancer prediction",
    "section": "biblio",
    "text": "biblio\nMehmet Ozgur Turkoglu, Stefano D‚ÄôAronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler, Jan Dirk Wegner, Crop mapping from image time series: Deep learning with multi-scale label hierarchies, Remote Sensing of Environment, Volume 264,2021,112603,ISSN 0034-4257, DOI GitHub"
  },
  {
    "objectID": "projets/Projet_exemple_2.html#authors",
    "href": "projets/Projet_exemple_2.html#authors",
    "title": "cancer prediction",
    "section": "Authors",
    "text": "Authors\nGiovanni Setaro - Github\nNo√© Coursimaux - Github\nMo√Øse Placier - Github"
  },
  {
    "objectID": "projets/Projet_exemple_2.html#footnotes",
    "href": "projets/Projet_exemple_2.html#footnotes",
    "title": "cancer prediction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nB, C=4, T, H, W‚Ü©Ô∏é"
  },
  {
    "objectID": "projets/Projet_exemple.html",
    "href": "projets/Projet_exemple.html",
    "title": "Crop Type Classification",
    "section": "",
    "text": "This project focuses on mapping crop types at the pixel level using multispectral satellite image time series. By leveraging both temporal and spatial information through a hybrid CNN architecture, we aim to accurately classify agricultural parcels across diverse French landscapes. The approach combines 1D convolutions for temporal encoding and a simplified U-Net for spatial segmentation.\n\n\n\n\n\n\nFor ground truth values, we utilize the 2023 Graphical Parcel Register (RPG) as the reference source. This dataset, provided as a shapefile, consists of polygons that precisely delineate agricultural parcels. Each polygon corresponds to an individual field and contains essential information: a unique identifier, its surface area measured in hectares (HA), and the identifier of the predominant crop grown on it during the 2023 cultivation season. The area covered is the entire contry with a total number of 9 797 405 parcels.\n\nonline visualisation\ndownloading link\n\n\n\n\nWe needed to clean the predominant crop identifier from the Registre Parcellaire Graphique (RPG) data. While the RPG encoding is useful for the Common Agricultural Policy (PAC), it isn‚Äôt ideal for our classification task.\nFor instance, the RPG distinguishes between ‚Äúsweet maize‚Äù and ‚Äúmaize‚Äù with separate crop IDs. However, these two share a nearly identical spectral signature, making their separation irrelevant for our classification purposes. This initial RPG classification also results in an excessively large number of classes.\nBy using the classes defined by Turkoglu et al., we leverage an expert-crafted set of more meaningful and spectrally distinct crop categories. This approach effectively addresses the over-granularity of the RPG, merging spectrally similar crops (like sweet maize and maize) into single, relevant categories, and significantly reducing the total number of classes to a practical size for our classification.\nWe also reprojected the CRS of parcel geometries (Lambert 93 : EPSG:2154) to match Sentinel-2‚Äôs projection system (WGS84: reproject each tile to its native UTM zone ), guaranting accurate overlay.\n\n\n\n\nWe rely on Sentinel-2 Level-2A (Surface Reflectance)\nWe leverages 4 spectral bands from Sentinel-2 satellites to perform crop detection. These bands allow us to extract detailed information about vegetation based on light reflectance at specific wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n\nBand\nName\nResolution\nWavelength (S2A / S2B)\nDescription\n\n\n\n\nB2\nBlue\n10 m\n496.6 / 492.1 nm\nChlorophyll detection, cloud cover analysis\n\n\nB3\nGreen\n10 m\n560 / 559 nm\nVegetation contrast, plant health analysis\n\n\nB4\nRed\n10 m\n664.5 / 665 nm\nNDVI calculation, vegetation growth tracking\n\n\nB8\nNIR\n10 m\n835.1 / 833 nm\nBiomass detection, distinguishes soil vs vegetation\n\n\n\n\n\n\nTo effectively manage clouds in our satellite imagery, we leverage the Scene Classification Layer (SCL) provided by Sentinel-2. The SCL is a band within the Sentinel-2 Level-2A product that classifies each pixel based on its content (e.g., cloud, shadow, vegetation, water, snow). We use this layer to mask out all pixels not classified as vegetation, bare soil, or water (SCL classes 4 to 7), ensuring that clouds, cloud shadows, and other atmospheric artifacts are excluded from our analysis.\nFollowing the SCL masking, we compute a pixel-wise median for each month. Since each month provides between 6 and 15 images per band for a given area, the median composite is highly robust. We choose the median over the mean because it is significantly less impacted by outliers that might persist even after SCL masking (e.g., residual cloud edges or noise). This process also reduces the probability of having ‚Äúabsent pixels‚Äù due to clouds in our monthly composites.\nWhile median compositing greatly minimizes cloud-induced gaps, some might still occur. To address these, we implemented a pixel-wise temporal interpolation strategy:\n\nFor a missing pixel value in a given month: The new value is calculated as the mean of the corresponding pixel‚Äôs value from the previous month and the next month.\nFor missing values in the first month of the time series: We use the next available monthly value for that pixel.\nFor missing values in the last month of the time series: We use the last available previous monthly value for that pixel.\n\nAlthough this interpolation involves a nasty function with many for loops, it proves to be quite powerful in generating a complete and continuous time series of satellite imagery.\n\n\n\n\nDue to the extensive size of the covered area in France, we had to reduce the dataset used for modeling. To achieve this, we selected specific zones representing distinct agricultural landscapes, characterized by predominant crops and farming practices influenced by varying pedoclimatic conditions.\nThe following table lists these key agricultural zones across France, alongside nearby towns for geographic reference:\n\n\n\n\n\n\n\n\n\nZone\nRegion\nNearby Town (Map Reference)\nNotes\n\n\n\n\nNord-Picardie\nHauts-de-France\nSaint-Quentin (Aisne)\nSurrounded by large-scale crops (wheat, sugar beet, potatoes)\n\n\nParis Basin\n√éle-de-France / Centre\nChartres (Eure-et-Loir)\nHeart of the Beauce, vast cereal plains\n\n\nBrittany / Pays de la Loire\nBrittany / Vend√©e\nVitr√© (Ille-et-Vilaine)\nMixed zone: livestock, silage maize, hedgerows\n\n\nSouthwest\nNouvelle-Aquitaine\nAuch (Gers)\nCereal polyculture, maize, sunflower\n\n\nSoutheast\nProvence, Rh√¥ne-Alpes\nCarpentras (Vaucluse)\nVineyards, orchards, greenhouse vegetable farming\n\n\nMassif Central\nAuvergne\nRiom (Puy-de-D√¥me)\nLimagne plain: polyculture on volcanic plains\n\n\nAlsace / Lorraine\nGrand Est\nColmar (Haut-Rhin)\nHillside vineyards + lowland crop farming\n\n\nMediterranean\nOccitanie, PACA\nB√©ziers (H√©rault)\nVineyards, olive trees, vegetable crops, dry climate\n\n\n\nWe used ESA WorldCover (10 m resolution, global) to identify highly cultivated areas for sampling. From these representative landscapes, we selected five 10¬†km√ó10¬†km zones around each. This resulted in a total dataset covering 40 zones (8 regions √ó 5 zones each), each spanning 100¬†km^2.\nWe then extracted all parcels from the 2023 RPG that intersect with these zones, totaling 130,000 parcels with an average size of 1.5 HA. And retrieve computed median satellites images of teh studied zones for each month via the google earth engine API.\nDespite this effort to ensure geographical diversity, we still face a highly imbalanced class distribution across crop types ‚Äî some crops are vastly overrepresented while others have very few examples.\nThe figure below illustrates this imbalance (note the logarithmic scale on the y-axis).\nThis skew can significantly affect evaluation metrics: in particular, accuracy may be misleading, as the model can achieve high accuracy by favoring dominant classes. Therefore, we also report macro-averaged metrics (precision, recall, F1-score) that treat all classes equally, regardless of frequency.\n\n\n\nFor each of the eight agricultural regions described above, we selected one 10√ó10 km zone out of the five available to serve as the test dataset. So 20% of the dataset is held out for testing, and that each region is represented in the test set.\nThis allows us to evaluate the model‚Äôs ability to generalize to completely unseen geographic areas across diverse agro-climatic contexts.\nThe remaining 32 zones were used for training and validation. To optimize model performance while managing computational cost, we adopted a 3-fold cross-validation (CV) approach on the training set. A higher number of folds (e.g., K &gt; 3) was avoided due to the long training times associated with deep learning models on large spatial-temporal datasets.\nThis spatially-aware split avoide any data leakage between training and test areas."
  },
  {
    "objectID": "projets/Projet_exemple.html#dataset-description",
    "href": "projets/Projet_exemple.html#dataset-description",
    "title": "Crop Type Classification",
    "section": "",
    "text": "For ground truth values, we utilize the 2023 Graphical Parcel Register (RPG) as the reference source. This dataset, provided as a shapefile, consists of polygons that precisely delineate agricultural parcels. Each polygon corresponds to an individual field and contains essential information: a unique identifier, its surface area measured in hectares (HA), and the identifier of the predominant crop grown on it during the 2023 cultivation season. The area covered is the entire contry with a total number of 9 797 405 parcels.\n\nonline visualisation\ndownloading link\n\n\n\n\nWe needed to clean the predominant crop identifier from the Registre Parcellaire Graphique (RPG) data. While the RPG encoding is useful for the Common Agricultural Policy (PAC), it isn‚Äôt ideal for our classification task.\nFor instance, the RPG distinguishes between ‚Äúsweet maize‚Äù and ‚Äúmaize‚Äù with separate crop IDs. However, these two share a nearly identical spectral signature, making their separation irrelevant for our classification purposes. This initial RPG classification also results in an excessively large number of classes.\nBy using the classes defined by Turkoglu et al., we leverage an expert-crafted set of more meaningful and spectrally distinct crop categories. This approach effectively addresses the over-granularity of the RPG, merging spectrally similar crops (like sweet maize and maize) into single, relevant categories, and significantly reducing the total number of classes to a practical size for our classification.\nWe also reprojected the CRS of parcel geometries (Lambert 93 : EPSG:2154) to match Sentinel-2‚Äôs projection system (WGS84: reproject each tile to its native UTM zone ), guaranting accurate overlay.\n\n\n\n\nWe rely on Sentinel-2 Level-2A (Surface Reflectance)\nWe leverages 4 spectral bands from Sentinel-2 satellites to perform crop detection. These bands allow us to extract detailed information about vegetation based on light reflectance at specific wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n\nBand\nName\nResolution\nWavelength (S2A / S2B)\nDescription\n\n\n\n\nB2\nBlue\n10 m\n496.6 / 492.1 nm\nChlorophyll detection, cloud cover analysis\n\n\nB3\nGreen\n10 m\n560 / 559 nm\nVegetation contrast, plant health analysis\n\n\nB4\nRed\n10 m\n664.5 / 665 nm\nNDVI calculation, vegetation growth tracking\n\n\nB8\nNIR\n10 m\n835.1 / 833 nm\nBiomass detection, distinguishes soil vs vegetation\n\n\n\n\n\n\nTo effectively manage clouds in our satellite imagery, we leverage the Scene Classification Layer (SCL) provided by Sentinel-2. The SCL is a band within the Sentinel-2 Level-2A product that classifies each pixel based on its content (e.g., cloud, shadow, vegetation, water, snow). We use this layer to mask out all pixels not classified as vegetation, bare soil, or water (SCL classes 4 to 7), ensuring that clouds, cloud shadows, and other atmospheric artifacts are excluded from our analysis.\nFollowing the SCL masking, we compute a pixel-wise median for each month. Since each month provides between 6 and 15 images per band for a given area, the median composite is highly robust. We choose the median over the mean because it is significantly less impacted by outliers that might persist even after SCL masking (e.g., residual cloud edges or noise). This process also reduces the probability of having ‚Äúabsent pixels‚Äù due to clouds in our monthly composites.\nWhile median compositing greatly minimizes cloud-induced gaps, some might still occur. To address these, we implemented a pixel-wise temporal interpolation strategy:\n\nFor a missing pixel value in a given month: The new value is calculated as the mean of the corresponding pixel‚Äôs value from the previous month and the next month.\nFor missing values in the first month of the time series: We use the next available monthly value for that pixel.\nFor missing values in the last month of the time series: We use the last available previous monthly value for that pixel.\n\nAlthough this interpolation involves a nasty function with many for loops, it proves to be quite powerful in generating a complete and continuous time series of satellite imagery.\n\n\n\n\nDue to the extensive size of the covered area in France, we had to reduce the dataset used for modeling. To achieve this, we selected specific zones representing distinct agricultural landscapes, characterized by predominant crops and farming practices influenced by varying pedoclimatic conditions.\nThe following table lists these key agricultural zones across France, alongside nearby towns for geographic reference:\n\n\n\n\n\n\n\n\n\nZone\nRegion\nNearby Town (Map Reference)\nNotes\n\n\n\n\nNord-Picardie\nHauts-de-France\nSaint-Quentin (Aisne)\nSurrounded by large-scale crops (wheat, sugar beet, potatoes)\n\n\nParis Basin\n√éle-de-France / Centre\nChartres (Eure-et-Loir)\nHeart of the Beauce, vast cereal plains\n\n\nBrittany / Pays de la Loire\nBrittany / Vend√©e\nVitr√© (Ille-et-Vilaine)\nMixed zone: livestock, silage maize, hedgerows\n\n\nSouthwest\nNouvelle-Aquitaine\nAuch (Gers)\nCereal polyculture, maize, sunflower\n\n\nSoutheast\nProvence, Rh√¥ne-Alpes\nCarpentras (Vaucluse)\nVineyards, orchards, greenhouse vegetable farming\n\n\nMassif Central\nAuvergne\nRiom (Puy-de-D√¥me)\nLimagne plain: polyculture on volcanic plains\n\n\nAlsace / Lorraine\nGrand Est\nColmar (Haut-Rhin)\nHillside vineyards + lowland crop farming\n\n\nMediterranean\nOccitanie, PACA\nB√©ziers (H√©rault)\nVineyards, olive trees, vegetable crops, dry climate\n\n\n\nWe used ESA WorldCover (10 m resolution, global) to identify highly cultivated areas for sampling. From these representative landscapes, we selected five 10¬†km√ó10¬†km zones around each. This resulted in a total dataset covering 40 zones (8 regions √ó 5 zones each), each spanning 100¬†km^2.\nWe then extracted all parcels from the 2023 RPG that intersect with these zones, totaling 130,000 parcels with an average size of 1.5 HA. And retrieve computed median satellites images of teh studied zones for each month via the google earth engine API.\nDespite this effort to ensure geographical diversity, we still face a highly imbalanced class distribution across crop types ‚Äî some crops are vastly overrepresented while others have very few examples.\nThe figure below illustrates this imbalance (note the logarithmic scale on the y-axis).\nThis skew can significantly affect evaluation metrics: in particular, accuracy may be misleading, as the model can achieve high accuracy by favoring dominant classes. Therefore, we also report macro-averaged metrics (precision, recall, F1-score) that treat all classes equally, regardless of frequency.\n\n\n\nFor each of the eight agricultural regions described above, we selected one 10√ó10 km zone out of the five available to serve as the test dataset. So 20% of the dataset is held out for testing, and that each region is represented in the test set.\nThis allows us to evaluate the model‚Äôs ability to generalize to completely unseen geographic areas across diverse agro-climatic contexts.\nThe remaining 32 zones were used for training and validation. To optimize model performance while managing computational cost, we adopted a 3-fold cross-validation (CV) approach on the training set. A higher number of folds (e.g., K &gt; 3) was avoided due to the long training times associated with deep learning models on large spatial-temporal datasets.\nThis spatially-aware split avoide any data leakage between training and test areas."
  },
  {
    "objectID": "projets/Projet_exemple.html#deep-learning-approach",
    "href": "projets/Projet_exemple.html#deep-learning-approach",
    "title": "Crop Type Classification",
    "section": "Deep Learning approach :",
    "text": "Deep Learning approach :\nOur model classifies each pixel of a multispectral time-series image into crop types by combining temporal and spatial feature extraction in a hybrid CNN architecture.\nInput: X ‚àà ‚Ñù1 ‚Äî a batch of multispectral sequences with 4 channels (e.g., Red, Green, Blue, NIR), T time steps, and spatial dimensions H√óW.\n\nStep 1: Temporal Encoding (Pixel-wise)\nReshape input to [B √ó H √ó W, C, T]. Apply a 1D CNN independently on each pixel‚Äôs temporal sequence. This captures temporal patterns per pixel across spectral bands and outputs D-dimensional embeddings.\n\n\nStep 2: Reshape to Spatial Grid\nReshape back to [B, D, H, W], forming a pseudo-image from the temporal embeddings.\n\n\nStep 3: Spatial Encoding (Image-wise)\nPass through a 2D CNN backbone (a simplified U-Net). This captures spatial context and relationships between neighboring pixels.\n\n\nStep 4: Classification\nThe final output is per-pixel class logits with shape [B, num_classes, H, W].\n\n\nResults :\nGlobal Accuracy = The ratio of correctly classified pixels over the total number of pixels\nPrecision, Recall, and F1-score (Macro) = averages across all classes (i.e., unweighted mean over classes):\n\n\n\nMetric\nScore\n\n\n\n\nAverage Loss\n0.5222\n\n\nGlobal Accuracy\n0.8721\n\n\nMacro Precision\n0.4099\n\n\nMacro Recall\n0.3544\n\n\nMacro F1-score\n0.3516"
  },
  {
    "objectID": "projets/Projet_exemple.html#xgboost-approach-pixel-wise-classification",
    "href": "projets/Projet_exemple.html#xgboost-approach-pixel-wise-classification",
    "title": "Crop Type Classification",
    "section": "XGBoost approach (Pixel-wise Classification)",
    "text": "XGBoost approach (Pixel-wise Classification)\nIn addition to the deep learning model, we implemented a classical machine learning pipeline using XGBoost to classify pixels individually based on their temporal and spectral profiles.\nWe use a flattened pixel-wise data. Each input vector represents the spectral evolution of a pixel over time.\n\nResults :\n\n\n\nMetric\nScore\n\n\n\n\nAverage Loss\n0.7358\n\n\nGlobal Accuracy\n0.8045\n\n\nMacro Precision\n0.3543\n\n\nMacro Recall\n0.2303\n\n\nMacro F1-score\n0.2524"
  },
  {
    "objectID": "projets/Projet_exemple.html#biblio",
    "href": "projets/Projet_exemple.html#biblio",
    "title": "Crop Type Classification",
    "section": "biblio",
    "text": "biblio\nMehmet Ozgur Turkoglu, Stefano D‚ÄôAronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler, Jan Dirk Wegner, Crop mapping from image time series: Deep learning with multi-scale label hierarchies, Remote Sensing of Environment, Volume 264,2021,112603,ISSN 0034-4257, DOI GitHub"
  },
  {
    "objectID": "projets/Projet_exemple.html#authors",
    "href": "projets/Projet_exemple.html#authors",
    "title": "Crop Type Classification",
    "section": "Authors",
    "text": "Authors\nGiovanni Setaro - Github\nNo√© Coursimaux - Github\nMo√Øse Placier - Github"
  },
  {
    "objectID": "projets/Projet_exemple.html#footnotes",
    "href": "projets/Projet_exemple.html#footnotes",
    "title": "Crop Type Classification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nB, C=4, T, H, W‚Ü©Ô∏é"
  },
  {
    "objectID": "programme.html",
    "href": "programme.html",
    "title": "Programme",
    "section": "",
<<<<<<< HEAD
    "text": "Order By\n       Default\n         \n          Description\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nCrop Type Classification\n\n\n9h30 - 10h\n\n\nMapping crop types at the pixel level using multispectral satellite image time series with a hybrid CNN + U-Net approach.\n\n\n\n\n\nNov 9, 2025\n\n\nPlacier Mo√Øse, Dupont Claire\n\n\n\n\n\n\n\n\n\n\n\n\nTitre du projet\n\n\nheure - passage\n\n\npetite description\n\n\n\n\n\nNov 21, 2025\n\n\nNom Prenom\n\n\n\n\n\n\n\n\n\n\n\n\ncancer prediction\n\n\n10h - 10h30\n\n\nPrediction of cancer via deep learning and computer vision\n\n\n\n\n\nNov 9, 2025\n\n\nCamille haar, Dupont Claire\n\n\n\n\n\n\nNo matching items"
=======
    "text": "You can review the following documents for additional information:\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Description\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nCrop Type Classification\n\n\n9h30 - 10h\n\n\nMapping crop types at the pixel level using multispectral satellite image time series with a hybrid CNN + U-Net approach.\n\n\n\n\n\n\nNov 9, 2025\n\n\nPlacier Mo√Øse, Dupont Claire\n\n\n\n\n\n\n  \n\n\n\n\nPr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es\n\n\nheure - passage\n\n\nPr√©diction de la structure secondaire √† partir de la s√©quence, en √©valuant l‚Äôimpact de diff√©rents descripteurs biologiques et des m√©thodes Random Forest, CNN et mod√®les de NLP sp√©cialis√©s du type BERT.\n\n\n\n\n\n\nNov 21, 2025\n\n\nBOULET Faustine, BEAUFILS Constance, PLACIER Mo√Øse\n\n\n\n\n\n\n  \n\n\n\n\nTitre du projet\n\n\nheure - passage\n\n\npetite description\n\n\n\n\n\n\nNov 21, 2025\n\n\nNom Prenom, Nom Prenom, Nom Prenom\n\n\n\n\n\n\n  \n\n\n\n\ncancer prediction\n\n\n10h - 10h30\n\n\nPrediction of cancer via deep learning and computer vision\n\n\n\n\n\n\nNov 9, 2025\n\n\nCamille haar, Dupont Claire\n\n\n\n\n\n\nNo matching items"
>>>>>>> 97db57e (presentation projet Mo√Øse)
  },
  {
    "objectID": "index.html#pr√©sentation",
    "href": "index.html#pr√©sentation",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Pr√©sentation",
    "text": "Pr√©sentation\nOrganis√©e enti√®rement par les √©tudiants de master 2 - sp√©cialisation Sciences des Donn√©es, cette conf√©rence annuelle est un rendez-vous incontournable !\nElle s‚Äôinscrit dans le cadre de l‚Äô√©valuation des modules Machine Learning et Computer Science for Big Data Approaches. C‚Äôest l‚Äôoccasion de mettre √† l‚Äôhonneur les projets des √©tudiants et de d√©couvrir des m√©thodes modernes de Machine Learning et de Deep Learning appliqu√©es aux probl√©matiques des sciences du vivant."
  },
  {
    "objectID": "index.html#th√®me-2025-machine-learning-pour-la-science-du-vivant",
    "href": "index.html#th√®me-2025-machine-learning-pour-la-science-du-vivant",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Th√®me 2025 ‚Äì Machine Learning pour la Science du Vivant",
    "text": "Th√®me 2025 ‚Äì Machine Learning pour la Science du Vivant\nPour cette 3·µâ √©dition,l‚Äô√©cole explore les apports du Machine Learning √† la compr√©hension, la mod√©lisation et la pr√©diction dans le champ du vivant : agriculture, environnement, √©cologie, sant√© ou biotechnologies.\nLes √©tudiants pr√©senteront des projets originaux illustrant la diversit√© des approches possibles et l‚Äôimpact concret de telles applications."
  },
  {
    "objectID": "index.html#organisation",
    "href": "index.html#organisation",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Organisation",
    "text": "Organisation\n\nEncadrants p√©dagogiques :\n\n\n\n Mathieu Emily\n\nProfesseur titulaire de statistique et responsable du d√©partement de recherche en statistique.\nLaboratoire : D√©partement statistique, IRMAR (UMR CNRS 6625)\nContact : mathieu.emily@agrocampus-ouest.fr\n\n\n Laetitia Chapel\n\nProfesseure titulaire en Computeur Science et chercheuse.\nLaboratoire : √âquipe OBELIX, IRISA (UMR CNRS 6074)\nContact : laetitia.chapel@agrocampus-ouest.fr\n\n\n\n \n√âtudiants participants\nLa promotion 2025 du parcours Sciences des Donn√©es √† l‚ÄôInstitut Agro Rennes est pr√©sent√©e dans la rubrique √Ä propos du site, avec leurs photos, noms et liens vers GitHub et LinkedIn."
  },
  {
    "objectID": "index.html#programme-de-la-journ√©e",
    "href": "index.html#programme-de-la-journ√©e",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Programme de la journ√©e",
    "text": "Programme de la journ√©e\nLe programme complet, incluant les horaires et les productions de chaque groupe, est consultable dans la rubrique Programme.\nTous les travaux des √©tudiants sont centralis√©s dans un d√©p√¥t GitHub. Chaque projet comprend le code, un document de synth√®se et les diapositives de pr√©sentation, permettant de consulter, reproduire et approfondir les travaux pr√©sent√©s durant cette √©dition de l‚Äô√©cole d‚Äôautomne."
  },
  {
    "objectID": "index.html#informations-pratiques",
    "href": "index.html#informations-pratiques",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "üìç Informations pratiques",
    "text": "üìç Informations pratiques\nD√©tails d‚Äôacc√®s et plan disponibles dans la page Infos pratiques.\nLieu : Institut Agro Rennes, Amphi Matagrin\nHoraires : 9h00 ‚Äì 17h30."
  },
  {
    "objectID": "about.html#intervenants-2025",
    "href": "about.html#intervenants-2025",
    "title": "A propos",
    "section": "Intervenants 2025",
    "text": "Intervenants 2025\nLes √©tudiants de la sp√©cialisation Sciences des Donn√©es Biologiques pr√©sentent leurs travaux dans le cadre de la conf√©rence Machine Learning pour la Science du Vivant.\n\n\n Dupont Alice Etudiant ing√©nieur Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n\nMartin Hugo\nUniversit√© Rennes 2\nInstitut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Placier Mo√Øse Etudiant ing√©nieur Agronome - ENSAT Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Durand Emma Etudiant ing√©nieur Agroalimentaire Institut Agro Rennes GitHub ‚Ä¢ LinkedIn\n\n\n Placier Mo√Øse Etudiant ing√©nieur Agronome - ENSAT Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Durand Emma Etudiant ing√©nieur Agroalimentaire Institut Agro Rennes GitHub ‚Ä¢ LinkedIn"
  },
  {
    "objectID": "about.html#professeurs",
    "href": "about.html#professeurs",
    "title": "A propos",
    "section": "Professeurs",
    "text": "Professeurs\nResponsable de la sp√©cialisation : S√©bastien L√™ ‚Äî sebastien.le@institut-agro.fr\nResponsable du master : David Causeur ‚Äî david.causeur@institut-agro.fr"
  },
  {
    "objectID": "about.html#responsables-p√©agogiques",
    "href": "about.html#responsables-p√©agogiques",
    "title": "A propos",
    "section": "Responsables p√©agogiques :",
    "text": "Responsables p√©agogiques :\nResponsable de la sp√©cialisation : S√©bastien L√™ ‚Äî sebastien.le@institut-agro.fr\nResponsable du master : David Causeur ‚Äî david.causeur@institut-agro.fr"
  },
  {
    "objectID": "about.html#promo-2025",
    "href": "about.html#promo-2025",
    "title": "A propos",
    "section": "Promo 2025",
    "text": "Promo 2025\nLes √©tudiants de la sp√©cialisation Sciences des Donn√©es Biologiques pr√©sentent leurs travaux dans le cadre de la conf√©rence Machine Learning pour la Science du Vivant.\n\n\n Dupont Alice Etudiant ing√©nieur Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n\nMartin Hugo\nUniversit√© Rennes 2\nInstitut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Placier Mo√Øse Etudiant ing√©nieur Agronome - ENSAT Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Durand Emma Etudiant ing√©nieur Agroalimentaire Institut Agro Rennes GitHub ‚Ä¢ LinkedIn\n\n\n Placier Mo√Øse Etudiant ing√©nieur Agronome - ENSAT Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Durand Emma Etudiant ing√©nieur Agroalimentaire Institut Agro Rennes GitHub ‚Ä¢ LinkedIn"
  },
  {
    "objectID": "index.html#pr√©sentation-de-la-conf√©rence",
    "href": "index.html#pr√©sentation-de-la-conf√©rence",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Pr√©sentation de la conf√©rence",
    "text": "Pr√©sentation de la conf√©rence\nOrganis√©e enti√®rement par les √©tudiants de master 2 - sp√©cialisation Sciences des Donn√©es, cette conf√©rence annuelle est un rendez-vous incontournable !\nElle s‚Äôinscrit dans le cadre de l‚Äô√©valuation des modules Machine Learning et Computer Science for Big Data Approaches. C‚Äôest l‚Äôoccasion de mettre √† l‚Äôhonneur les projets des √©tudiants et de d√©couvrir des m√©thodes modernes de Machine Learning et de Deep Learning appliqu√©es aux probl√©matiques des sciences du vivant."
  },
  {
    "objectID": "index.html#pr√©sentation-de-l√©cole-dautomne",
    "href": "index.html#pr√©sentation-de-l√©cole-dautomne",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Pr√©sentation de l‚Äô√©cole d‚Äôautomne",
    "text": "Pr√©sentation de l‚Äô√©cole d‚Äôautomne\nOrganis√©e enti√®rement par les √©tudiants de Master 2 ‚Äì sp√©cialisation Sciences des Donn√©es, cette √©cole d‚Äôautomne annuelle est un rendez-vous incontournable !\nElle s‚Äôinscrit dans le cadre de l‚Äô√©valuation des modules Machine Learning et Computer Science for Big Data Approaches, et permet aux √©tudiants de restituer leurs projets sous forme de mini‚Äëcours. Chaque groupe pr√©sente ainsi un expos√© didactique, combinant th√©orie et pratique, pour partager ses m√©thodes et r√©sultats.\nC‚Äôest l‚Äôoccasion de mettre √† l‚Äôhonneur les travaux des √©tudiants et de d√©couvrir des approches modernes de Machine Learning et de Deep Learning appliqu√©es aux probl√©matiques des sciences du vivant.\n\nTh√®me 2025 ‚Äì Machine Learning pour la Science du Vivant\nPour cette 3·µâ √©dition,l‚Äô√©cole explore les apports du Machine Learning √† la compr√©hension, la mod√©lisation et la pr√©diction dans le champ du vivant : agriculture, environnement, √©cologie, sant√© ou biotechnologies.\nLes √©tudiants pr√©senteront des projets originaux illustrant la diversit√© des approches possibles et l‚Äôimpact concret de telles applications.\n\n\nLes acteurs de la conf√©rence\n\nEncadrants p√©dagogiques :\n\n\n\n Mathieu Emily\n\nProfesseur titulaire de statistique et responsable du d√©partement de recherche en statistique.\nLaboratoire : D√©partement statistique, IRMAR (UMR CNRS 6625)\nContact : mathieu.emily@agrocampus-ouest.fr\n\n\n Laetitia Chapel\n\nProfesseure titulaire en Computeur Science et chercheuse.\nLaboratoire : √âquipe OBELIX, IRISA (UMR CNRS 6074)\nContact : laetitia.chapel@agrocampus-ouest.fr\n\n\n\n\n\n√âtudiants participants :\n\nLes √©tudiants de la promotion 2025 du parcours Sciences des Donn√©es sont pr√©sent√©s dans la rubrique √Ä propos du site, avec leurs photos, noms et liens vers GitHub et LinkedIn. \n\n\nProgramme de la journ√©e\nLe programme complet, incluant les horaires de passages et les slides de chaque groupe, est consultable dans la rubrique Programme.\nTous les travaux des √©tudiants sont centralis√©s dans un d√©p√¥t GitHub. Chaque projet comprend le code, un document de synth√®se et les diapositives de pr√©sentation, permettant de consulter, reproduire et approfondir les travaux pr√©sent√©s durant cette √©dition de l‚Äô√©cole d‚Äôautomne.\n\n\nüìç Informations pratiques\nD√©tails d‚Äôacc√®s et plan disponibles dans la page Infos pratiques.\nLieu : Institut Agro Rennes, Amphi Matagrin\nHoraires : 9h00 ‚Äì 17h30."
  },
  {
    "objectID": "index.html#les-acteurs-de-la-conf√©rence",
    "href": "index.html#les-acteurs-de-la-conf√©rence",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Les acteurs de la conf√©rence",
    "text": "Les acteurs de la conf√©rence\n\nEncadrants p√©dagogiques :\n\n\n\n Mathieu Emily\n\nProfesseur titulaire de statistique et responsable du d√©partement de recherche en statistique.\nLaboratoire : D√©partement statistique, IRMAR (UMR CNRS 6625)\nContact : mathieu.emily@agrocampus-ouest.fr\n\n\n Laetitia Chapel\n\nProfesseure titulaire en Computeur Science et chercheuse.\nLaboratoire : √âquipe OBELIX, IRISA (UMR CNRS 6074)\nContact : laetitia.chapel@agrocampus-ouest.fr\n\n\n\n \n\n√âtudiants participants\n\nLes √©tudiants de la promotion 2025 du parcours Sciences des Donn√©es sont pr√©sent√©s dans la rubrique √Ä propos du site, avec leurs photos, noms et liens vers GitHub et LinkedIn."
  },
  {
    "objectID": "index.html#edition-2025-ecole-dautomne",
    "href": "index.html#edition-2025-ecole-dautomne",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Edition 2025 : Ecole d‚Äôautomne",
<<<<<<< Updated upstream
    "text": "Edition 2025 : Ecole d‚Äôautomne\nPour cette 3√®me √©dition, la conf√©rence prend le format d‚Äôune √©cole d‚Äôautomne et est organis√©e enti√®rement par les √©tudiants de Master 2 ‚Äì sp√©cialisation Sciences des Donn√©es. Nous explorons les apports du Machine Learning √† la compr√©hension, la mod√©lisation et la pr√©diction dans le champ du vivant : agriculture, environnement, √©cologie, sant√© ou biotechnologies.\nCette initiative s‚Äôinscrit dans le cadre de l‚Äô√©valuation des modules Machine Learning et Computer Science for Big Data Approaches. Les √©tudiants de restitueront leurs projets sous forme de mini‚Äëcours afin d‚Äôillustrer la diversit√© des approches possibles et l‚Äôimpact concret de telles applications.\nC‚Äôest l‚Äôoccasion de d√©couvrir des m√©thodes modernes de Machine Learning et de Deep Learning appliqu√©es aux probl√©matiques des sciences du vivant.\n\nLes acteurs de la conf√©rence\n\nEncadrants p√©dagogiques :\n\n\n\n Mathieu Emily\n\nProfesseur titulaire de statistique et responsable du d√©partement de recherche en statistique.\nLaboratoire : D√©partement statistique, IRMAR (UMR CNRS 6625)\nContact : mathieu.emily@agrocampus-ouest.fr\n\n\n Laetitia Chapel\n\nProfesseure titulaire en Computeur Science et chercheuse.\nLaboratoire : √âquipe OBELIX, IRISA (UMR CNRS 6074)\nContact : laetitia.chapel@agrocampus-ouest.fr\n\n\n\n\n\n√âtudiants participants :\n\nLes √©tudiants de la promotion 2025 du parcours Sciences des Donn√©es sont pr√©sent√©s dans la rubrique √Ä propos du site, avec leurs photos, noms et liens vers GitHub et LinkedIn. \n\n\nProgramme de la journ√©e\nLe programme complet, incluant les horaires de passages et les slides de chaque groupe, est consultable dans la rubrique Programme.\nTous les travaux des √©tudiants sont centralis√©s dans un d√©p√¥t GitHub. Chaque projet comprend le code, un document de synth√®se et les diapositives de pr√©sentation, permettant de consulter, reproduire et approfondir les travaux pr√©sent√©s durant cette √©dition de l‚Äô√©cole d‚Äôautomne.\n\n\nüìç Informations pratiques\nD√©tails d‚Äôacc√®s et plan disponibles dans la page Infos pratiques.\nLieu : Institut Agro Rennes, Amphi Matagrin\nHoraires : 9h00 ‚Äì 17h30."
<<<<<<< HEAD
=======
    "text": "Edition 2025 : Ecole d‚Äôautomne\nPour cette 3√®me √©dition, la conf√©rence prend le format d‚Äôune √©cole d‚Äôautomne.\nOrganis√©e par les √©tudiants de Master 2 et les √©l√®ves ing√©nieurs en sp√©cialisation Sciences des Donn√©es, cette √©cole d‚Äôautomne annuelle est un rendez-vous incontournable !\nElle s‚Äôinscrit dans le cadre de l‚Äô√©valuation des modules Machine Learning et Computer Science for Big Data Approaches, et permet aux √©tudiants de restituer leurs projets sous forme de mini‚Äëcours.\nC‚Äôest l‚Äôoccasion de mettre √† l‚Äôhonneur les travaux des √©tudiants et de d√©couvrir des approches modernes de Machine Learning et de Deep Learning appliqu√©es aux probl√©matiques des sciences du vivant.\n\nTh√®me 2025\nPour cette 3·µâ √©dition, nous explorons les apports du Machine Learning √† la compr√©hension, la mod√©lisation et la pr√©diction dans le champ du vivant : agriculture, environnement, √©cologie, sant√© ou biotechnologies.\nLes √©tudiants pr√©senteront des projets originaux illustrant la diversit√© des approches possibles et l‚Äôimpact concret de telles applications.\n\n\nProgramme de la journ√©e\nLe programme complet, incluant les horaires de passages et les slides de chaque groupe, est consultable dans la rubrique Programme.\nTous les travaux des √©tudiants sont centralis√©s dans un d√©p√¥t GitHub. Chaque projet comprend le code, un document de synth√®se et les diapositives de pr√©sentation, permettant de consulter, reproduire et approfondir les travaux pr√©sent√©s durant cette √©dition de l‚Äô√©cole d‚Äôautomne.\n\n\nüìç Informations pratiques\nD√©tails d‚Äôacc√®s et plan disponibles dans la page Infos pratiques.\nLieu : Salle 5√®me ann√©e du B√¢timent 24 de l‚ÄôInstitut Agro Rennes-Angers (Campus de Rennes)\nHoraires : Vendredi 21 novembre 2025 entre 13h30 et 16h30."
>>>>>>> Stashed changes
=======
  },
  {
    "objectID": "projets/Template_presentation_projets.html#definitions",
    "href": "projets/Template_presentation_projets.html#definitions",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Definitions",
    "text": "Definitions\nPrimary structure refers to the linear sequence of amino acids (residues) in a protein.\nThe secondary structure describes the local organization of the protein backbone. Most residues adopt one of two regular conformations: Œ±-helices and Œ≤-strands, as originally formalized in the early structural work of Pauling & Corey. For modelling, we simplify the standard eight secondary structure categories into three classes:\n‚ÄúH‚Äù for helix (including 3-10 helix ‚ÄúG‚Äù and œÄ-helix ‚ÄúI‚Äù mapped to ‚ÄòH‚Äô)\n‚ÄúE‚Äù for Œ≤-strand (including Œ≤-bridge ‚ÄúB‚Äù)\n‚ÄúC‚Äù for coil (turns ‚ÄúT‚Äù, bends ‚ÄúS‚Äù, loops ‚ÄúL‚Äù)\nThis allows us to represent the secondary structure as a one-dimensional sequence of H/E/C labels.\nTertiary structure refers to the three-dimensional conformation of a protein under physiological conditions (temperature, pH, solvent etc.), as observed via X-ray crystallography, NMR or cryo-EM. It describes the spatial relationships among the secondary-structure elements."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#why-focus-on-sequence-based-prediction",
    "href": "projets/Template_presentation_projets.html#why-focus-on-sequence-based-prediction",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Why focus on sequence-based prediction?",
    "text": "Why focus on sequence-based prediction?\nA central principle of molecular biophysics is that the amino-acid sequence largely determines the final three-dimensional fold, a concept supported both experimentally (e.g., Anfinsen‚Äôs dogma) and theoretically. This makes structure prediction from sequence an attractive computational goal, especially because sequencing a protein is vastly simpler, faster, and cheaper (on the order of ~$100) than experimentally determining its structure via crystallography, NMR or cryo-EM (which often require years of work and involve very large costs). Consequently the field of protein-structure prediction is highly active.\nHowever, the prediction problem is intrinsically difficult. The classical Levinthal paradox illustrates well the combinatorial explosion of possible conformations: if each residue can adopt approximately three stable states, a protein of 101 amino acids would have ~3^100 potential conformations. Exhaustive enumeration is therefore infeasible"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#why-predict-secondary-structure",
    "href": "projets/Template_presentation_projets.html#why-predict-secondary-structure",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Why predict secondary structure?",
    "text": "Why predict secondary structure?\nWe restrict our focus to secondary-structure prediction because it simplifies both the modelling and the evaluation. Instead of predicting a 3D coordinate triplet (x, y, z) for every residue, we classify each residue into H, E or C. Metrics such as Q3 accuracy are straightforward to compute, and this one-dimensional output remains highly informative for understanding folding, guiding tertiary-structure prediction, and supporting downstream tasks in structural bioinformatics.\nAt the same time, although simplified, the biological input features (physico-chemical properties, multiple-sequence alignments, PSSM/evolutionary profiles) and the modelling strategies (Random Forest, CNNs, transformer/NLP-based embeddings) remain relevant and transferable to tertiary-structure prediction tasks. This project therefore offers a sound starting point for exploring the core themes of protein-structure prediction."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#characteristics-of-protein-datasets",
    "href": "projets/Template_presentation_projets.html#characteristics-of-protein-datasets",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Characteristics of Protein Datasets",
    "text": "Characteristics of Protein Datasets\nProtein datasets differ fundamentally from standard machine-learning datasets, and these differences deeply impact training, evaluation, and generalization.\n\nNon-I.I.D. Nature and Evolutionary Coupling\nProteins are not independent samples. They arise from evolutionary processes and thus share phylogenetic relationships. Many proteins within a dataset have detectable homology, violating the i.i.d. assumption that underpins most ML models. Two sequences may share a common ancestor even if they differ in function, which makes na√Øve dataset splitting misleading.\n\n\nHigh Structural and Sequential Redundancy\nHomologous proteins can exceed 90% sequence identity, meaning they are nearly identical at the residue level. This level of redundancy has no equivalent in common ML domains such as vision, where similar classes remain pixel-distinct. Without proper control of redundancy, models trivially memorize homologous examples rather than learning the underlying biophysics of folding."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#impact-on-machine-learning-training",
    "href": "projets/Template_presentation_projets.html#impact-on-machine-learning-training",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Impact on Machine-Learning Training",
    "text": "Impact on Machine-Learning Training\nThese dataset characteristics create several pitfalls that must be explicitly mitigated.\n\nSevere Risk of Overfitting\nIf training, validation, and test sets share proteins above 30‚Äì40% sequence identity, a model can achieve high accuracy simply by memorizing close homologs. This yields deceptively strong performance, especially on short-range structure, without genuine understanding of folding constraints. When homologous leakage occurs, a model does not generalize the folding process and will fail to predict structures for truly novel proteins, such as proteins from under-sampled species or newly sequenced metagenomic datasets. This undermines the biological utility of the predictor."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#implemented-solutions",
    "href": "projets/Template_presentation_projets.html#implemented-solutions",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Implemented Solutions",
    "text": "Implemented Solutions\nProteinNet employs several mechanisms to avoid these pitfalls, and we reproduce these principles in our experimental setup.\n\nHomology-Aware Splitting Through Sequence Clustering for train and validation split\nDataset splits are not random but based on sequence-identity clustering. Tools such as jackHMMER group proteins by similarity, ensuring that clusters assigned to training do not overlap with those assigned to validation. This preserves evolutionary independence across folds and yields more realistic performance estimates.\n\n\nBlind Evaluation via CASP Protocol\nProteinNet uses the CASP (Critical Assessment of Structure Prediction) evaluation framework, where models are tested on protein structures that were not publicly available at training time. This ensures transparent, unbiased assessment of generalization. CASP remains the gold standard benchmark for structure prediction."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#local-models-physico-chemical-features-random-forest",
    "href": "projets/Template_presentation_projets.html#local-models-physico-chemical-features-random-forest",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "1. Local Models: Physico-Chemical Features + Random Forest",
    "text": "1. Local Models: Physico-Chemical Features + Random Forest\nOur initial modeling strategy leverages the intrinsic physico-chemical properties of individual amino acids and their immediate sequence context to predict secondary structure. By employing a sliding window approach, we capture the local interactions that drive helix and coil formation. This framework provides a straightforward yet biologically informed baseline\n\nData Preprocessing for the Random Forest\nTo prepare the input data for our Random Forest model, each protein sequence is first segmented into overlapping windows of size 11, such that for a sequence of length \\(L\\), \\(L\\) windows are generated, each centered on a single residue. Within each window, individual amino acids are represented as vectors of physico-chemical descriptors derived from the AAindex1 database. Residues that correspond to padding (‚Äò-‚Äô) at sequence termini are assigned zero-filled vectors to maintain consistent dimensionality. The descriptors from all residues in a window are then concatenated to form a single flattened feature vector, which preserves local contextual information around each residue while producing a tabular format compatible with classical machine learning models.\nWe selected descriptors that influence secondary structure formation:\n\nHydrophobicity / Hydrophilicity\n\nDetermines helix folding and internal beta-strand stability.\n\nARGP820101 Hydrophobicity index (Argos et al., 1982)\n\n\nSide-chain Volume / Size\n\nSteric effects can favor loops versus compact helices.\n\nBIGC670101 Residue volume (Bigelow, 1967)\nFAUJ880106 Max width of side chain (Fauchere et al., 1988)\n\n\nPolarity\n\nInfluences hydrogen bonding and solvent exposure.\n\nCHAM820101 Polarizability (Charton-Charton, 1982)\nGRAR740102 Polarity (Grantham, 1974)\nRADA880108 Mean polarity (Radzicka-Wolfenden, 1988)\n\n\nCharge\n\nLocal electrostatics affect helix and beta-strand formation.\n\nFAUJ880111 Positive charge (Fauchere et al., 1988)\nFAUJ880112 Negative charge (Fauchere et al., 1988)\n\n\nFlexibility / Rigidity\n\nGlycine is flexible, proline rigid; this affects loop/corner formation.\n\nBHAR880101 Flexibility index (Bhaskaran-Ponnuswamy, 1988)\n\n\nHydrogen-bond potential\n\nAbility to donate/accept H-bonds stabilizes helices and strands.\n\nCHAM830107 Charge transfer parameter (Charton-Charton, 1983)\nFAUJ880109 Number of hydrogen-bond donors (Fauchere et al., 1988)\n\nFollowing this preprocessing pipeline, we obtain a comprehensive tabular dataset suitable for Random Forest training. For a sliding window of size 11, each residue is represented by 11 √ó 11 = 121 features, reflecting the concatenation of 11 physico-chemical descriptors across the local sequence context. The resulting training set comprises 2,270,581 windows, with secondary structure labels distributed as 1,011,153 coils (C), 472,863 beta strands (E), and 786,565 helices (H).\n\n\nModel Training\nTo train our Random Forest classifier efficiently, we first extracted a representative subset of 200,000 windows from the training set, stratified by secondary structure labels to preserve class distributions (C: 1,011,153; E: 472,863; H: 786,565). This subset was used for rapid hyperparameter tuning, allowing systematic exploration of the number of estimators, tree depth, minimum samples per leaf, and the number of features considered at each split. Each combination of hyperparameters was evaluated on a held-out validation set using multiple metrics, including Q3 accuracy (the fraction of residues correctly classified into the three secondary structure classes H, E, and C), balanced Q3 accuracy and macro F1 score.\nAfter exhaustive grid search, the optimal parameters were identified as 200 trees, a maximum depth of 20, minimum samples per leaf of 1, and sqrt features considered at each split. With thoses hyperparameters determined, the final Random Forest was trained on the full training set and persisted to disk.\n\n\nResults and discussion\nOverall Metrics\n\n\n\nMetric\nValue\n\n\n\n\nQ3 Accuracy\n0.665\n\n\nBalanced Accuracy\n0.626\n\n\nMacro F1\n0.633\n\n\n\nClass-wise Performance\n\n\n\nClass\nPrecision\nRecall\nF1-score\nSupport\n\n\n\n\nH\n0.63\n0.68\n0.65\n3788\n\n\nE\n0.65\n0.43\n0.52\n2551\n\n\nC\n0.69\n0.77\n0.73\n5317\n\n\nMacro Avg\n0.66\n0.63\n0.63\n11656\n\n\nWeighted Avg\n0.66\n0.66\n0.66\n11656\n\n\n\nAlthough Random Forests trained on local physico-chemical features provide a biologically interpretable baseline, they are inherently limited, which directly accounts for the observed performance. These models are fundamentally local, relying on sliding windows that capture only short-range interactions between residues.\nBeta strands are fundamentally non-local structures, as their formation often involves interactions between residues that are distant in the primary sequence, unlike alpha helices, which are largely local and can be stabilized by as few as five consecutive residues through hydrogen bonding. Moreover, a given amino acid sequence can adopt a stable alpha helix in isolation but form a beta strand in the context of long-range interactions with other distant residues. This distinction explains why the model predicts helices and coils relatively well but struggles with beta strands. As Baldwin and Rose note, ‚Äúthe accuracy of secondary structure predictions is only 65‚Äì70%. This fact is usually interpreted to imply that the remaining variance of 30‚Äì35% is caused by non-local interactions‚Äù (Baldwin & Rose, 2013), which is consistent with the ~66% Q3 accuracy achieved by our Random Forest.\n\nAnother limitation stems from the residue-level granularity of predictions, which can fragment continuous secondary structure elements. Helices and beta strands span multiple residues, but predicting each residue independently often produces biologically inconsistent patterns. For instance, a target sequence : [‚ÄòC‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô] may be predicted as : [‚ÄòC‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòE‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô] resulting in short, fragmented structures that do not reflect realistic motifs. This is particularly problematic for alpha helices, which require a minimum of five consecutive residues to form a stable helix. If only three consecutive residues are predicted as helix, it is unclear how to interpret them biologically: should they be converted to coil, extended to form a full helix, or treated as part of a beta strand? Such inconsistencies highlight the limitations of purely residue-level, local prediction approaches.\nFinally, the Random Forest model itself has limitations: it treats features as independent and is invariant to permutations, so it cannot exploit sequential correlations or detect motifs across neighboring residues within the window as a CNN or transformer-based model could. Additionally, the input features‚Äîphysico-chemical descriptors‚Äîrepresent only local properties and is a redundant information. Taken together, these factors naturally limit the model‚Äôs performance, making a plateau around 65‚Äì66% accuracy expected for purely local, feature-based methods."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#evolutionary-information-and-convolutional-models-2d-cnn-pssm",
    "href": "projets/Template_presentation_projets.html#evolutionary-information-and-convolutional-models-2d-cnn-pssm",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Evolutionary information and convolutional models (2D CNN + PSSM)",
    "text": "Evolutionary information and convolutional models (2D CNN + PSSM)\nThis subsection introduces evolutionary descriptors, especially Position-Specific Scoring Matrices (PSSMs) derived from multiple sequence alignments, widely used in secondary-structure predictors such as PSIPRED and JPred . A PSSM provides, for each sequence position i and amino acid a, a substitution score or probability ùëÉ ( ùëé ‚à£ ùëñ ) P(a‚à£i). Each column represents the evolutionary profile of that position, and the profiles are treated as independent across positions‚Äîno long-range coupling is encoded.\nYou then justify the use of 1D or 2D convolutional networks: CNNs apply learnable filters that slide along the sequence, sharing weights across positions and exploiting translational invariance (or equivariance). This yields a stronger ability to learn local sequence motifs and conserved patterns than Random Forests. However, CNNs remain inherently local. Although receptive fields can be widened, PSSMs themselves carry position-specific but non-contextual information, so long-range effects are still not represented explicitly."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#global-contextual-representation-learning-protein-bert-transformer-models",
    "href": "projets/Template_presentation_projets.html#global-contextual-representation-learning-protein-bert-transformer-models",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Global, contextual representation learning (Protein BERT / Transformer models)",
    "text": "Global, contextual representation learning (Protein BERT / Transformer models)\nThis subsection introduces protein language models such as ProtBERT, ESM, and ProtT5, citing foundational works:\nProtBERT: BERTology for Proteins\nESM: Evolutionary-Scale Modeling\nExplain that transformers use global self-attention, enabling every residue to incorporate information from every other residue, regardless of distance in the sequence. These models inherently capture long-range dependencies and evolutionary constraints, making them especially effective for predicting Œ≤-sheets, inter-strand pairing, and cooperative formation of helices.\nYou can contrast this with PSSMs:\nPSSMs encode positional evolutionary profiles but treat each column independently.\nProtein language models encode contextual evolutionary and structural signals by learning from millions of sequences.\nThis positions transformer-based embeddings as the most expressive and biologically relevant inputs for downstream secondary-structure prediction."
  },
  {
    "objectID": "projets/Template_presentation_projets.html#evolutionary-information-and-convolutional-models-1d-cnn-pssm",
    "href": "projets/Template_presentation_projets.html#evolutionary-information-and-convolutional-models-1d-cnn-pssm",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Evolutionary information and convolutional models (1D CNN + PSSM)",
    "text": "Evolutionary information and convolutional models (1D CNN + PSSM)\nThis subsection introduces evolutionary descriptors, especially Position-Specific Scoring Matrices (PSSMs) derived from multiple sequence alignments, widely used in secondary-structure predictors.\n\nThe biological input : PSSM\nA Position-Specific Scoring Matrix (PSSM) provides an evolutionary profile for each residue position within a protein sequence. For each position \\(i\\) and amino acid \\(a\\), the PSSM encodes a substitution probability or score \\(P(a \\mid i)\\) derived from a Multiple Sequence Alignment (MSA). An MSA is a matrix-like arrangement of homologous sequences where each row represents a sequence and columns align residues considered evolutionarily equivalent.\nSuppose we have the following MSA for a protein segment of length 5:\n\n\n\nSequence\n1\n2\n3\n4\n5\n\n\n\n\nS1\nA\nL\nK\nA\nV\n\n\nS2\nA\nL\nR\nA\nV\n\n\nS3\nA\nI\nK\nA\nI\n\n\nS4\nA\nL\nK\nA\nV\n\n\n\nFirst, the multiple sequence alignment is scanned column by column to count how many times each amino acid occurs at position \\(i\\).\n\n\n\nPosition\nA\nL\nI\nK\nR\nV\n\n\n\n\n1\n4\n0\n0\n0\n0\n0\n\n\n2\n0\n3\n1\n0\n0\n0\n\n\n3\n0\n0\n0\n3\n1\n0\n\n\n4\n4\n0\n0\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n0\n3\n\n\n\nNext, the counts are converted into positional probabilities \\(P(a \\mid i)\\) by dividing by the number of sequences in the MSA. For example, at position 2, \\(P(L \\mid 2)=3/4\\) and \\(P(I \\mid 2)=1/4\\). These probabilities indicate how frequently each amino acid occurs at a given evolutionary position.\nFinally, the positional probabilities are compared to the background frequency \\(P(a)\\) of each amino acid in a large non-redundant protein database using the log-odds formula: \\[PSSM(a, i) = \\log \\frac{P(a \\mid i)}{P(a)}\\]\n\n\n\n\n\n\n\n\n\n\n\nAA ‚Üì / Pos ‚Üí\n1\n2\n3\n4\n5\n\n\n\n\nA\nlog(4/4 / 0.05)= log(20)= 3.00\n0\n0\n3.00\n0\n\n\nL\n0\nlog(3/4 / 0.05)=2.30\n0\n0\n0\n\n\nI\n0\nlog(1/4 / 0.05)=1.61\n0\n0\n1.61\n\n\nK\n0\n0\n2.71\n0\n0\n\n\nR\n0\n0\n1.61\n0\n0\n\n\nV\n0\n0\n0\n0\n2.30\n\n\n\nIf \\(P(a\\mid i)\\) is higher than the background, the score is positive, indicating evolutionary enrichment of that amino acid at that position. If it is lower, the score is negative. In the example, position 1 is strongly enriched for A because \\(P(A\\mid1)=1.0\\) is much larger than the background probability \\(P(A)=0.05\\), giving a high log-odds value of about 3.00. In other words, a high positive PSSM score at position \\(i\\) for amino acid \\(a\\) indicates that \\(a\\) occurs more often than expected by chance at that position among homologous sequences.\nThe PSSMs used in this project are derived from the ProteinNet dataset, where MSAs were generated using JackHMMER and weighted with Henikoff position-based weights to reduce the influence of closely related sequences.\nFor secondary structure prediction, PSSMs introduce a strong biological signal that is not present in raw amino acid sequences or physico-chemical descriptors. Evolutionarily conserved positions tend to correspond to structurally or functionally important residues, while positions tolerant to substitution often lie in loops or solvent-exposed regions.\n\n\nData Preprocessing for the 1D CNN Model\nTo leverage the sequential nature of proteins, the 1D convolutional neural network (CNN) operates on full-length sequences rather than fixed local windows. Unlike the Random Forest, which relies on sliding windows to capture short-range context, the CNN requires a consistent tensor shape across all proteins while preserving the residue order.\nEach amino acid is represented as a 21-dimensional one-hot vector, encoding the 20 standard residues plus a dedicated padding token. Protein sequences vary in length, so both inputs and labels are padded to the maximum sequence length in the dataset. As a result, each protein is converted into an input tensor of shape \\((L_{\\text{max}}, 21)\\) and a label tensor of shape \\((L_{\\text{max}})\\), with padded positions assigned a special index to be ignored during loss computation.\nDuring training, input tensors are transposed to \\((\\text{Batch}, 21, L_{\\text{max}})\\), the format expected by PyTorch‚Äôs Conv1d layers.\n\n\n1D CNN Architecture\nThe network consists of three consecutive 1D convolutional layers with kernel size 5 corresponding to the typical length of local structural motifs, progressively increasing the number of filters from 128 to 256 and then 512. Dropout layers (rate 0.5) follow the first two convolutions to mitigate overfitting. The final classification layer is a position-wise 1D convolution with kernel size one, producing logits over the three secondary structure classes (H, E, C) for each residue. Padding is applied to maintain the original sequence length throughout all convolutional layers.\nThis architecture was chosen to balance biological interpretability and computational efficiency: the kernel size reflects the scale of short-range interactions, the progressive increase in filter number allows hierarchical feature extraction, and the absence of pooling preserves positional information critical for residue-level classification. By combining sequence order and evolutionary profiles through PSSMs, the network can leverage both local residue context and evolutionary conservation to improve secondary structure prediction accuracy.\nYou then justify the use of 1D or 2D convolutional networks: CNNs apply learnable filters that slide along the sequence, sharing weights across positions and exploiting translational invariance (or equivariance). This yields a stronger ability to learn local sequence motifs and conserved patterns than Random Forests. However, CNNs remain inherently local. Although receptive fields can be widened, PSSMs themselves carry position-specific but non-contextual information, so long-range effects are still not represented explicitly.\n\n\nResults and discussion"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#language-model-proteinbert-for-secondary-structure-prediction",
    "href": "projets/Template_presentation_projets.html#language-model-proteinbert-for-secondary-structure-prediction",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "language model ProteinBERT for Secondary Structure Prediction",
    "text": "language model ProteinBERT for Secondary Structure Prediction\nProteinBERT is a deep language model specifically designed for protein sequences. Inspired by the Transformer/BERT architecture from natural language processing, it integrates both local (residue-level) and global (whole-sequence) representations, enabling efficient modeling of very long protein sequences. Despite its relatively modest size (~16 million parameters), ProteinBERT achieves state-of-the-art performance across multiple protein prediction benchmarks.\nThe model is pretrained using a dual-task self-supervised scheme on ~106 million non-redundant protein sequences from UniRef90. The pretraining tasks include masked language modeling, where random amino acids are corrupted and must be reconstructed, and Gene Ontology (GO) annotation prediction, where the model predicts functional annotations from partial input. This joint pretraining allows ProteinBERT to learn representations that capture both sequence patterns and functional context.\nProteinBERT embeddings encode a rich mixture of residue-level physicochemical properties, evolutionary information, and functional context. Pretraining on large, diverse protein sets allows the model to generalize to sequences lacking close homologs, while the GO prediction task provides global functional signals that improve local predictions.\nWhile PSSMs encode only the likelihood of observing each amino acid at a given position, independently of other positions, ProteinBERT captures richer information that integrates residue-level context, long-range dependencies, and functional signals learned across millions of proteins. Consequently, whereas PSSMs are limited to evolutionary conservation and local substitution patterns, ProteinBERT embeddings incorporate both local sequence motifs and global structural and functional cues.This combination of local and global context makes ProteinBERT particularly suitable for predicting residue-level secondary structures.\n\nThe embedding-generation pipeline\nThe embedding-generation pipeline follows a simple two-step procedure.\nIn the first step, each protein sequence is processed independently through the pretrained ProtBERT model. The sequence is tokenized into single-residue tokens, encoded with the ProtBERT tokenizer, and passed through the encoder in inference mode. Each amino-acid sequence of length \\(L\\) is transformed by ProtBERT into a matrix of shape \\((L, 1024)\\), where each residue is represented by a 1024-dimensional contextual embedding. These embeddings are saved individually as .npy arrays, one per protein, and the associated secondary-structure labels are stored as vectors of length \\(L\\) containing integer class indices.\nDuring dataset loading, each sequence keeps its original shape \\((L, 1024)\\) until batching. When a batch is formed, the variable-length sequences are padded along the residue axis, producing a tensor of size \\((\\text{Batch}, L_{\\text{max}}, 1024)\\), where \\(L_{\\text{max}}\\) is the longest sequence in the batch. Labels undergo the same padding procedure and form a tensor of size \\((\\text{Batch}, L_{\\text{max}})\\), with a dedicated padding index (‚àí100) used to mask non-valid positions during loss computation."
>>>>>>> 97db57e (presentation projet Mo√Øse)
  }
]