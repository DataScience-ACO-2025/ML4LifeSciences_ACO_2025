[
  {
    "objectID": "infos.html",
    "href": "infos.html",
    "title": "Infos pratiques",
    "section": "",
    "text": "Horaires :\nvendredi 21 novembre 2025 entre 13h30 et 16h30\n\n\nLieu\nSalle 5√®me ann√©e du B√¢timent 24\nInstitut Agro Rennes 65 Rue de Saint-Brieuc, 35042 Rennes.\n\n\nPlan d‚Äôacc√®s"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "A propos",
    "section": "",
    "text": "L‚ÄôInstitut Agro Rennes-Angers est un √©tablissement public d‚Äôenseignement sup√©rieur et de recherche en agronomie, environnement et alimentation. Il forme des ing√©nieurs et chercheurs capables de relever les d√©fis li√©s √† la durabilit√© des syst√®mes agricoles et alimentaires.\nLe Master Math√©matiques Appliqu√©es, Statistique est co-accr√©dit√©e par plusieurs √©tablissements d‚Äôenseignement sup√©rieur rennais, notament l‚ÄôUniversit√© Rennes 2 et l‚Äô√âcole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation (ENSAI).\nAu sein de l‚ÄôInstitut Agro Rennes-Angers, les √©tudiants suivent le parcours Data Science pour la biologie, qui vise √† d√©velopper des comp√©tences avanc√©es en analyse de donn√©es et en mod√©lisation statistique appliqu√©es aux domaines de l‚Äôagriculture, de l‚Äôagroalimentaire, des sciences de l‚Äôenvironnement et de la biologie."
  },
  {
    "objectID": "about.html#responsables-p√©agogiques",
    "href": "about.html#responsables-p√©agogiques",
    "title": "A propos",
    "section": "Responsables p√©agogiques :",
    "text": "Responsables p√©agogiques :\nResponsable de la sp√©cialisation : S√©bastien L√™ ‚Äî sebastien.le@institut-agro.fr\nResponsable du master : David Causeur ‚Äî david.causeur@institut-agro.fr"
  },
  {
    "objectID": "about.html#promo-2025",
    "href": "about.html#promo-2025",
    "title": "A propos",
    "section": "Promo 2025",
    "text": "Promo 2025\nLes √©tudiants de la sp√©cialisation Sciences des Donn√©es Biologiques pr√©sentent leurs travaux dans le cadre de la conf√©rence Machine Learning pour la Science du Vivant.\n\n\n Dupont Alice Etudiant ing√©nieur Agronome Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n\nMartin Hugo\nUniversit√© Rennes 2\nInstitut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Placier Mo√Øse Etudiant ing√©nieur Agronome - ENSAT Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Durand Emma Etudiant ing√©nieur Agroalimentaire Institut Agro Rennes GitHub ‚Ä¢ LinkedIn\n\n\n Placier Mo√Øse Etudiant ing√©nieur Agronome - ENSAT Institut Agro Rennes\nGitHub ‚Ä¢ LinkedIn\n\n\n Durand Emma Etudiant ing√©nieur Agroalimentaire Institut Agro Rennes GitHub ‚Ä¢ LinkedIn"
  },
  {
    "objectID": "projets/Template_presentation_projets.html",
    "href": "projets/Template_presentation_projets.html",
    "title": "D√©tection et segmentation automatique des m√©tastases c√©r√©brales sur IRM avec U-Net et SAM",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#lien-vers-le-code-github",
    "href": "projets/Template_presentation_projets.html#lien-vers-le-code-github",
    "title": "D√©tection et segmentation automatique des m√©tastases c√©r√©brales sur IRM avec U-Net et SAM",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#lien-vers-les-slides",
    "href": "projets/Template_presentation_projets.html#lien-vers-les-slides",
    "title": "D√©tection et segmentation automatique des m√©tastases c√©r√©brales sur IRM avec U-Net et SAM",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/Template_presentation_projets.html#description-projet",
    "href": "projets/Template_presentation_projets.html#description-projet",
    "title": "D√©tection et segmentation automatique des m√©tastases c√©r√©brales sur IRM avec U-Net et SAM",
    "section": "description Projet",
    "text": "description Projet\nLes m√©tastases c√©r√©brales apparaissent chez environ 2% des patients d√®s le diagnostic initial de leur cancer primaire, et ce chiffre peut √™tre plus √©lev√© pour les cancers particuli√®rement agressifs. Une d√©tection pr√©coce et pr√©cise de ces l√©sions est cruciale, car certaines m√©tastases peuvent √™tre trait√©es chirurgicalement ou par radioth√©rapie st√©r√©otaxique. Cependant, la lecture et l‚Äôannotation des IRM c√©r√©brales restent des t√¢ches longues et minutieuses pour les radiologues.\nPour r√©pondre √† ce d√©fi, notre projet utilise un jeu de donn√©es de 156 IRM c√©r√©brales issues de patients pr√©sentant au moins une m√©tastase confirm√©e. Pour une partie de ces images, des annotations de r√©f√©rence r√©alis√©es par des radiologues permettent de comparer et d‚Äô√©valuer les performances des m√©thodes d√©velopp√©es. L‚Äôobjectif est de concevoir des approches automatis√©es capables de d√©tecter et segmenter les m√©tastases c√©r√©brales, en s‚Äôappuyant notamment sur des architectures d‚Äôapprentissage profond telles que U-Net, largement utilis√©e pour la segmentation m√©dicale, et SAM (Segment Anything Model), un mod√®le plus r√©cent et g√©n√©ralisable. Ces outils permettent d‚Äôidentifier et de d√©limiter avec pr√©cision les l√©sions, illustrant comment l‚Äôintelligence artificielle peut acc√©l√©rer le diagnostic, am√©liorer la prise en charge clinique et ouvrir la voie √† une m√©decine plus assist√©e, fiable et personnalis√©e."
  },
  {
    "objectID": "projets/presentation_projet_CNN-BNN_insects.html",
    "href": "projets/presentation_projet_CNN-BNN_insects.html",
    "title": "Apport d‚Äôun mod√®le Bay√©sien lors de l‚Äôutilisation de r√©seaux de neuronnes pour la classification d‚Äôimages",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/presentation_projet_CNN-BNN_insects.html#lien-vers-le-code-github",
    "href": "projets/presentation_projet_CNN-BNN_insects.html#lien-vers-le-code-github",
    "title": "Apport d‚Äôun mod√®le Bay√©sien lors de l‚Äôutilisation de r√©seaux de neuronnes pour la classification d‚Äôimages",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/presentation_projet_CNN-BNN_insects.html#lien-vers-les-slides",
    "href": "projets/presentation_projet_CNN-BNN_insects.html#lien-vers-les-slides",
    "title": "Apport d‚Äôun mod√®le Bay√©sien lors de l‚Äôutilisation de r√©seaux de neuronnes pour la classification d‚Äôimages",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/presentation_projet_CNN-BNN_insects.html#description-projet",
    "href": "projets/presentation_projet_CNN-BNN_insects.html#description-projet",
    "title": "Apport d‚Äôun mod√®le Bay√©sien lors de l‚Äôutilisation de r√©seaux de neuronnes pour la classification d‚Äôimages",
    "section": "Description Projet",
    "text": "Description Projet\nNotre projet s‚Äôaxe sur des probl√©matiques d‚Äôapprentissage profond via r√©seaux de neuronnes, dans le cadre de la reconnaissance d‚Äôimages. Il a pour but l‚Äô√©valuation de l‚Äôapport d‚Äôun mod√®le comportant des composantes bay√©siennes par rapport √† un mod√®le purement fr√©quentiste. En comparant les 2 mod√®les du point de vue de l‚Äôacuracy en fonction des ressources demand√©es (nombre d‚Äôimage dans le jeu de donn√©e, temps d‚Äôentrainement du mod√®le, ressource GPU, ‚Ä¶) nous pourrons alors d√©terminer dans quels cas il est pr√©f√©rable d‚Äôutiliser l‚Äôune des 2 m√©thodes.\nEn terme de donn√©e, nous avons trouv√© un jeu de donn√©e ‚ÄúInsect_Detect_classification_v2‚Äù contenant des images d‚Äôinsectes de basse qualit√© (70x70) r√©partie dans 27 classes.\nPour effectuer cette d√©marche, le choix du mod√®le de CNN s‚Äôest d‚Äôabord impos√©. Notre r√©flexion s‚Äôest port√©e autour 3 mod√®les connus et √©prouv√©s : AlexNet, VGGNet et ResNet. Ces 3 mod√®les ont √©t√© entrain√© avec les data d‚Äô‚ÄúImageNet‚Äù, banque de plus de 14 millions d‚Äôimages annot√©es √† la main(1.2M √† l‚Äô√©poque). La simplicit√© de manipulation du mod√®le ainsi que sa clart√© ont √©t√© les principaux √©l√©ments de d√©cisions qui nous a pouss√© √† utiliser AlexNet, qui fait figure de basique du genre. En effet, ce mod√®le contient 8 couches : 5 convolutionnelles (+ 3 max-pooling) et 3 couches denses.\nNous poss√©dons des ressources limit√©es, et avons donc fait le choix de prendre le mod√®le AlexNet d√©j√† pr√©-entrain√© (en conservant les poids optenu √† la suite de son entrainement sur ImageNet) et de le fine-tuner pour nos donn√©es.\nAinsi, reste le probl√®me du mod√®le bay√©sien. Au cours de nos recherches, nous avons d√©couvert un package permettant de fine-tuner AlexNet en remplacant les couches convolutionnelles et lin√©aires classiques, qui renvoient des poids w fixe, en couches bay√©siennes qui renvoient une distriution de poids w.\nL‚Äôobjectif est alors de comprendre ce package, r√©ussir √† le faire fonctionner correctement pour notre probl√©matique, et l‚Äôoptimiser au possible avec nos ressources disponibles."
  },
  {
    "objectID": "projets/presentationFruits.html",
    "href": "projets/presentationFruits.html",
    "title": "Classification d‚Äôimages - une comparaison entre R et Python",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/presentationFruits.html#lien-vers-le-code-github",
    "href": "projets/presentationFruits.html#lien-vers-le-code-github",
    "title": "Classification d‚Äôimages - une comparaison entre R et Python",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/presentationFruits.html#lien-vers-les-slides",
    "href": "projets/presentationFruits.html#lien-vers-les-slides",
    "title": "Classification d‚Äôimages - une comparaison entre R et Python",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/presentationFruits.html#description-projet",
    "href": "projets/presentationFruits.html#description-projet",
    "title": "Classification d‚Äôimages - une comparaison entre R et Python",
    "section": "description Projet",
    "text": "description Projet\nLes disciplines de machine learning et de deep learning se pratiquent essentiellement avec le langage Python, langage de programmation le plus demand√© par les recruteurs de la Data Science en 2021 (KDnuggets). Or, le langage de programmation Open Source R est celui que nous utilisons le plus pour programmer.\nAinsi, nous nous sommes donn√© le challenge suivant : construire un mod√®le de deep learning en langage R.\nNous nous sommes demand√© : Comment un m√™me projet de deep learning peut-il √™tre abord√© diff√©remment selon l‚Äôoutil utilis√© ? Quels sont les avantages et limites de R Keras, Python Keras et PyTorch pour construire, entra√Æner et exploiter un mod√®le ?\nNotre exemple se place dans le cadre d‚Äôune classification de fruits pourris ou frais."
  },
  {
    "objectID": "projets/Project_protein_web.html",
    "href": "projets/Project_protein_web.html",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "",
    "text": "This project investigates Protein Secondary Structure Prediction (PSSP) from the primary amino-acid sequence, mapping the linear sequence of residues (primary structure) to a one-dimensional annotation of local folding states (secondary structure). We evaluate the impact of different biological descriptors and compare three core modeling strategies: Random Forest, 1D Convolutional Neural Networks (CNN), and specialized Protein Language Models (BERT)."
  },
  {
    "objectID": "projets/Project_protein_web.html#project-summary",
    "href": "projets/Project_protein_web.html#project-summary",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "",
    "text": "This project investigates Protein Secondary Structure Prediction (PSSP) from the primary amino-acid sequence, mapping the linear sequence of residues (primary structure) to a one-dimensional annotation of local folding states (secondary structure). We evaluate the impact of different biological descriptors and compare three core modeling strategies: Random Forest, 1D Convolutional Neural Networks (CNN), and specialized Protein Language Models (BERT)."
  },
  {
    "objectID": "projets/Project_protein_web.html#local-model-physico-chemical-features-random-forest",
    "href": "projets/Project_protein_web.html#local-model-physico-chemical-features-random-forest",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "1. Local Model : Physico-Chemical Features + Random Forest",
    "text": "1. Local Model : Physico-Chemical Features + Random Forest\nOur initial modeling strategy leverages the intrinsic physico-chemical properties of individual amino acids and their immediate sequence context to predict secondary structure. By employing a sliding window approach, we capture the local interactions that drive helix and coil formation. This framework provides a straightforward yet biologically informed baseline\n\nData Preprocessing for the Random Forest\nTo prepare the input data for our Random Forest model, each protein sequence is first segmented into overlapping windows of size 11, such that for a sequence of length \\(L\\), \\(L\\) windows are generated, each centered on a single residue. Within each window, individual amino acids are represented as vectors of physico-chemical descriptors derived from the AAindex1 database. Residues that correspond to padding (‚Äò-‚Äô) at sequence termini are assigned zero-filled vectors to maintain consistent dimensionality. The descriptors from all residues in a window are then concatenated to form a single flattened feature vector, which preserves local contextual information around each residue while producing a tabular format compatible with classical machine learning models.\nWe selected descriptors that influence secondary structure formation:\n\nHydrophobicity / Hydrophilicity\n\nDetermines helix folding and internal beta-strand stability.\n\nARGP820101 Hydrophobicity index (Argos et al., 1982)\n\n\nSide-chain Volume / Size\n\nSteric effects can favor loops versus compact helices.\n\nBIGC670101 Residue volume (Bigelow, 1967)\nFAUJ880106 Max width of side chain (Fauchere et al., 1988)\n\n\nPolarity\n\nInfluences hydrogen bonding and solvent exposure.\n\nCHAM820101 Polarizability (Charton-Charton, 1982)\nGRAR740102 Polarity (Grantham, 1974)\nRADA880108 Mean polarity (Radzicka-Wolfenden, 1988)\n\n\nCharge\n\nLocal electrostatics affect helix and beta-strand formation.\n\nFAUJ880111 Positive charge (Fauchere et al., 1988)\nFAUJ880112 Negative charge (Fauchere et al., 1988)\n\n\nFlexibility / Rigidity\n\nGlycine is flexible, proline rigid; this affects loop/corner formation.\n\nBHAR880101 Flexibility index (Bhaskaran-Ponnuswamy, 1988)\n\n\nHydrogen-bond potential\n\nAbility to donate/accept H-bonds stabilizes helices and strands.\n\nCHAM830107 Charge transfer parameter (Charton-Charton, 1983)\nFAUJ880109 Number of hydrogen-bond donors (Fauchere et al., 1988)\n\nFollowing this preprocessing pipeline, we obtain a comprehensive tabular dataset suitable for Random Forest training. For a sliding window of size 11, each residue is represented by 11 √ó 11 = 121 features, reflecting the concatenation of 11 physico-chemical descriptors across the local sequence context. The resulting training set comprises 2,270,581 windows, with secondary structure labels distributed as 1,011,153 coils (C), 472,863 beta strands (E), and 786,565 helices (H).\n\n\nModel Training\nTo train our Random Forest classifier efficiently, we first extracted a representative subset of 200,000 windows from the training set, stratified by secondary structure labels to preserve class distributions (C: 1,011,153; E: 472,863; H: 786,565). This subset was used for rapid hyperparameter tuning, allowing systematic exploration of the number of estimators, tree depth, minimum samples per leaf, and the number of features considered at each split. Each combination of hyperparameters was evaluated on a held-out validation set using multiple metrics, including Q3 accuracy (the fraction of residues correctly classified into the three secondary structure classes H, E, and C), balanced Q3 accuracy and macro F1 score.\nAfter exhaustive grid search, the optimal parameters were identified as 200 trees, a maximum depth of 20, minimum samples per leaf of 1, and sqrt features considered at each split. With thoses hyperparameters determined, the final Random Forest was trained on the full training set and persisted to disk.\n\n\nResults and discussion\nOverall Metrics\n\n\n\nMetric\nValue\n\n\n\n\nQ3 Accuracy\n0.665\n\n\nBalanced Accuracy\n0.626\n\n\nMacro F1\n0.633\n\n\n\nClass-wise Performance\n\n\n\nClass\nPrecision\nRecall\nF1-score\nSupport\n\n\n\n\nH\n0.63\n0.68\n0.65\n3788\n\n\nE\n0.65\n0.43\n0.52\n2551\n\n\nC\n0.69\n0.77\n0.73\n5317\n\n\nMacro Avg\n0.66\n0.63\n0.63\n11656\n\n\nWeighted Avg\n0.66\n0.66\n0.66\n11656\n\n\n\nAlthough Random Forests trained on local physico-chemical features provide a biologically interpretable baseline, they are inherently limited, which directly accounts for the observed performance. These models are fundamentally local, relying on sliding windows that capture only short-range interactions between residues.\nBeta strands are fundamentally non-local structures, as their formation often involves interactions between residues that are distant in the primary sequence, unlike alpha helices, which are largely local and can be stabilized by as few as five consecutive residues through hydrogen bonding. Moreover, a given amino acid sequence can adopt a stable alpha helix in isolation but form a beta strand in the context of long-range interactions with other distant residues. This distinction explains why the model predicts helices and coils relatively well but struggles with beta strands. As Baldwin and Rose note, ‚Äúthe accuracy of secondary structure predictions is only 65‚Äì70%. This fact is usually interpreted to imply that the remaining variance of 30‚Äì35% is caused by non-local interactions‚Äù (Baldwin & Rose, 2013), which is consistent with the ~66% Q3 accuracy achieved by our Random Forest.\n\nAnother limitation stems from the residue-level granularity of predictions, which can fragment continuous secondary structure elements. Helices and beta strands span multiple residues, but predicting each residue independently often produces biologically inconsistent patterns. For instance, a target sequence : [‚ÄòC‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô] may be predicted as : [‚ÄòC‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòH‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòE‚Äô,‚ÄòC‚Äô,‚ÄòC‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô,‚ÄòE‚Äô] resulting in short, fragmented structures that do not reflect realistic motifs. This is particularly problematic for alpha helices, which require a minimum of five consecutive residues to form a stable helix. If only three consecutive residues are predicted as helix, it is unclear how to interpret them biologically: should they be converted to coil, extended to form a full helix, or treated as part of a beta strand? Such inconsistencies highlight the limitations of purely residue-level, local prediction approaches.\nFinally, the Random Forest model itself has limitations: it treats features as independent and is invariant to permutations, so it cannot exploit sequential correlations or detect motifs across neighboring residues within the window as a CNN or transformer-based model could. Additionally, the input features‚Äîphysico-chemical descriptors‚Äîrepresent only local properties and is a redundant information. Taken together, these factors naturally limit the model‚Äôs performance, making a plateau around 65‚Äì66% accuracy expected for purely local, feature-based methods."
  },
  {
    "objectID": "projets/Project_protein_web.html#evolutionary-information-and-convolutional-models-1d-cnn-pssm",
    "href": "projets/Project_protein_web.html#evolutionary-information-and-convolutional-models-1d-cnn-pssm",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Evolutionary information and convolutional models (1D CNN + PSSM)",
    "text": "Evolutionary information and convolutional models (1D CNN + PSSM)\nThis subsection introduces evolutionary descriptors, especially Position-Specific Scoring Matrices (PSSMs) derived from multiple sequence alignments, widely used in secondary-structure predictors.\n\nThe biological input : PSSM\nA Position-Specific Scoring Matrix (PSSM) provides an evolutionary profile for each residue position within a protein sequence. For each position \\(i\\) and amino acid \\(a\\), the PSSM encodes a substitution probability or score \\(P(a \\mid i)\\) derived from a Multiple Sequence Alignment (MSA). An MSA is a matrix-like arrangement of homologous sequences where each row represents a sequence and columns align residues considered evolutionarily equivalent.\nSuppose we have the following MSA for a protein segment of length 5:\n\n\n\nSequence\n1\n2\n3\n4\n5\n\n\n\n\nS1\nA\nL\nK\nA\nV\n\n\nS2\nA\nL\nR\nA\nV\n\n\nS3\nA\nI\nK\nA\nI\n\n\nS4\nA\nL\nK\nA\nV\n\n\n\nFirst, the multiple sequence alignment is scanned column by column to count how many times each amino acid occurs at position \\(i\\).\n\n\n\nPosition\nA\nL\nI\nK\nR\nV\n\n\n\n\n1\n4\n0\n0\n0\n0\n0\n\n\n2\n0\n3\n1\n0\n0\n0\n\n\n3\n0\n0\n0\n3\n1\n0\n\n\n4\n4\n0\n0\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n0\n3\n\n\n\nNext, the counts are converted into positional probabilities \\(P(a \\mid i)\\) by dividing by the number of sequences in the MSA. For example, at position 2, \\(P(L \\mid 2)=3/4\\) and \\(P(I \\mid 2)=1/4\\). These probabilities indicate how frequently each amino acid occurs at a given evolutionary position.\nFinally, the positional probabilities are compared to the background frequency \\(P(a)\\) of each amino acid in a large non-redundant protein database using the log-odds formula: \\[PSSM(a, i) = \\log \\frac{P(a \\mid i)}{P(a)}\\]\n\n\n\n\n\n\n\n\n\n\n\nAA ‚Üì / Pos ‚Üí\n1\n2\n3\n4\n5\n\n\n\n\nA\nlog(4/4 / 0.05)= log(20)= 3.00\n0\n0\n3.00\n0\n\n\nL\n0\nlog(3/4 / 0.05)=2.30\n0\n0\n0\n\n\nI\n0\nlog(1/4 / 0.05)=1.61\n0\n0\n1.61\n\n\nK\n0\n0\n2.71\n0\n0\n\n\nR\n0\n0\n1.61\n0\n0\n\n\nV\n0\n0\n0\n0\n2.30\n\n\n\nIf \\(P(a\\mid i)\\) is higher than the background, the score is positive, indicating evolutionary enrichment of that amino acid at that position. If it is lower, the score is negative. In the example, position 1 is strongly enriched for A because \\(P(A\\mid1)=1.0\\) is much larger than the background probability \\(P(A)=0.05\\), giving a high log-odds value of about 3.00. In other words, a high positive PSSM score at position \\(i\\) for amino acid \\(a\\) indicates that \\(a\\) occurs more often than expected by chance at that position among homologous sequences.\nThe PSSMs used in this project are derived from the ProteinNet dataset, where MSAs were generated using JackHMMER and weighted with Henikoff position-based weights [18] to reduce the influence of closely related sequences.\nFor secondary structure prediction, PSSMs introduce a strong biological signal that is not present in raw amino acid sequences or physico-chemical descriptors. Evolutionarily conserved positions tend to correspond to structurally or functionally important residues, while positions tolerant to substitution often lie in loops or solvent-exposed regions.\n\nData Preprocessing for the 1D CNN Model\nTo leverage the sequential nature of proteins, the 1D convolutional neural network (CNN) operates on full-length sequences rather than fixed local windows. Unlike the Random Forest, which relies on sliding windows to capture short-range context, the CNN requires a consistent tensor shape across all proteins while preserving the residue order.\nEach amino acid is represented by a 41-dimensional feature vector. This vector is constructed by concatenating the 21-dimensional One-Hot Encoding (OHE) (20 standard residues plus a dedicated padding token) and the 20-dimensional PSSM profile [19]. Protein sequences vary in length, so both inputs and labels are padded to the maximum sequence length in the dataset. As a result, each protein is converted into an input tensor of shape \\((L_{\\text{max}}, 41)\\) and a label tensor of shape \\((L_{\\text{max}})\\), with padded positions assigned a special index to be ignored during loss computation.\nDuring training, input tensors are transposed to \\((\\text{Batch}, 41, L_{\\text{max}})\\), the format expected by PyTorch‚Äôs Conv1d layers.\n\n\n1D CNN Architecture\nThe network consists of three consecutive 1D convolutional layers with multi-scale kernel sizes (3, 7, and 11) [19] corresponding to different lengths of local structural motifs, progressively increasing the number of filters from 128 to 256 and then 512. Dropout layers (rate 0.5) follow the first two convolutions to mitigate overfitting. The final classification layer is a position-wise 1D convolution with kernel size one, producing logits over the three secondary structure classes (H, E, C) for each residue. Padding is applied to maintain the original sequence length throughout all convolutional layers.\nThis architecture was chosen to balance biological interpretability and computational efficiency: the use of multiple kernel sizes (3, 7, 11) allows the model to simultaneously reflect the scale of short-range interactions and analyze longer contextual segments (up to 11 residues), crucial for defining Œ≤-strands. The progressive increase in filter number allows hierarchical feature extraction, and the absence of pooling preserves positional information critical for residue-level classification. By combining sequence order and evolutionary profiles through PSSMs, the network can leverage both local residue context and evolutionary conservation to improve secondary structure prediction accuracy.\n\n\nResults and discussion\nOverall Metrics\n\n\n\nMetric\nValue\n\n\n\n\nQ3 Accuracy\n82.56%\n\n\nBalanced Accuracy\n83%\n\n\nMacro F1\n83%%\n\n\n\nClass-wise Performance\n\n\n\nClass\nPrecision\nRecall\nF1-score\nSupport\n\n\n\n\nH\n0.85\n0.86\n0.85\n3788\n\n\nE\n0.83\n0.77\n0.80\n2551\n\n\nC\n0.81\n0.83\n0.82\n5317\n\n\nMacro Avg\n0.83\n0.82\n0.82\n11656\n\n\nWeighted Avg\n0.83\n0.83\n0.83\n11656\n\n\n\nCNNs apply learnable filters that slide along the sequence, sharing weights across positions and exploiting translational invariance (or equivariance). This yields a stronger ability to learn local sequence motifs and conserved patterns than Random Forests. However, CNNs remain inherently local. Although the multi-scale kernels (3, 7, 11) widen the receptive fields significantly, PSSMs themselves carry position-specific but non-contextual information, so true long-range effects (interactions between residues far apart in the sequence) are still not represented explicitly.\nAdditionally, PSSMs derived from multiple sequence alignments (MSAs) represent aggregated evolutionary information at each position, but they do not implicitly encode co-evolution between residues. That is, correlations between mutations of different residues‚Äîwhich often reflect spatial contacts in the 3D structure‚Äîare lost in the positional averaging of PSSMs."
  },
  {
    "objectID": "projets/Project_protein_web.html#protein-secondary-structure-prediction-with-protbert",
    "href": "projets/Project_protein_web.html#protein-secondary-structure-prediction-with-protbert",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Protein Secondary Structure Prediction with ProtBERT",
    "text": "Protein Secondary Structure Prediction with ProtBERT\nIn this part, we leveraged ProtBERT, a deep language model for protein sequences, to predict residue-level secondary structure (H/E/C). ProtBERT is inspired by BERT from natural language processing and is pretrained on over 100 million non-redundant protein sequences from UniRef90 using a dual-task self-supervised approach:\n\nMasked Language Modeling (MLM): random amino acids are masked and reconstructed.\n\nGene Ontology (GO) annotation prediction: the model predicts functional annotations from partial sequences.\n\nProtBERT embeddings capture both local sequence patterns and global functional context, providing 1024-dimensional vectors per residue. These embeddings encode physicochemical, evolutionary, and functional information, offering a rich starting point for downstream tasks such as secondary structure prediction.\n\nEmbedding Generation Pipeline\n\nEach protein sequence is tokenized at the residue level and passed through ProtBERT.\n\nEach residue is mapped to a 1024-dimensional embedding.\n\nEmbeddings are saved as .npy files per protein, and corresponding secondary structure labels are stored as integer vectors.\n\nDuring training, sequences are padded to form batches, and padding positions are masked during loss computation.\n\n\n\nTransformer-based Classifier\nTo adapt ProtBERT embeddings for secondary structure prediction, we use a lightweight Transformer architecture. The embeddings are first projected to a lower-dimensional space, then processed through the Transformer to capture relationships between residues, and finally passed through a linear classifier to produce per-residue predictions for H/E/C classes. This approach allows the model to combine ProtBERT‚Äôs rich contextual information with sequence-level dependencies."
  },
  {
    "objectID": "projets/Project_protein_web.html#results-and-discussion-2",
    "href": "projets/Project_protein_web.html#results-and-discussion-2",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nThe ProtBERT-based Transformer produces the following overall performance:\n\n\n\nMetric\nValue\n\n\n\n\nAccuracy\n0.8223\n\n\nBalanced Accuracy\n0.8149\n\n\nMacro F1\n0.8156\n\n\n\nClass-wise performance:\n\n\n\nClass\nPrecision\nRecall\nF1-score\nSupport\n\n\n\n\nH\n0.84\n0.84\n0.84\n3788\n\n\nE\n0.78\n0.77\n0.78\n2551\n\n\nC\n0.83\n0.83\n0.83\n5317\n\n\nMacro Avg\n0.82\n0.81\n0.82\n11656\n\n\nWeighted Avg\n0.82\n0.82\n0.82\n11656\n\n\n\nClassical PSSM-based predictors report similar metrics (Q3 accuracy ~82.5%, balanced accuracy ~83%, macro F1 ~83%). ProtBERT embeddings encode residue-level and long-range sequence information, including patterns learned across millions of proteins, which capture implicit evolutionary and structural signals."
  },
  {
    "objectID": "projets/Project_protein_web.html#references",
    "href": "projets/Project_protein_web.html#references",
    "title": "Pr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es",
    "section": "References",
    "text": "References\n\nIsmi, D. P., Pulungan, R., & Afiahayati. Deep learning for protein secondary structure prediction: Pre and post-AlphaFold. Computational and Structural Biotechnology Journal 20, 6271‚Äì6286 (2022).\nBreda, A. et al.¬†Protein structure, modelling and applications. Bioinformatics in tropical disease research: a practical and case-study approach. (eds.¬†Gruber, A. et al.) 137‚Äì170 (National Center for Biotechnology Information (US), 2008).\nBranden, C. I. & Tooze, J. Introduction to Protein Structure. (Garland Science, 2012).\nAnfinsen, C. B. Principles that Govern the Folding of Protein Chains. Science 181, 223‚Äì230 (1973).\nZwanzig, R., Szabo, A. & Bagchi, B. Levinthal‚Äôs paradox. Proc. Natl. Acad. Sci. U.S.A. 89, 20‚Äì22 (1992).\nAlQuraishi, M. ProteinNet: a standardized data set for machine learning of protein structure. BMC Bioinformatics 20, 311 (2019).\nFinn, R. D. et al.¬†HMMER web server: 2015 update. Nucleic Acids Res 43, W30‚ÄìW38 (2015).\nKryshtafovych, A., Schwede, T., Topf, M., Fidelis, K. & Moult, J. Critical assessment of methods of protein structure prediction (CASP)‚ÄîRound XIII. Proteins 87, 1011‚Äì1020 (2019).\nArgos, P., Rao, J. K. M. & Hargrave, P. A. Structural Prediction of Membrane‚ÄêBound Proteins. European Journal of Biochemistry 128, 565‚Äì575 (1982).\nBigelow, C. C. On the average hydrophobicity of proteins and the relation between it and protein structure. Journal of Theoretical Biology 16, 187‚Äì211 (1967).\nFauch√®re, J., Charton, M., Kier, L. B., Verloop, A. & Pliska, V. Amino acid side chain parameters for correlation studies in biology and pharmacology. International Journal of Peptide and Protein Research 32, 269‚Äì278 (1988).\nCharton, M. & Charton, B. I. The structural dependence of amino acid hydrophobicity parameters. Journal of Theoretical Biology 99, 629‚Äì644 (1982).\nGrantham, R. Amino Acid Difference Formula to Help Explain Protein Evolution. Science 185, 862‚Äì864 (1974).\nRadzicka, A., Pedersen, L. & Wolfenden, R. Influences of solvent water on protein folding: free energies of solvation of cis and trans peptides are nearly identical. Biochemistry 27, 4538‚Äì4541 (1988).\nBhaskaran, R. & Ponnuswamy, P. K. Positional flexibilities of amino acid residues in globular proteins. International Journal of Peptide and Protein Research 32, 241‚Äì255 (1988).\nCharton, M. & Charton, B. I. The dependence of the Chou-Fasman parameters on amino acid side chain structure. Journal of Theoretical Biology 102, 121‚Äì134 (1983).\nBaldwin, R. L. & Rose, G. D. Is protein folding hierarchic? I. Local structure and peptide folding. Trends in Biochemical Sciences 24, 26‚Äì33 (1999).\nHenikoff, S. & Henikoff, J. G. Position-based sequence weights. Journal of Molecular Biology 243, 574‚Äì578 (1994).\nLu, Y. Protein Secondary Structure Prediction Using Convolutional Bidirectional GRU. JMR 16, 11 (2024)."
  },
  {
    "objectID": "projets/Template_presentation_feuille.html",
    "href": "projets/Template_presentation_feuille.html",
    "title": "Entra√Æner un mod√®le Vision Transformers pour la classification d‚Äôimages",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_feuille.html#lien-vers-le-code-github",
    "href": "projets/Template_presentation_feuille.html#lien-vers-le-code-github",
    "title": "Entra√Æner un mod√®le Vision Transformers pour la classification d‚Äôimages",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_feuille.html#lien-vers-les-slides",
    "href": "projets/Template_presentation_feuille.html#lien-vers-les-slides",
    "title": "Entra√Æner un mod√®le Vision Transformers pour la classification d‚Äôimages",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/Template_presentation_feuille.html#description-projet",
    "href": "projets/Template_presentation_feuille.html#description-projet",
    "title": "Entra√Æner un mod√®le Vision Transformers pour la classification d‚Äôimages",
    "section": "description Projet",
    "text": "description Projet\nUtilisation d‚Äôun Vision Transformers pour determiner si des feuilles sont malades ou non et leur maladie."
  },
  {
    "objectID": "projets/Projet_DeepMeow.html",
    "href": "projets/Projet_DeepMeow.html",
    "title": "Deep Meow",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Projet_DeepMeow.html#lien-vers-le-code-github",
    "href": "projets/Projet_DeepMeow.html#lien-vers-le-code-github",
    "title": "Deep Meow",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Projet_DeepMeow.html#lien-vers-les-slides",
    "href": "projets/Projet_DeepMeow.html#lien-vers-les-slides",
    "title": "Deep Meow",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/Projet_DeepMeow.html#contexte",
    "href": "projets/Projet_DeepMeow.html#contexte",
    "title": "Deep Meow",
    "section": "Contexte :",
    "text": "Contexte :\nLa labellisation d‚Äôaudio est une m√©thode fortement utilis√©e en machine learning, en agronomie, en sociologie, musique, etc‚Ä¶ Nous proposons donc de pr√©senter une d√©marche de traitement de signaux audio et de labellisation de ces signaux."
  },
  {
    "objectID": "projets/Projet_DeepMeow.html#notre-jeu-de-donn√©es",
    "href": "projets/Projet_DeepMeow.html#notre-jeu-de-donn√©es",
    "title": "Deep Meow",
    "section": "Notre jeu de donn√©es :",
    "text": "Notre jeu de donn√©es :\nNotre exemple sera la labellisation d‚Äôaudio de chat. Le jeu de donn√©es comprend 440 audios au format .WAV. Chaque audio √©tant un miaulement de chat. Les chats sont enregistr√©s dans diff√©rentes situations (En train d‚Äô√™tre bross√©, attendant de la nourriture, isolement dans un espace inconnu). Le but ici est de d√©terminer le contexte d‚Äô√©mission d‚Äôun miaulement."
  },
  {
    "objectID": "projets/Projet_DeepMeow.html#points-abord√©s",
    "href": "projets/Projet_DeepMeow.html#points-abord√©s",
    "title": "Deep Meow",
    "section": "Points abord√©s :",
    "text": "Points abord√©s :\n\nPreprocessing sur des donn√©es audios\nExtraction de features via un r√©seau de neurones et des couches convolutionnelles"
  },
  {
    "objectID": "projets/projets_val.html",
    "href": "projets/projets_val.html",
    "title": "Optimisation de l‚ÄôIrrigation des Cultures de Tomates par Apprentissage par Renforcement : Application de l‚ÄôAlgorithme Proximal Policy Optimization (PPO)",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/projets_val.html#lien-vers-le-code-github",
    "href": "projets/projets_val.html#lien-vers-le-code-github",
    "title": "Optimisation de l‚ÄôIrrigation des Cultures de Tomates par Apprentissage par Renforcement : Application de l‚ÄôAlgorithme Proximal Policy Optimization (PPO)",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/projets_val.html#lien-vers-les-slides",
    "href": "projets/projets_val.html#lien-vers-les-slides",
    "title": "Optimisation de l‚ÄôIrrigation des Cultures de Tomates par Apprentissage par Renforcement : Application de l‚ÄôAlgorithme Proximal Policy Optimization (PPO)",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/projets_val.html#description-projet",
    "href": "projets/projets_val.html#description-projet",
    "title": "Optimisation de l‚ÄôIrrigation des Cultures de Tomates par Apprentissage par Renforcement : Application de l‚ÄôAlgorithme Proximal Policy Optimization (PPO)",
    "section": "description Projet",
    "text": "description Projet\nCe travail applique l‚Äôalgorithme Proximal Policy Optimization (PPO) issu du framework de l‚Äôapprentissage par renforcement (RL) √† l‚Äôoptimisation de l‚Äôirrigation des cultures de tomates, en exploitant des donn√©es agronomiques et climatiques. L‚Äôagent apprend √† maximiser le rendement tout en minimisant le gaspillage d‚Äôeau, validant l‚Äôefficacit√© du RL pour une gestion adaptative des ressources en agriculture."
  },
  {
    "objectID": "projets/Template_presentation_projets_Tom_Jules.html",
    "href": "projets/Template_presentation_projets_Tom_Jules.html",
    "title": "A deep CNN architecture : the Resnet - Application to image classification of pathogenous mycosis",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projets_Tom_Jules.html#lien-vers-le-code-github",
    "href": "projets/Template_presentation_projets_Tom_Jules.html#lien-vers-le-code-github",
    "title": "A deep CNN architecture : the Resnet - Application to image classification of pathogenous mycosis",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projets_Tom_Jules.html#lien-vers-les-slides",
    "href": "projets/Template_presentation_projets_Tom_Jules.html#lien-vers-les-slides",
    "title": "A deep CNN architecture : the Resnet - Application to image classification of pathogenous mycosis",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/Template_presentation_projets_Tom_Jules.html#description-projet",
    "href": "projets/Template_presentation_projets_Tom_Jules.html#description-projet",
    "title": "A deep CNN architecture : the Resnet - Application to image classification of pathogenous mycosis",
    "section": "description Projet",
    "text": "description Projet\nThis project explains the architecture of a ResNet and compares it to a traditional CNN in the context of classifying microscopic images of pathogenic fungi. We explain how skip connections enable ResNet models to preserve information and ease gradient flow, addressing limitations of deeper conventional CNNs. Both architectures were tested on the fungal image dataset to evaluate differences in learning efficiency and classification performance."
  },
  {
    "objectID": "projets/Template_presentation_projet_data_augmentation.html",
    "href": "projets/Template_presentation_projet_data_augmentation.html",
    "title": "Data augmentation appliqu√©e √† des images",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projet_data_augmentation.html#lien-vers-le-code-github",
    "href": "projets/Template_presentation_projet_data_augmentation.html#lien-vers-le-code-github",
    "title": "Data augmentation appliqu√©e √† des images",
    "section": "",
    "text": "Github"
  },
  {
    "objectID": "projets/Template_presentation_projet_data_augmentation.html#lien-vers-les-slides",
    "href": "projets/Template_presentation_projet_data_augmentation.html#lien-vers-les-slides",
    "title": "Data augmentation appliqu√©e √† des images",
    "section": "Lien vers les slides",
    "text": "Lien vers les slides\n\nSlides"
  },
  {
    "objectID": "projets/Template_presentation_projet_data_augmentation.html#description-projet",
    "href": "projets/Template_presentation_projet_data_augmentation.html#description-projet",
    "title": "Data augmentation appliqu√©e √† des images",
    "section": "description Projet",
    "text": "description Projet\nProjet de classification d‚Äôimages bas√© sur un CNN entra√Æn√© sur le dataset Animals10. Mise en place d‚Äôun pipeline complet : pr√©paration des donn√©es, data augmentation et entra√Ænement du mod√®le avec PyTorch. √âvaluation des performances via pr√©cision, matrice de confusion et courbes d‚Äôapprentissage."
  },
  {
    "objectID": "index.html#edition-2025-ecole-dautomne",
    "href": "index.html#edition-2025-ecole-dautomne",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Edition 2025 : Ecole d‚Äôautomne",
    "text": "Edition 2025 : Ecole d‚Äôautomne\nPour cette 3√®me √©dition, la conf√©rence prend le format d‚Äôune √©cole d‚Äôautomne.\nOrganis√©e par les √©tudiants de Master 2 et les √©l√®ves ing√©nieurs en sp√©cialisation Sciences des Donn√©es, cette √©cole d‚Äôautomne annuelle est un rendez-vous incontournable !\nElle s‚Äôinscrit dans le cadre de l‚Äô√©valuation des modules Machine Learning et Computer Science for Big Data Approaches, et permet aux √©tudiants de restituer leurs projets sous forme de mini‚Äëcours.\nC‚Äôest l‚Äôoccasion de mettre √† l‚Äôhonneur les travaux des √©tudiants et de d√©couvrir des approches modernes de Machine Learning et de Deep Learning appliqu√©es aux probl√©matiques des sciences du vivant.\n\nTh√®me 2025\nPour cette 3·µâ √©dition, nous explorons les apports du Machine Learning √† la compr√©hension, la mod√©lisation et la pr√©diction dans le champ du vivant : agriculture, environnement, √©cologie, sant√© ou biotechnologies.\nLes √©tudiants pr√©senteront des projets originaux illustrant la diversit√© des approches possibles et l‚Äôimpact concret de telles applications.\n\n\nProgramme de la journ√©e\nLe programme complet, incluant les horaires de passages et les slides de chaque groupe, est consultable dans la rubrique Programme.\nTous les travaux des √©tudiants sont centralis√©s dans un d√©p√¥t GitHub. Chaque projet comprend le code, un document de synth√®se et les diapositives de pr√©sentation, permettant de consulter, reproduire et approfondir les travaux pr√©sent√©s durant cette √©dition de l‚Äô√©cole d‚Äôautomne."
  },
  {
    "objectID": "index.html#inscription",
    "href": "index.html#inscription",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "Inscription",
    "text": "Inscription\nNous vous invitons √† vous inscrire en remplissant le formulaire suivant :"
  },
  {
    "objectID": "index.html#informations-pratiques",
    "href": "index.html#informations-pratiques",
    "title": "3·µâ √©dition de la conf√©rence de Machine Learning en Sciences du Vivant",
    "section": "üìç Informations pratiques",
    "text": "üìç Informations pratiques\nD√©tails d‚Äôacc√®s et plan disponibles dans la page Infos pratiques.\nLieu : Salle 5√®me ann√©e du B√¢timent 24 de l‚ÄôInstitut Agro Rennes-Angers (Campus de Rennes)\nHoraires : Vendredi 21 novembre 2025 entre 13h30 et 16h30."
  },
  {
    "objectID": "programme.html",
    "href": "programme.html",
    "title": "Programme",
    "section": "",
    "text": "Order By\n       Default\n         \n          Description\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nA deep CNN architecture : the Resnet - Application to image classification of pathogenous mycosis\n\n\n13h50‚Äì14h10\n\n\nWhat is a ResNet and how this architecture permited to train deeper network\n\n\n\n\n\n\nNov 21, 2025\n\n\nMathieu Jules, Norroy Tom\n\n\n\n\n\n\n  \n\n\n\n\nApport d‚Äôun mod√®le Bay√©sien lors de l‚Äôutilisation de r√©seaux de neuronnes pour la classification d‚Äôimages\n\n\n14h10‚Äì14h30\n\n\nComparaison de 2 ‚Äòversions‚Äô du mod√®le AlexNet pour la classification d‚Äôimages, exemple sur un jeu d‚Äôimages d‚Äôinsectes\n\n\n\n\n\n\nNov 21, 2025\n\n\nRoattino Thibault, Belle Louis, Rosa Mat√©o\n\n\n\n\n\n\n  \n\n\n\n\nClassification d‚Äôimages - une comparaison entre R et Python\n\n\n14h30‚Äì14h50\n\n\nComparaison m√©thologiques de l‚Äôutilisation de Keras sur R et Python et Pytorch sur Python dans le cadre d‚Äôune classification d‚Äôimages √† 2 classes\n\n\n\n\n\n\nNov 21, 2025\n\n\nCl√©ment Melina, Le Moan Delalande Riwal, Mathieu Anna\n\n\n\n\n\n\n  \n\n\n\n\nData augmentation appliqu√©e √† des images\n\n\n14h50‚Äì15h10\n\n\nMod√®le CNN avec data augmentation pour classifier des images d‚Äôanimaux\n\n\n\n\n\n\nNov 21, 2025\n\n\nEL HILALI Nassima, MONTIER Ma√©va, TRAORE Fabrice\n\n\n\n\n\n\n  \n\n\n\n\nDeep Meow\n\n\n15h10‚Äì15h30\n\n\nLabellisation de signaux audio de miaulement de chat\n\n\n\n\n\n\nNov 21, 2025\n\n\nAntier Augustin, Causeur L√©na, Prusiewicz-Blondin Louis\n\n\n\n\n\n\n  \n\n\n\n\nD√©tection et segmentation automatique des m√©tastases c√©r√©brales sur IRM avec U-Net et SAM\n\n\n13h30‚Äì13h50\n\n\nPr√©sentation sur l‚Äôimagerie m√©dicale et l‚ÄôIA : √† partir de 156 IRM c√©r√©brales, nous d√©veloppons des m√©thodes automatis√©es pour d√©tecter et segmenter les m√©tastases, rendant le diagnostic plus rapide et fiable.\n\n\n\n\n\n\nNov 21, 2025\n\n\nMarine Camus, Audrey Lapie, L√©a Desbats\n\n\n\n\n\n\n  \n\n\n\n\nEntra√Æner un mod√®le Vision Transformers pour la classification d‚Äôimages\n\n\n15h50‚Äì16h10\n\n\nUtilisation d‚Äôun Vision Transformers pour determiner si des feuilles sont malades ou non et leur maladie\n\n\n\n\n\n\nNov 21, 2025\n\n\nFraysse Emilie, Gouhier Erwan, Delage de Luget Sixtine\n\n\n\n\n\n\n  \n\n\n\n\nOptimisation de l‚ÄôIrrigation des Cultures de Tomates par Apprentissage par Renforcement : Application de l‚ÄôAlgorithme Proximal Policy Optimization (PPO)\n\n\n15h30‚Äì15h50\n\n\nNotre projet vise √† optimiser l‚Äôirrigation de plants de tomates gr√¢ce √† un agent d‚Äôapprentissage par renforcement.\n\n\n\n\n\n\nNov 21, 2025\n\n\nLef√®vre Vadim, Naux Emilie, Julliard Valentine\n\n\n\n\n\n\n  \n\n\n\n\nPr√©dire la structure secondaire des prot√©ines : du signal biologique aux approches d‚Äôapprentissage avanc√©es\n\n\n16h10‚Äì16h30\n\n\nPr√©diction de la structure secondaire √† partir de la s√©quence, en √©valuant l‚Äôimpact de diff√©rents descripteurs biologiques et des m√©thodes Random Forest, CNN et mod√®les de NLP sp√©cialis√©s du type BERT.\n\n\n\n\n\n\nNov 21, 2025\n\n\nBOULET Faustine, BEAUFILS Constance, PLACIER Mo√Øse\n\n\n\n\n\n\nNo matching items"
  }
]