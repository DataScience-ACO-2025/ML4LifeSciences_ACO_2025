{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c0dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Début de l'entraînement pour 1000 épisodes...\n",
      "Épisode 1/1000 terminé. Récompense: -146.38\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.64e+03 |\n",
      "|    ep_rew_mean     | -146     |\n",
      "| time/              |          |\n",
      "|    fps             | 4336     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.64e+03      |\n",
      "|    ep_rew_mean          | -146          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2173          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0092901345  |\n",
      "|    clip_fraction        | 0.0382        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.38         |\n",
      "|    explained_variance   | -0.0022568703 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.75          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0094       |\n",
      "|    value_loss           | 10.4          |\n",
      "-------------------------------------------\n",
      "Épisode 2/1000 terminé. Récompense: -65.17\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.31e+03     |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2092         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010554468  |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.014865756 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.41         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    value_loss           | 10.7         |\n",
      "------------------------------------------\n",
      "Épisode 3/1000 terminé. Récompense: 119.99\n",
      "Épisode 4/1000 terminé. Récompense: 44.17\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | -11.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2104        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009130463 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.10649854  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 6.07        |\n",
      "-----------------------------------------\n",
      "Épisode 5/1000 terminé. Récompense: 72.04\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 4.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2113        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011798339 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.036140084 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 4.57        |\n",
      "-----------------------------------------\n",
      "Épisode 6/1000 terminé. Récompense: 187.74\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | 35.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2118        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011268522 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.050763905 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.57        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 4.9         |\n",
      "-----------------------------------------\n",
      "Épisode 7/1000 terminé. Récompense: 540.04\n",
      "Épisode 8/1000 terminé. Récompense: 57.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2122        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010839585 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.15440989  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 6.79        |\n",
      "-----------------------------------------\n",
      "Épisode 9/1000 terminé. Récompense: 267.34\n",
      "Épisode 10/1000 terminé. Récompense: 159.31\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 124         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2124        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008778527 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.02902633  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.28        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 5.3         |\n",
      "-----------------------------------------\n",
      "Épisode 11/1000 terminé. Récompense: 482.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 156          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055276835 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.03903067   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    value_loss           | 4.67         |\n",
      "------------------------------------------\n",
      "Épisode 12/1000 terminé. Récompense: 529.67\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | 187          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071522654 |\n",
      "|    clip_fraction        | 0.0583       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.034918547  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 5.48         |\n",
      "------------------------------------------\n",
      "Épisode 13/1000 terminé. Récompense: 654.36\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00643376  |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.969      |\n",
      "|    explained_variance   | 0.025869966 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 4.23        |\n",
      "-----------------------------------------\n",
      "Épisode 14/1000 terminé. Récompense: 582.55\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | 249          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070215883 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0.03415823   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.773        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 4.35         |\n",
      "------------------------------------------\n",
      "Épisode 15/1000 terminé. Récompense: 769.60\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | 284          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061098207 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.885       |\n",
      "|    explained_variance   | 0.026111007  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.13         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00723     |\n",
      "|    value_loss           | 4.46         |\n",
      "------------------------------------------\n",
      "Épisode 16/1000 terminé. Récompense: 840.32\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.78e+03     |\n",
      "|    ep_rew_mean          | 318          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030669435 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.839       |\n",
      "|    explained_variance   | 0.038338065  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.709        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    value_loss           | 4.31         |\n",
      "------------------------------------------\n",
      "Épisode 17/1000 terminé. Récompense: 310.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | 318          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034430772 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.82        |\n",
      "|    explained_variance   | 0.046896577  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.69         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 4.21         |\n",
      "------------------------------------------\n",
      "Épisode 18/1000 terminé. Récompense: 800.34\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 345         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007335651 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.061742723 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.686       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "Épisode 19/1000 terminé. Récompense: 538.76\n",
      "Épisode 20/1000 terminé. Récompense: 180.45\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | 346         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2133        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005075355 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.052551866 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.45        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    value_loss           | 5.03        |\n",
      "-----------------------------------------\n",
      "Épisode 21/1000 terminé. Récompense: 495.66\n",
      "Épisode 22/1000 terminé. Récompense: 21.38\n",
      "Épisode 23/1000 terminé. Récompense: 86.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 327         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004668128 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.063498676 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.817       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    value_loss           | 8.01        |\n",
      "-----------------------------------------\n",
      "Épisode 24/1000 terminé. Récompense: 736.88\n",
      "Épisode 25/1000 terminé. Récompense: 354.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 345          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026389793 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.785       |\n",
      "|    explained_variance   | 0.11652279   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.13         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "Épisode 26/1000 terminé. Récompense: 993.00\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 370          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033182395 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.758       |\n",
      "|    explained_variance   | 0.26107484   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 8.54         |\n",
      "------------------------------------------\n",
      "Épisode 27/1000 terminé. Récompense: 583.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 378          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061746873 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.748       |\n",
      "|    explained_variance   | 0.25844175   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    value_loss           | 4.8          |\n",
      "------------------------------------------\n",
      "Épisode 28/1000 terminé. Récompense: 317.46\n",
      "Épisode 29/1000 terminé. Récompense: 12.66\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 363          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030736825 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.775       |\n",
      "|    explained_variance   | 0.25134033   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.389        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 5.37         |\n",
      "------------------------------------------\n",
      "Épisode 30/1000 terminé. Récompense: 840.01\n",
      "Épisode 31/1000 terminé. Récompense: 440.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 381          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041788686 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.778       |\n",
      "|    explained_variance   | 0.3734085    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.64         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 7.68         |\n",
      "------------------------------------------\n",
      "Épisode 32/1000 terminé. Récompense: 270.13\n",
      "Épisode 33/1000 terminé. Récompense: 536.67\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 382          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064575765 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.77        |\n",
      "|    explained_variance   | 0.3693471    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.53         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 8.13         |\n",
      "------------------------------------------\n",
      "Épisode 34/1000 terminé. Récompense: 438.58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 384          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033666915 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.742       |\n",
      "|    explained_variance   | 0.475815     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.01         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 7.61         |\n",
      "------------------------------------------\n",
      "Épisode 35/1000 terminé. Récompense: 823.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 396          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035486545 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.728       |\n",
      "|    explained_variance   | 0.58986735   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.79         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 4.56         |\n",
      "------------------------------------------\n",
      "Épisode 36/1000 terminé. Récompense: 780.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 407          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031241435 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.709       |\n",
      "|    explained_variance   | 0.5901223    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 4.94         |\n",
      "------------------------------------------\n",
      "Épisode 37/1000 terminé. Récompense: 995.03\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 423          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045250487 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.6694734    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.7          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00059     |\n",
      "|    value_loss           | 4.22         |\n",
      "------------------------------------------\n",
      "Épisode 38/1000 terminé. Récompense: 516.42\n",
      "Épisode 39/1000 terminé. Récompense: 361.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 424          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018357133 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.715       |\n",
      "|    explained_variance   | 0.59267235   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.52         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 4.64         |\n",
      "------------------------------------------\n",
      "Épisode 40/1000 terminé. Récompense: 496.68\n",
      "Épisode 41/1000 terminé. Récompense: 490.25\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 427         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003748295 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.705      |\n",
      "|    explained_variance   | 0.615525    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "Épisode 42/1000 terminé. Récompense: 844.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 437          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074744537 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.709       |\n",
      "|    explained_variance   | 0.6938815    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 6.49         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 437          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039723613 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.716       |\n",
      "|    explained_variance   | 0.71758306   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.72         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 4.49         |\n",
      "------------------------------------------\n",
      "Épisode 43/1000 terminé. Récompense: 1242.96\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 456          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072625326 |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.669       |\n",
      "|    explained_variance   | 0.341304     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.519        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00774     |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "Épisode 44/1000 terminé. Récompense: 955.77\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 467          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038998968 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.76167786   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.612        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 4.09         |\n",
      "------------------------------------------\n",
      "Épisode 45/1000 terminé. Récompense: 1017.55\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 479          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025844024 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.698       |\n",
      "|    explained_variance   | 0.7917061    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.903        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 3.63         |\n",
      "------------------------------------------\n",
      "Épisode 46/1000 terminé. Récompense: 327.16\n",
      "Épisode 47/1000 terminé. Récompense: 301.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 472         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2127        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003461577 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.75971407  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.642       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "Épisode 48/1000 terminé. Récompense: 991.09\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 483         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2128        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002965685 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.7990303   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000493   |\n",
      "|    value_loss           | 5.95        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 483          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050905533 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.691       |\n",
      "|    explained_variance   | 0.8007002    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.62         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 4.58         |\n",
      "------------------------------------------\n",
      "Épisode 49/1000 terminé. Récompense: 1218.33\n",
      "Épisode 50/1000 terminé. Récompense: 381.43\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 496         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197603 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.3130837   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.886       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 496          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018547121 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.8030908    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000453    |\n",
      "|    value_loss           | 5.69         |\n",
      "------------------------------------------\n",
      "Épisode 51/1000 terminé. Récompense: 1049.62\n",
      "Épisode 52/1000 terminé. Récompense: 768.45\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 512         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2125        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005324913 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.693      |\n",
      "|    explained_variance   | 0.8267863   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.651       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "Épisode 53/1000 terminé. Récompense: 484.87\n",
      "Épisode 54/1000 terminé. Récompense: 293.36\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2095        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002159431 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.693      |\n",
      "|    explained_variance   | 0.7325992   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.03        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    value_loss           | 5.14        |\n",
      "-----------------------------------------\n",
      "Épisode 55/1000 terminé. Récompense: 614.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 509         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2097        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002878777 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | 0.77241015  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.18        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    value_loss           | 6.13        |\n",
      "-----------------------------------------\n",
      "Épisode 56/1000 terminé. Récompense: 856.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 515          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2097         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060765324 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.683       |\n",
      "|    explained_variance   | 0.78958917   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.734        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 3.84         |\n",
      "------------------------------------------\n",
      "Épisode 57/1000 terminé. Récompense: 716.17\n",
      "Épisode 58/1000 terminé. Récompense: 228.39\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 514         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2098        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005199955 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.698      |\n",
      "|    explained_variance   | 0.7874819   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.613       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "Épisode 59/1000 terminé. Récompense: 712.47\n",
      "Épisode 60/1000 terminé. Récompense: 152.85\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 511          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2101         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040623397 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.703       |\n",
      "|    explained_variance   | 0.7970511    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.824        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 5.68         |\n",
      "------------------------------------------\n",
      "Épisode 61/1000 terminé. Récompense: 612.35\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 513         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2103        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004788484 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.82432884  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    value_loss           | 5.77        |\n",
      "-----------------------------------------\n",
      "Épisode 62/1000 terminé. Récompense: 504.31\n",
      "Épisode 63/1000 terminé. Récompense: 466.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 512          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2104         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057537565 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.631       |\n",
      "|    explained_variance   | 0.8362514    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 512         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2106        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003819676 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.87931275  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000305   |\n",
      "|    value_loss           | 4.84        |\n",
      "-----------------------------------------\n",
      "Épisode 64/1000 terminé. Récompense: 1203.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 523          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052310545 |\n",
      "|    clip_fraction        | 0.0939       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.621       |\n",
      "|    explained_variance   | 0.38288873   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.51         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "Épisode 65/1000 terminé. Récompense: 854.22\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 528         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002082634 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.8070192   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "Épisode 66/1000 terminé. Récompense: 692.24\n",
      "Épisode 67/1000 terminé. Récompense: 464.77\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 529          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032923906 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.615       |\n",
      "|    explained_variance   | 0.79474795   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "Épisode 68/1000 terminé. Récompense: 750.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 533          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018848014 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.84491324   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.585        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 5.2          |\n",
      "------------------------------------------\n",
      "Épisode 69/1000 terminé. Récompense: 538.35\n",
      "Épisode 70/1000 terminé. Récompense: 246.31\n",
      "Épisode 71/1000 terminé. Récompense: 224.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 524         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2114        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002500891 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.8462274   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.99        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.000439    |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 524          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042544496 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.85987467   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.02         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.000676    |\n",
      "|    value_loss           | 7.52         |\n",
      "------------------------------------------\n",
      "Épisode 72/1000 terminé. Récompense: 1216.63\n",
      "Épisode 73/1000 terminé. Récompense: 190.43\n",
      "Épisode 74/1000 terminé. Récompense: 104.98\n",
      "Épisode 75/1000 terminé. Récompense: 43.59\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.51e+03  |\n",
      "|    ep_rew_mean          | 517       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2117      |\n",
      "|    iterations           | 56        |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 114688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.004606  |\n",
      "|    clip_fraction        | 0.0409    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.613    |\n",
      "|    explained_variance   | 0.8123758 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.606     |\n",
      "|    n_updates            | 550       |\n",
      "|    policy_gradient_loss | -0.0049   |\n",
      "|    value_loss           | 1.59      |\n",
      "---------------------------------------\n",
      "Épisode 76/1000 terminé. Récompense: 684.35\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 519         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2119        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004342082 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.8039674   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.2         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    value_loss           | 8.56        |\n",
      "-----------------------------------------\n",
      "Épisode 77/1000 terminé. Récompense: 926.79\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 525         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2119        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005153705 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.8378788   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.908       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 3.71        |\n",
      "-----------------------------------------\n",
      "Épisode 78/1000 terminé. Récompense: 891.47\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 529          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035844957 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.8359807    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.553        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "Épisode 79/1000 terminé. Récompense: 819.63\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 533          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2122         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046240985 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.61        |\n",
      "|    explained_variance   | 0.81035376   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.643        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.000807    |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "Épisode 80/1000 terminé. Récompense: 1107.90\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 540         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2123        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009947975 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.8511368   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.25        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "Épisode 81/1000 terminé. Récompense: 1079.76\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 547          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020230103 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.8724925    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "Épisode 82/1000 terminé. Récompense: 913.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 551         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004749722 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.88523203  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "Épisode 83/1000 terminé. Récompense: 892.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 555         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2128        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004968072 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.89521885  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "Épisode 84/1000 terminé. Récompense: 753.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 558          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073218746 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.89232033   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 3.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 558          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014448784 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.9066917    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.17         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "Épisode 85/1000 terminé. Récompense: 1328.37\n",
      "Épisode 86/1000 terminé. Récompense: 437.01\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 565          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052614366 |\n",
      "|    clip_fraction        | 0.0583       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.45342708   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.693        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "Épisode 87/1000 terminé. Récompense: 545.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 565          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2122         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018394827 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.602       |\n",
      "|    explained_variance   | 0.91000295   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.784        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 4.16         |\n",
      "------------------------------------------\n",
      "Épisode 88/1000 terminé. Récompense: 753.23\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 567          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022935779 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.579       |\n",
      "|    explained_variance   | 0.89242506   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.762        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "Épisode 89/1000 terminé. Récompense: 676.15\n",
      "Épisode 90/1000 terminé. Récompense: 83.64\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 563          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020374777 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.579       |\n",
      "|    explained_variance   | 0.883777     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 3.15         |\n",
      "------------------------------------------\n",
      "Épisode 91/1000 terminé. Récompense: 1051.89\n",
      "Épisode 92/1000 terminé. Récompense: 332.60\n",
      "Épisode 93/1000 terminé. Récompense: 152.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 561          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010929783 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.9146768    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.000458    |\n",
      "|    value_loss           | 4.38         |\n",
      "------------------------------------------\n",
      "Épisode 94/1000 terminé. Récompense: 366.66\n",
      "Épisode 95/1000 terminé. Récompense: 184.02\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 555          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016470754 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.9063031    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 5.75         |\n",
      "------------------------------------------\n",
      "Épisode 96/1000 terminé. Récompense: 1027.86\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 560          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2125         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023285884 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.586       |\n",
      "|    explained_variance   | 0.9240713    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.58         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.000328    |\n",
      "|    value_loss           | 3.94         |\n",
      "------------------------------------------\n",
      "Épisode 97/1000 terminé. Récompense: 447.63\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 559          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034802633 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.88939625   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 3.11         |\n",
      "------------------------------------------\n",
      "Épisode 98/1000 terminé. Récompense: 803.31\n",
      "Épisode 99/1000 terminé. Récompense: 88.94\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | 557        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2126       |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0052381  |\n",
      "|    clip_fraction        | 0.0293     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.57      |\n",
      "|    explained_variance   | 0.90467954 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.623      |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.00326   |\n",
      "|    value_loss           | 2.87       |\n",
      "----------------------------------------\n",
      "Épisode 100/1000 terminé. Récompense: 1243.00\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 564          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033017546 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.9459599    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.000977    |\n",
      "|    value_loss           | 3.78         |\n",
      "------------------------------------------\n",
      "Épisode 101/1000 terminé. Récompense: 926.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 575          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056134257 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.9170295    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.874        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "Épisode 102/1000 terminé. Récompense: 1016.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 585          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060813557 |\n",
      "|    clip_fraction        | 0.0628       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.524       |\n",
      "|    explained_variance   | 0.9242559    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n",
      "Épisode 103/1000 terminé. Récompense: 89.48\n",
      "Épisode 104/1000 terminé. Récompense: 21.50\n",
      "Épisode 105/1000 terminé. Récompense: 789.80\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 592          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014066775 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.920537     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.000365    |\n",
      "|    value_loss           | 3.71         |\n",
      "------------------------------------------\n",
      "Épisode 106/1000 terminé. Récompense: 547.23\n",
      "Épisode 107/1000 terminé. Récompense: 62.22\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 591          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023386378 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.93378484   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | 0.000361     |\n",
      "|    value_loss           | 3.65         |\n",
      "------------------------------------------\n",
      "Épisode 108/1000 terminé. Récompense: 367.10\n",
      "Épisode 109/1000 terminé. Récompense: 629.58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 598          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037057174 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.9192815    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.25         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 4.2          |\n",
      "------------------------------------------\n",
      "Épisode 110/1000 terminé. Récompense: 782.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 604          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023423787 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.592       |\n",
      "|    explained_variance   | 0.9291926    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 3.55         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 604         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2124        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004369053 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.9297664   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.801       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "Épisode 111/1000 terminé. Récompense: 1258.84\n",
      "Épisode 112/1000 terminé. Récompense: 461.91\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 611         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2124        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005716968 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.4719867   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.467       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 611         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2125        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002406494 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 0.9564576   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.000323   |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "Épisode 113/1000 terminé. Récompense: 1278.73\n",
      "Épisode 114/1000 terminé. Récompense: 765.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 619          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068526827 |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.579       |\n",
      "|    explained_variance   | 0.66195667   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.655        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 619          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017849263 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.9501327    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 3.17         |\n",
      "------------------------------------------\n",
      "Épisode 115/1000 terminé. Récompense: 973.86\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 621          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053562084 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.66367316   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00858     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "Épisode 116/1000 terminé. Récompense: 1302.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 626          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015213919 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.96030676   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.782        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 2.3          |\n",
      "------------------------------------------\n",
      "Épisode 117/1000 terminé. Récompense: 437.34\n",
      "Épisode 118/1000 terminé. Récompense: 374.62\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 623          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034631123 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.9518471    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.881        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "Épisode 119/1000 terminé. Récompense: 807.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 625          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020940243 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.95678836   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.907        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "Épisode 120/1000 terminé. Récompense: 793.19\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031934646 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.9488768    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 2.23         |\n",
      "------------------------------------------\n",
      "Épisode 121/1000 terminé. Récompense: 1138.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031394595 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.9512667    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.97         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "Épisode 122/1000 terminé. Récompense: 894.01\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 647         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003089024 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.941079    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "Épisode 123/1000 terminé. Récompense: 741.39\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 653         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004022249 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.9432039   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "Épisode 124/1000 terminé. Récompense: 974.09\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 655         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2132        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003490969 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.94312     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00096    |\n",
      "|    value_loss           | 2.3         |\n",
      "-----------------------------------------\n",
      "Épisode 125/1000 terminé. Récompense: 1083.60\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.6e+03    |\n",
      "|    ep_rew_mean          | 663        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2133       |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00242111 |\n",
      "|    clip_fraction        | 0.0287     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.573     |\n",
      "|    explained_variance   | 0.9415366  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.0022    |\n",
      "|    value_loss           | 2.29       |\n",
      "----------------------------------------\n",
      "Épisode 126/1000 terminé. Récompense: 1005.55\n",
      "Épisode 127/1000 terminé. Récompense: 29.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 657          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045710094 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.9365296    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 2.23         |\n",
      "------------------------------------------\n",
      "Épisode 128/1000 terminé. Récompense: 704.27\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 661         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002500182 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | 0.9418735   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "Épisode 129/1000 terminé. Récompense: 1077.62\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 672         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2136        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003247126 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | 0.935998    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 2.49        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 672          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045971125 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.92328006   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.87         |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "Épisode 130/1000 terminé. Récompense: 946.69\n",
      "Épisode 131/1000 terminé. Récompense: 151.98\n",
      "Épisode 132/1000 terminé. Récompense: 361.80\n",
      "Épisode 133/1000 terminé. Récompense: 182.98\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.6e+03   |\n",
      "|    ep_rew_mean          | 667       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2136      |\n",
      "|    iterations           | 102       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 208896    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0080743 |\n",
      "|    clip_fraction        | 0.0665    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.565    |\n",
      "|    explained_variance   | 0.8882102 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.63      |\n",
      "|    n_updates            | 1010      |\n",
      "|    policy_gradient_loss | -0.00346  |\n",
      "|    value_loss           | 1.35      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032333054 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.91851366   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.815        |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 5.38         |\n",
      "------------------------------------------\n",
      "Épisode 134/1000 terminé. Récompense: 1038.16\n",
      "Épisode 135/1000 terminé. Récompense: 682.29\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.61e+03   |\n",
      "|    ep_rew_mean          | 672        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2131       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 99         |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00429379 |\n",
      "|    clip_fraction        | 0.0511     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.572     |\n",
      "|    explained_variance   | 0.9005288  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.676      |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | -0.00277   |\n",
      "|    value_loss           | 1.54       |\n",
      "----------------------------------------\n",
      "Épisode 136/1000 terminé. Récompense: 832.90\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034947568 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | 0.89437854   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.652        |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "Épisode 137/1000 terminé. Récompense: 1080.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043874946 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.59        |\n",
      "|    explained_variance   | 0.9016728    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.986        |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.000223    |\n",
      "|    value_loss           | 2.8          |\n",
      "------------------------------------------\n",
      "Épisode 138/1000 terminé. Récompense: 180.09\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 670         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2129        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005170497 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.90626353  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "Épisode 139/1000 terminé. Récompense: 1034.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034734772 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.9042403    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "Épisode 140/1000 terminé. Récompense: 1270.98\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038371081 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.619       |\n",
      "|    explained_variance   | 0.93377      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.919        |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 2.89         |\n",
      "------------------------------------------\n",
      "Épisode 141/1000 terminé. Récompense: 970.80\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 689          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046020728 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.92155683   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    value_loss           | 2.34         |\n",
      "------------------------------------------\n",
      "Épisode 142/1000 terminé. Récompense: 754.27\n",
      "Épisode 143/1000 terminé. Récompense: 153.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033146164 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.91942734   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.619        |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 2.49         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032574143 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.9220307    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83         |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -5.78e-05    |\n",
      "|    value_loss           | 3.9          |\n",
      "------------------------------------------\n",
      "Épisode 144/1000 terminé. Récompense: 912.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063351723 |\n",
      "|    clip_fraction        | 0.0565       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.82293844   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.702        |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "Épisode 145/1000 terminé. Récompense: 968.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058697863 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.89701265   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.658        |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | 0.000489     |\n",
      "|    value_loss           | 2.02         |\n",
      "------------------------------------------\n",
      "Épisode 146/1000 terminé. Récompense: 1094.53\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.62e+03  |\n",
      "|    ep_rew_mean          | 684       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2126      |\n",
      "|    iterations           | 115       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 235520    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0024262 |\n",
      "|    clip_fraction        | 0.0263    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.562    |\n",
      "|    explained_variance   | 0.9165697 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.03      |\n",
      "|    n_updates            | 1140      |\n",
      "|    policy_gradient_loss | -0.00167  |\n",
      "|    value_loss           | 2.75      |\n",
      "---------------------------------------\n",
      "Épisode 147/1000 terminé. Récompense: 691.21\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030886072 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.909498     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.715        |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00081     |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "Épisode 148/1000 terminé. Récompense: 839.86\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028603568 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | 0.9168209    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 2.59         |\n",
      "------------------------------------------\n",
      "Épisode 149/1000 terminé. Récompense: 893.48\n",
      "Épisode 150/1000 terminé. Récompense: 472.20\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043234136 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.9258851    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000472    |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030500283 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.94619375   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.06         |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "Épisode 151/1000 terminé. Récompense: 1213.53\n",
      "Épisode 152/1000 terminé. Récompense: 495.74\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039316984 |\n",
      "|    clip_fraction        | 0.061        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.7012006    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.423        |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023825737 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.9477143    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 3.91         |\n",
      "------------------------------------------\n",
      "Épisode 153/1000 terminé. Récompense: 1357.04\n",
      "Épisode 154/1000 terminé. Récompense: 380.50\n",
      "Épisode 155/1000 terminé. Récompense: 167.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058039417 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.307293     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.722        |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "Épisode 156/1000 terminé. Récompense: 691.41\n",
      "Épisode 157/1000 terminé. Récompense: 60.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 680          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009905318 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.8881373    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22         |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | 0.000718     |\n",
      "|    value_loss           | 5.3          |\n",
      "------------------------------------------\n",
      "Épisode 158/1000 terminé. Récompense: 778.50\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2119         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016648012 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.9130485    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.02         |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    value_loss           | 4.29         |\n",
      "------------------------------------------\n",
      "Épisode 159/1000 terminé. Récompense: 958.93\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 688         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2116        |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005741223 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.9069538   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.865       |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "Épisode 160/1000 terminé. Récompense: 998.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2114         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028321277 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.9111682    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "Épisode 161/1000 terminé. Récompense: 425.65\n",
      "Épisode 162/1000 terminé. Récompense: 139.35\n",
      "Épisode 163/1000 terminé. Récompense: 300.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 689          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020739988 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.9039184    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "Épisode 164/1000 terminé. Récompense: 509.74\n",
      "Épisode 165/1000 terminé. Récompense: 213.89\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 676         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2114        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001143025 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | 0.9349932   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.000567   |\n",
      "|    value_loss           | 4.52        |\n",
      "-----------------------------------------\n",
      "Épisode 166/1000 terminé. Récompense: 1170.62\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2114         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032710908 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.9385564    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36         |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.000725    |\n",
      "|    value_loss           | 3.37         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 681         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2115        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005915609 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.94579744  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.967       |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    value_loss           | 2.78        |\n",
      "-----------------------------------------\n",
      "Épisode 167/1000 terminé. Récompense: 1324.74\n",
      "Épisode 168/1000 terminé. Récompense: 274.65\n",
      "Épisode 169/1000 terminé. Récompense: 251.21\n",
      "Épisode 170/1000 terminé. Récompense: 128.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062005576 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.20897228   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.835        |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "Épisode 171/1000 terminé. Récompense: 221.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010541892 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.9165214    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.67         |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.000298    |\n",
      "|    value_loss           | 5.84         |\n",
      "------------------------------------------\n",
      "Épisode 172/1000 terminé. Récompense: 649.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2116         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026420592 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | 0.9338751    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "Épisode 173/1000 terminé. Récompense: 972.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031851346 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.8735786    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.349        |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | 0.000235     |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "Épisode 174/1000 terminé. Récompense: 1144.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 693          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017035533 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.9435962    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.77         |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 2.52         |\n",
      "------------------------------------------\n",
      "Épisode 175/1000 terminé. Récompense: 808.76\n",
      "Épisode 176/1000 terminé. Récompense: 346.33\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037556207 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.9480843    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.651        |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 697         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2110        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003673696 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.9654786   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "Épisode 177/1000 terminé. Récompense: 1242.51\n",
      "Épisode 178/1000 terminé. Récompense: 725.52\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059409533 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.59        |\n",
      "|    explained_variance   | 0.39407504   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.657        |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 1.47         |\n",
      "------------------------------------------\n",
      "Épisode 179/1000 terminé. Récompense: 856.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2109         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020217393 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.618       |\n",
      "|    explained_variance   | 0.9387362    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77         |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 3.57         |\n",
      "------------------------------------------\n",
      "Épisode 180/1000 terminé. Récompense: 415.25\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032053841 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.9298797    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8          |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 2.51         |\n",
      "------------------------------------------\n",
      "Épisode 181/1000 terminé. Récompense: 610.87\n",
      "Épisode 182/1000 terminé. Récompense: 292.22\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2106         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033767708 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.9189185    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36         |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 2.46         |\n",
      "------------------------------------------\n",
      "Épisode 183/1000 terminé. Récompense: 802.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014694938 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.9363338    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.696        |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 3.31         |\n",
      "------------------------------------------\n",
      "Épisode 184/1000 terminé. Récompense: 1237.81\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030638562 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.9414712    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.816        |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 2.42         |\n",
      "------------------------------------------\n",
      "Épisode 185/1000 terminé. Récompense: 354.69\n",
      "Épisode 186/1000 terminé. Récompense: 178.67\n",
      "Épisode 187/1000 terminé. Récompense: 26.47\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023237746 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.579       |\n",
      "|    explained_variance   | 0.9093532    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.19         |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 2.52         |\n",
      "------------------------------------------\n",
      "Épisode 188/1000 terminé. Récompense: 1058.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2108         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011948489 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.9357376    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.000615    |\n",
      "|    value_loss           | 4.16         |\n",
      "------------------------------------------\n",
      "Épisode 189/1000 terminé. Récompense: 439.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | 669         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2108        |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004017585 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.929437    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.526       |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "Épisode 190/1000 terminé. Récompense: 1169.28\n",
      "Épisode 191/1000 terminé. Récompense: 71.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 670          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2108         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016703805 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.9292683    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.893        |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 2.34         |\n",
      "------------------------------------------\n",
      "Épisode 192/1000 terminé. Récompense: 437.86\n",
      "Épisode 193/1000 terminé. Récompense: 222.75\n",
      "Épisode 194/1000 terminé. Récompense: 228.40\n",
      "Épisode 195/1000 terminé. Récompense: 210.44\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 670          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2108         |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021393597 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.9405939    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24         |\n",
      "|    n_updates            | 1470         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "Épisode 196/1000 terminé. Récompense: 653.84\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2108         |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 305152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029261108 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.9438354    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.19         |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 4.89         |\n",
      "------------------------------------------\n",
      "Épisode 197/1000 terminé. Récompense: 949.44\n",
      "Épisode 198/1000 terminé. Récompense: 324.66\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2109         |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033334517 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.93883157   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.893        |\n",
      "|    n_updates            | 1490         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 2.27         |\n",
      "------------------------------------------\n",
      "Épisode 199/1000 terminé. Récompense: 213.30\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 668         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001977025 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 0.9459653   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.839       |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.000145   |\n",
      "|    value_loss           | 3.12        |\n",
      "-----------------------------------------\n",
      "Épisode 200/1000 terminé. Récompense: 1024.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 666          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2109         |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040164776 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.592       |\n",
      "|    explained_variance   | 0.9312573    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "Épisode 201/1000 terminé. Récompense: 1125.50\n",
      "Épisode 202/1000 terminé. Récompense: 145.38\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 659         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010166192 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.93699116  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "Épisode 203/1000 terminé. Récompense: 359.39\n",
      "Épisode 204/1000 terminé. Récompense: 318.59\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 665         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008065013 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.9466211   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "Épisode 205/1000 terminé. Récompense: 1136.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021333871 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.9523869    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16         |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2109         |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030552181 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.93688244   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.917        |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 2.48         |\n",
      "------------------------------------------\n",
      "Épisode 206/1000 terminé. Récompense: 1236.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 321536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075301332 |\n",
      "|    clip_fraction        | 0.077        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.26107335   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.417        |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | 0.000183     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 207/1000 terminé. Récompense: 1028.95\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 323584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026061097 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.90014994   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 1570         |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 2.67         |\n",
      "------------------------------------------\n",
      "Épisode 208/1000 terminé. Récompense: 567.42\n",
      "Épisode 209/1000 terminé. Récompense: 10.20\n",
      "Épisode 210/1000 terminé. Récompense: 51.17\n",
      "Épisode 211/1000 terminé. Récompense: 274.17\n",
      "Épisode 212/1000 terminé. Récompense: 0.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 659          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 325632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021973392 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.9216087    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 2.43         |\n",
      "------------------------------------------\n",
      "Épisode 213/1000 terminé. Récompense: 1114.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 657          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010508257 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.94833934   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11         |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.000472    |\n",
      "|    value_loss           | 4.5          |\n",
      "------------------------------------------\n",
      "Épisode 214/1000 terminé. Récompense: 697.05\n",
      "Épisode 215/1000 terminé. Récompense: 332.42\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 650         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2106        |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004213831 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.9265017   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "Épisode 216/1000 terminé. Récompense: 430.96\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 641         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2105        |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005461416 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.9495421   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.82        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "Épisode 217/1000 terminé. Récompense: 555.61\n",
      "Épisode 218/1000 terminé. Récompense: 758.47\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2104         |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 333824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024667103 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.94390166   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.707        |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 2.17         |\n",
      "------------------------------------------\n",
      "Épisode 219/1000 terminé. Récompense: 726.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020708062 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.9609211    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.07         |\n",
      "|    n_updates            | 1630         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "Épisode 220/1000 terminé. Récompense: 579.64\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 643         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2105        |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002741101 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.94308007  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "Épisode 221/1000 terminé. Récompense: 894.20\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 641          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037897397 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.9481844    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.858        |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "Épisode 222/1000 terminé. Récompense: 1309.52\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 645          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2104         |\n",
      "|    iterations           | 167          |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 342016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037612536 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.96707535   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.915        |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.0004      |\n",
      "|    value_loss           | 2.12         |\n",
      "------------------------------------------\n",
      "Épisode 223/1000 terminé. Récompense: 291.69\n",
      "Épisode 224/1000 terminé. Récompense: 353.25\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 634         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2105        |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005270772 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.582      |\n",
      "|    explained_variance   | 0.9483785   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2           |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.000844   |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "Épisode 225/1000 terminé. Récompense: 1035.98\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 634          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2104         |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036982289 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.9581874    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36         |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 2.82         |\n",
      "------------------------------------------\n",
      "Épisode 226/1000 terminé. Récompense: 552.43\n",
      "Épisode 227/1000 terminé. Récompense: 301.15\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 632          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019916482 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.9412926    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.775        |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    value_loss           | 2.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 632          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 350208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038974534 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.601       |\n",
      "|    explained_variance   | 0.95801866   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.000866    |\n",
      "|    value_loss           | 2.73         |\n",
      "------------------------------------------\n",
      "Épisode 228/1000 terminé. Récompense: 1103.42\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 636          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 172          |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068958425 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.58881426   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.763        |\n",
      "|    n_updates            | 1710         |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    value_loss           | 1.47         |\n",
      "------------------------------------------\n",
      "Épisode 229/1000 terminé. Récompense: 1082.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 636          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 354304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036550767 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.9254403    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 2.47         |\n",
      "------------------------------------------\n",
      "Épisode 230/1000 terminé. Récompense: 1083.10\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2105         |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019274795 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.9420552    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 1730         |\n",
      "|    policy_gradient_loss | 0.000433     |\n",
      "|    value_loss           | 2.17         |\n",
      "------------------------------------------\n",
      "Épisode 231/1000 terminé. Récompense: 504.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 641          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2106         |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022137654 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.9417149    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.778        |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | 0.000351     |\n",
      "|    value_loss           | 2.01         |\n",
      "------------------------------------------\n",
      "Épisode 232/1000 terminé. Récompense: 978.58\n",
      "Épisode 233/1000 terminé. Récompense: 669.98\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2106         |\n",
      "|    iterations           | 176          |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039703706 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.94733113   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.814        |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 2.08         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2106         |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015365004 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.95640075   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.543        |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00073     |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "Épisode 234/1000 terminé. Récompense: 1031.40\n",
      "Épisode 235/1000 terminé. Récompense: 316.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 648         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2106        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007222385 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | 0.44681078  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.571       |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "Épisode 236/1000 terminé. Récompense: 1200.11\n",
      "Épisode 237/1000 terminé. Récompense: 33.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 642          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2106         |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018473784 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.9525657    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.512        |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.000399    |\n",
      "|    value_loss           | 2.96         |\n",
      "------------------------------------------\n",
      "Épisode 238/1000 terminé. Récompense: 756.19\n",
      "Épisode 239/1000 terminé. Récompense: 71.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2106         |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009884299 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.9545399    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15         |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 638         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2107        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002093906 |\n",
      "|    clip_fraction        | 0.00503     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.95743906  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "Épisode 240/1000 terminé. Récompense: 1135.10\n",
      "Épisode 241/1000 terminé. Récompense: 430.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037159305 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.8340181    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.552        |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "Épisode 242/1000 terminé. Récompense: 467.25\n",
      "Épisode 243/1000 terminé. Récompense: 322.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 630          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2107         |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012996129 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.9443763    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 2.64         |\n",
      "------------------------------------------\n",
      "Épisode 244/1000 terminé. Récompense: 1203.74\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 633          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2108         |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016068358 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.95288444   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.794        |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 2.72         |\n",
      "------------------------------------------\n",
      "Épisode 245/1000 terminé. Récompense: 395.29\n",
      "Épisode 246/1000 terminé. Récompense: 136.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 617          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2108         |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019804349 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.94186735   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.492        |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 2.32         |\n",
      "------------------------------------------\n",
      "Épisode 247/1000 terminé. Récompense: 930.00\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 620          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2109         |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 380928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026285918 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.9573777    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77         |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "Épisode 248/1000 terminé. Récompense: 986.22\n",
      "Épisode 249/1000 terminé. Récompense: 137.38\n",
      "Épisode 250/1000 terminé. Récompense: 171.92\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 611         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002438027 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.9430362   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.853       |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "Épisode 251/1000 terminé. Récompense: 272.51\n",
      "Épisode 252/1000 terminé. Récompense: 328.60\n",
      "Épisode 253/1000 terminé. Récompense: 221.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 588         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002418425 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.542      |\n",
      "|    explained_variance   | 0.9560547   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 3.75        |\n",
      "-----------------------------------------\n",
      "Épisode 254/1000 terminé. Récompense: 1071.89\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 595         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002917274 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.9613868   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "Épisode 255/1000 terminé. Récompense: 572.60\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 599         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003641354 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.93630797  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "Épisode 256/1000 terminé. Récompense: 477.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | 597          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2109         |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 391168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018555375 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.9425015    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34         |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.000466    |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "Épisode 257/1000 terminé. Récompense: 803.33\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 605         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2110        |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003108847 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.9401724   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "Épisode 258/1000 terminé. Récompense: 1153.19\n",
      "Épisode 259/1000 terminé. Récompense: 53.38\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 599         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2110        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009530287 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | 0.9213875   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.000881   |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "Épisode 260/1000 terminé. Récompense: 938.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | 599          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2110         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032082614 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.96418715   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "Épisode 261/1000 terminé. Récompense: 488.18\n",
      "Épisode 262/1000 terminé. Récompense: 298.24\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 601         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2111        |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001497351 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.96167564  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.416       |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.000298   |\n",
      "|    value_loss           | 2.19        |\n",
      "-----------------------------------------\n",
      "Épisode 263/1000 terminé. Récompense: 671.47\n",
      "Épisode 264/1000 terminé. Récompense: 175.85\n",
      "Épisode 265/1000 terminé. Récompense: 11.62\n",
      "Épisode 266/1000 terminé. Récompense: 319.23\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.37e+03     |\n",
      "|    ep_rew_mean          | 591          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2111         |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024050353 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.95777434   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 2.36         |\n",
      "------------------------------------------\n",
      "Épisode 267/1000 terminé. Récompense: 1086.46\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 588         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2111        |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003682685 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.9700311   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.915       |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.37e+03     |\n",
      "|    ep_rew_mean          | 588          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 198          |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 405504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048986413 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.9443103    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37         |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    value_loss           | 2.5          |\n",
      "------------------------------------------\n",
      "Épisode 268/1000 terminé. Récompense: 1252.35\n",
      "Épisode 269/1000 terminé. Récompense: 560.49\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.4e+03    |\n",
      "|    ep_rew_mean          | 601        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2112       |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 407552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0055847  |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.563     |\n",
      "|    explained_variance   | 0.22469425 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.718      |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | -0.00188   |\n",
      "|    value_loss           | 1.51       |\n",
      "----------------------------------------\n",
      "Épisode 270/1000 terminé. Récompense: 366.44\n",
      "Épisode 271/1000 terminé. Récompense: 228.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 604          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012063005 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.9610888    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.916        |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.000929    |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 604         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2112        |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003302609 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.9649219   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "Épisode 272/1000 terminé. Récompense: 1244.59\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | 610          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 413696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039244923 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.5295317    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.67         |\n",
      "|    n_updates            | 2010         |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "Épisode 273/1000 terminé. Récompense: 1191.63\n",
      "Épisode 274/1000 terminé. Récompense: 353.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 604          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 415744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010479728 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.613       |\n",
      "|    explained_variance   | 0.9496418    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.986        |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 2.2          |\n",
      "------------------------------------------\n",
      "Épisode 275/1000 terminé. Récompense: 910.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 605          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023222761 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.96289724   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 2030         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "Épisode 276/1000 terminé. Récompense: 111.41\n",
      "Épisode 277/1000 terminé. Récompense: 486.46\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | 595          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051896963 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.94994736   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 2.21         |\n",
      "------------------------------------------\n",
      "Épisode 278/1000 terminé. Récompense: 744.48\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | 595          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 206          |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 421888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047280095 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.597       |\n",
      "|    explained_variance   | 0.95992637   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    value_loss           | 2.66         |\n",
      "------------------------------------------\n",
      "Épisode 279/1000 terminé. Récompense: 1111.07\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | 598         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2113        |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002916193 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.953953    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.805       |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "Épisode 280/1000 terminé. Récompense: 1140.61\n",
      "Épisode 281/1000 terminé. Récompense: 26.26\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | 599          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054290486 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.95180154   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.75         |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "Épisode 282/1000 terminé. Récompense: 465.31\n",
      "Épisode 283/1000 terminé. Récompense: 13.29\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 593         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2113        |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001935831 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.9591829   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.858       |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.000205   |\n",
      "|    value_loss           | 2.39        |\n",
      "-----------------------------------------\n",
      "Épisode 284/1000 terminé. Récompense: 812.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.36e+03     |\n",
      "|    ep_rew_mean          | 589          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029140632 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.9545468    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 2090         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "Épisode 285/1000 terminé. Récompense: 1237.57\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | 597          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2111         |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034703966 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.9548752    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.501        |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "Épisode 286/1000 terminé. Récompense: 935.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 605         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2111        |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006744571 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.95216906  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 605         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2111        |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003180351 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.94607687  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.793       |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "Épisode 287/1000 terminé. Récompense: 1142.81\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 616         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2111        |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006261732 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.24980706  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.523       |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "Épisode 288/1000 terminé. Récompense: 1048.29\n",
      "Épisode 289/1000 terminé. Récompense: 364.25\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 615          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2111         |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 440320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013547951 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.8815701    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.588        |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | 0.000761     |\n",
      "|    value_loss           | 2.16         |\n",
      "------------------------------------------\n",
      "Épisode 290/1000 terminé. Récompense: 422.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | 608          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2111         |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016505511 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.9269347    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.538        |\n",
      "|    n_updates            | 2150         |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "Épisode 291/1000 terminé. Récompense: 1008.03\n",
      "Épisode 292/1000 terminé. Récompense: 441.09\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 617          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 444416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019361166 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.524       |\n",
      "|    explained_variance   | 0.92823446   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.958        |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 2.11         |\n",
      "------------------------------------------\n",
      "Épisode 293/1000 terminé. Récompense: 843.10\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 623          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 446464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018399422 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.95960796   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.833        |\n",
      "|    n_updates            | 2170         |\n",
      "|    policy_gradient_loss | -0.000156    |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "Épisode 294/1000 terminé. Récompense: 883.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 630         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2112        |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002284283 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | 0.9395082   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.81        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "Épisode 295/1000 terminé. Récompense: 968.03\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2112         |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017642826 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.93330115   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.569        |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.000719    |\n",
      "|    value_loss           | 2.22         |\n",
      "------------------------------------------\n",
      "Épisode 296/1000 terminé. Récompense: 220.24\n",
      "Épisode 297/1000 terminé. Récompense: 116.82\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 625          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 452608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030471743 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.9460484    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.884        |\n",
      "|    n_updates            | 2200         |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 2.06         |\n",
      "------------------------------------------\n",
      "Épisode 298/1000 terminé. Récompense: 1150.95\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 633          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023761285 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.9607542    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 2210         |\n",
      "|    policy_gradient_loss | -0.000547    |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "Épisode 299/1000 terminé. Récompense: 1290.23\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 644          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024408372 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.962429     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.653        |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | 0.000194     |\n",
      "|    value_loss           | 2.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 644          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2113         |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036370147 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.94488704   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.801        |\n",
      "|    n_updates            | 2230         |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "Épisode 300/1000 terminé. Récompense: 1081.49\n",
      "Épisode 301/1000 terminé. Récompense: 279.28\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.47e+03   |\n",
      "|    ep_rew_mean          | 636        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2113       |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00441868 |\n",
      "|    clip_fraction        | 0.0646     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.539     |\n",
      "|    explained_variance   | 0.2388671  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.481      |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    value_loss           | 1.22       |\n",
      "----------------------------------------\n",
      "Épisode 302/1000 terminé. Récompense: 1034.09\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 645         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2114        |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002006483 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.91297936  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.646       |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "Épisode 303/1000 terminé. Récompense: 923.37\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 651         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2114        |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004554174 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.8978986   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.868       |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "Épisode 304/1000 terminé. Récompense: 327.79\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 651          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2114         |\n",
      "|    iterations           | 228          |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041339574 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.9148873    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.517        |\n",
      "|    n_updates            | 2270         |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 2.15         |\n",
      "------------------------------------------\n",
      "Épisode 305/1000 terminé. Récompense: 1182.47\n",
      "Épisode 306/1000 terminé. Récompense: 36.62\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 639          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2114         |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 468992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009830643 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.9319451    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.916        |\n",
      "|    n_updates            | 2280         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 2.19         |\n",
      "------------------------------------------\n",
      "Épisode 307/1000 terminé. Récompense: 1377.65\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 643          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 471040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024914034 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.967983     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.774        |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 643          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 473088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040357383 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.9460186    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.572        |\n",
      "|    n_updates            | 2300         |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 2.13         |\n",
      "------------------------------------------\n",
      "Épisode 308/1000 terminé. Récompense: 1135.73\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 648         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2115        |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006879176 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.2615897   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.418       |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "Épisode 309/1000 terminé. Récompense: 877.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 657          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015530024 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.93088454   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 2320         |\n",
      "|    policy_gradient_loss | -0.000319    |\n",
      "|    value_loss           | 2.08         |\n",
      "------------------------------------------\n",
      "Épisode 310/1000 terminé. Récompense: 1068.71\n",
      "Épisode 311/1000 terminé. Récompense: 509.93\n",
      "Épisode 312/1000 terminé. Récompense: 121.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2115         |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 479232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027553565 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.9396177    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 2330         |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 2.13         |\n",
      "------------------------------------------\n",
      "Épisode 313/1000 terminé. Récompense: 265.27\n",
      "Épisode 314/1000 terminé. Récompense: 227.63\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2116         |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 481280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009565275 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.9620266    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.000441    |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "Épisode 315/1000 terminé. Récompense: 879.58\n",
      "Épisode 316/1000 terminé. Récompense: 319.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2116         |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015535504 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.9595234    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73         |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 662         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2116        |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002162465 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.9603503   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.631       |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "Épisode 317/1000 terminé. Récompense: 1281.15\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 669         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2116        |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003319533 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.19442225  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.716       |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.000199   |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Épisode 318/1000 terminé. Récompense: 952.17\n",
      "Épisode 319/1000 terminé. Récompense: 532.80\n",
      "Épisode 320/1000 terminé. Récompense: 1.42\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2116         |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026137286 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.9253072    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.602        |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    value_loss           | 2.18         |\n",
      "------------------------------------------\n",
      "Épisode 321/1000 terminé. Récompense: 219.25\n",
      "Épisode 322/1000 terminé. Récompense: 638.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 650          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2116         |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020330288 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.9480185    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 2390         |\n",
      "|    policy_gradient_loss | 0.000363     |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "Épisode 323/1000 terminé. Récompense: 580.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2116         |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 233          |\n",
      "|    total_timesteps      | 493568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011275961 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.95135874   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.649        |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | 0.000132     |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "Épisode 324/1000 terminé. Récompense: 666.21\n",
      "Épisode 325/1000 terminé. Récompense: 57.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2117         |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 495616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019698467 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.93316966   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.76         |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | -0.000377    |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "Épisode 326/1000 terminé. Récompense: 854.67\n",
      "Épisode 327/1000 terminé. Récompense: 563.12\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2117         |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046016932 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.9499661    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 2.97         |\n",
      "------------------------------------------\n",
      "Épisode 328/1000 terminé. Récompense: 839.45\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 649         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2117        |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002394092 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | 0.9540387   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "Épisode 329/1000 terminé. Récompense: 131.47\n",
      "Épisode 330/1000 terminé. Récompense: 106.41\n",
      "Épisode 331/1000 terminé. Récompense: 613.80\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.45e+03      |\n",
      "|    ep_rew_mean          | 631           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2117          |\n",
      "|    iterations           | 245           |\n",
      "|    time_elapsed         | 236           |\n",
      "|    total_timesteps      | 501760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043089956 |\n",
      "|    clip_fraction        | 0.00469       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.522        |\n",
      "|    explained_variance   | 0.949332      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.986         |\n",
      "|    n_updates            | 2440          |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    value_loss           | 2.8           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2117         |\n",
      "|    iterations           | 246          |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 503808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027539348 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.9511572    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 2450         |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    value_loss           | 3.09         |\n",
      "------------------------------------------\n",
      "Épisode 332/1000 terminé. Récompense: 1187.04\n",
      "Épisode 333/1000 terminé. Récompense: 353.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 630         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2118        |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004213798 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.21087456  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.555       |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "Épisode 334/1000 terminé. Récompense: 952.83\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 629          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2118         |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021318854 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.9610989    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 2470         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "Épisode 335/1000 terminé. Récompense: 1089.82\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 637          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2118         |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030566761 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.95862114   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.665        |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 637          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2118         |\n",
      "|    iterations           | 250          |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 512000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014134994 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.96568227   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.733        |\n",
      "|    n_updates            | 2490         |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 2.05         |\n",
      "------------------------------------------\n",
      "Épisode 336/1000 terminé. Récompense: 1330.86\n",
      "Épisode 337/1000 terminé. Récompense: 560.32\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 643         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2118        |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006324269 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.21378338  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.66        |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 643         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2118        |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003191826 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.92360663  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | 0.000627    |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "Épisode 338/1000 terminé. Récompense: 1120.43\n",
      "Épisode 339/1000 terminé. Récompense: 618.60\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 653         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2118        |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004214557 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.29169524  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "Épisode 340/1000 terminé. Récompense: 781.34\n",
      "Épisode 341/1000 terminé. Récompense: 175.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 646         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2118        |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002822181 |\n",
      "|    clip_fraction        | 0.00962     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.543      |\n",
      "|    explained_variance   | 0.9339374   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "Épisode 342/1000 terminé. Récompense: 399.04\n",
      "Épisode 343/1000 terminé. Récompense: 320.77\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2119         |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 522240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009561764 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.9504019    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 2540         |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "Épisode 344/1000 terminé. Récompense: 1036.13\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 644          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2119         |\n",
      "|    iterations           | 256          |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010113453 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.96118647   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.604        |\n",
      "|    n_updates            | 2550         |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    value_loss           | 2.61         |\n",
      "------------------------------------------\n",
      "Épisode 345/1000 terminé. Récompense: 549.97\n",
      "Épisode 346/1000 terminé. Récompense: 89.36\n",
      "Épisode 347/1000 terminé. Récompense: 232.11\n",
      "Épisode 348/1000 terminé. Récompense: 154.36\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 630          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2119         |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 526336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022770073 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.9450619    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.65         |\n",
      "|    n_updates            | 2560         |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 2.12         |\n",
      "------------------------------------------\n",
      "Épisode 349/1000 terminé. Récompense: 456.90\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.45e+03      |\n",
      "|    ep_rew_mean          | 633           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2119          |\n",
      "|    iterations           | 258           |\n",
      "|    time_elapsed         | 249           |\n",
      "|    total_timesteps      | 528384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081411796 |\n",
      "|    clip_fraction        | 0.00142       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.544        |\n",
      "|    explained_variance   | 0.96285915    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.04          |\n",
      "|    n_updates            | 2570          |\n",
      "|    policy_gradient_loss | -0.00167      |\n",
      "|    value_loss           | 4.12          |\n",
      "-------------------------------------------\n",
      "Épisode 350/1000 terminé. Récompense: 452.01\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 636         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2119        |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001957138 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.9593035   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.63        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "Épisode 351/1000 terminé. Récompense: 1334.20\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 646         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2119        |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004857677 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.9419687   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.945       |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "Épisode 352/1000 terminé. Récompense: 897.18\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2119         |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 534528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034645218 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.9474958    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.68         |\n",
      "|    n_updates            | 2600         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 2.19         |\n",
      "------------------------------------------\n",
      "Épisode 353/1000 terminé. Récompense: 592.25\n",
      "Épisode 354/1000 terminé. Récompense: 224.19\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 647          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 262          |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 536576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036210832 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.9517148    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.685        |\n",
      "|    n_updates            | 2610         |\n",
      "|    policy_gradient_loss | -0.00085     |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "Épisode 355/1000 terminé. Récompense: 1128.89\n",
      "Épisode 356/1000 terminé. Récompense: 170.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 650          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 538624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018877988 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.9679976    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "Épisode 357/1000 terminé. Récompense: 524.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 647          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 264          |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041187294 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.634       |\n",
      "|    explained_variance   | 0.96788466   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.784        |\n",
      "|    n_updates            | 2630         |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 2.45         |\n",
      "------------------------------------------\n",
      "Épisode 358/1000 terminé. Récompense: 551.62\n",
      "Épisode 359/1000 terminé. Récompense: 611.19\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 647          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058803405 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.653       |\n",
      "|    explained_variance   | 0.9531768    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.768        |\n",
      "|    n_updates            | 2640         |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "Épisode 360/1000 terminé. Récompense: 139.59\n",
      "Épisode 361/1000 terminé. Récompense: 633.06\n",
      "Épisode 362/1000 terminé. Récompense: 191.14\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 639         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2120        |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007499665 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.96412325  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 639         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2120        |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004673696 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.971826    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "Épisode 363/1000 terminé. Récompense: 1077.62\n",
      "Épisode 364/1000 terminé. Récompense: 382.47\n",
      "Épisode 365/1000 terminé. Récompense: 58.42\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2120         |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047296444 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.24466193   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.76         |\n",
      "|    n_updates            | 2670         |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "Épisode 366/1000 terminé. Récompense: 1002.79\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 269          |\n",
      "|    time_elapsed         | 259          |\n",
      "|    total_timesteps      | 550912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011583354 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.9395296    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 2680         |\n",
      "|    policy_gradient_loss | -0.000126    |\n",
      "|    value_loss           | 2.88         |\n",
      "------------------------------------------\n",
      "Épisode 367/1000 terminé. Récompense: 660.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 648          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025802364 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.91447693   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.5          |\n",
      "|    n_updates            | 2690         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 2.48         |\n",
      "------------------------------------------\n",
      "Épisode 368/1000 terminé. Récompense: 896.99\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.48e+03   |\n",
      "|    ep_rew_mean          | 645        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2121       |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 555008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00408239 |\n",
      "|    clip_fraction        | 0.0268     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.551     |\n",
      "|    explained_variance   | 0.9213326  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.21       |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | -0.00479   |\n",
      "|    value_loss           | 2.35       |\n",
      "----------------------------------------\n",
      "Épisode 369/1000 terminé. Récompense: 376.85\n",
      "Épisode 370/1000 terminé. Récompense: 674.48\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.48e+03      |\n",
      "|    ep_rew_mean          | 646           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2121          |\n",
      "|    iterations           | 272           |\n",
      "|    time_elapsed         | 262           |\n",
      "|    total_timesteps      | 557056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086875306 |\n",
      "|    clip_fraction        | 0.00928       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.537        |\n",
      "|    explained_variance   | 0.93618006    |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.791         |\n",
      "|    n_updates            | 2710          |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    value_loss           | 2.26          |\n",
      "-------------------------------------------\n",
      "Épisode 371/1000 terminé. Récompense: 889.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013884243 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.9578008    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 2.57         |\n",
      "------------------------------------------\n",
      "Épisode 372/1000 terminé. Récompense: 621.61\n",
      "Épisode 373/1000 terminé. Récompense: 359.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 274          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 561152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028944295 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.9379842    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.535        |\n",
      "|    n_updates            | 2730         |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 2.3          |\n",
      "------------------------------------------\n",
      "Épisode 374/1000 terminé. Récompense: 301.02\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 637          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011751783 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.96399105   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72         |\n",
      "|    n_updates            | 2740         |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 2.38         |\n",
      "------------------------------------------\n",
      "Épisode 375/1000 terminé. Récompense: 971.86\n",
      "Épisode 376/1000 terminé. Récompense: 108.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 638         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2121        |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002762466 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.9519615   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.732       |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "Épisode 377/1000 terminé. Récompense: 593.19\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 639          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 267          |\n",
      "|    total_timesteps      | 567296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022558742 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.966215     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.689        |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 2.45         |\n",
      "------------------------------------------\n",
      "Épisode 378/1000 terminé. Récompense: 1202.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 644          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2121         |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 569344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033126725 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.95502114   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.596        |\n",
      "|    n_updates            | 2770         |\n",
      "|    policy_gradient_loss | -0.000547    |\n",
      "|    value_loss           | 1.9          |\n",
      "------------------------------------------\n",
      "Épisode 379/1000 terminé. Récompense: 1254.63\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 645         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2122        |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005006584 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.952199    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.663       |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00016    |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "Épisode 380/1000 terminé. Récompense: 517.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 639          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2122         |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034181378 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.95146245   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.627        |\n",
      "|    n_updates            | 2790         |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "Épisode 381/1000 terminé. Récompense: 624.75\n",
      "Épisode 382/1000 terminé. Récompense: 91.65\n",
      "Épisode 383/1000 terminé. Récompense: 662.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 648          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2122         |\n",
      "|    iterations           | 281          |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 575488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048208153 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.9479846    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.873        |\n",
      "|    n_updates            | 2800         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 2.31         |\n",
      "------------------------------------------\n",
      "Épisode 384/1000 terminé. Récompense: 460.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 644          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2122         |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 577536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025351138 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.96276534   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 2810         |\n",
      "|    policy_gradient_loss | -0.000583    |\n",
      "|    value_loss           | 2.81         |\n",
      "------------------------------------------\n",
      "Épisode 385/1000 terminé. Récompense: 1331.82\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.47e+03   |\n",
      "|    ep_rew_mean          | 645        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2122       |\n",
      "|    iterations           | 283        |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 579584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00555072 |\n",
      "|    clip_fraction        | 0.0488     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.524     |\n",
      "|    explained_variance   | 0.9689527  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.09       |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.000133  |\n",
      "|    value_loss           | 1.78       |\n",
      "----------------------------------------\n",
      "Épisode 386/1000 terminé. Récompense: 974.09\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 645          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2122         |\n",
      "|    iterations           | 284          |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 581632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030602543 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.95597774   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.775        |\n",
      "|    n_updates            | 2830         |\n",
      "|    policy_gradient_loss | 0.00066      |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "Épisode 387/1000 terminé. Récompense: 255.88\n",
      "Épisode 388/1000 terminé. Récompense: 391.09\n",
      "Épisode 389/1000 terminé. Récompense: 160.27\n",
      "Épisode 390/1000 terminé. Récompense: 98.98\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 625          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 285          |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 583680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073357895 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.9560008    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.643        |\n",
      "|    n_updates            | 2840         |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 1.91         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 625         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2123        |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002237998 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.9771101   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.806       |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "Épisode 391/1000 terminé. Récompense: 1335.85\n",
      "Épisode 392/1000 terminé. Récompense: 22.48\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.42e+03   |\n",
      "|    ep_rew_mean          | 624        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2123       |\n",
      "|    iterations           | 287        |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 587776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00826372 |\n",
      "|    clip_fraction        | 0.0651     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.506     |\n",
      "|    explained_variance   | 0.22848243 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.818      |\n",
      "|    n_updates            | 2860       |\n",
      "|    policy_gradient_loss | -0.000446  |\n",
      "|    value_loss           | 1.22       |\n",
      "----------------------------------------\n",
      "Épisode 393/1000 terminé. Récompense: 1094.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 626          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013109713 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.96806574   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 2870         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "Épisode 394/1000 terminé. Récompense: 1157.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 629          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 289          |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 591872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012184007 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.96031255   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.739        |\n",
      "|    n_updates            | 2880         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "Épisode 395/1000 terminé. Récompense: 923.20\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 629          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012718427 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.9562484    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 2890         |\n",
      "|    policy_gradient_loss | -0.000994    |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "Épisode 396/1000 terminé. Récompense: 362.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 630          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2123         |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 595968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032800357 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.9568893    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.97         |\n",
      "|    n_updates            | 2900         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.83         |\n",
      "------------------------------------------\n",
      "Épisode 397/1000 terminé. Récompense: 1249.83\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 641          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034992332 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.95717794   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.719        |\n",
      "|    n_updates            | 2910         |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 2.01         |\n",
      "------------------------------------------\n",
      "Épisode 398/1000 terminé. Récompense: 745.55\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 637         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2124        |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003551962 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.94811094  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 2.05        |\n",
      "-----------------------------------------\n",
      "Épisode 399/1000 terminé. Récompense: 975.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 634          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015035409 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.9566182    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 2930         |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "Épisode 400/1000 terminé. Récompense: 1038.52\n",
      "Épisode 401/1000 terminé. Récompense: 190.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 633         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2124        |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002582598 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.9554568   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.915       |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "Épisode 402/1000 terminé. Récompense: 495.02\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 627          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 296          |\n",
      "|    time_elapsed         | 285          |\n",
      "|    total_timesteps      | 606208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032414044 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.9658399    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.767        |\n",
      "|    n_updates            | 2950         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 2.37         |\n",
      "------------------------------------------\n",
      "Épisode 403/1000 terminé. Récompense: 869.86\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 627          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2124         |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 608256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028556976 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.95656765   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.845        |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.000747    |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "Épisode 404/1000 terminé. Récompense: 630.29\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 630         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2124        |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002114526 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.537      |\n",
      "|    explained_variance   | 0.9469522   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.846       |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "Épisode 405/1000 terminé. Récompense: 1319.93\n",
      "Épisode 406/1000 terminé. Récompense: 321.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 634          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2125         |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031378195 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.96685714   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 2980         |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 634          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2125         |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013801679 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.9682336    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.534        |\n",
      "|    n_updates            | 2990         |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 2.23         |\n",
      "------------------------------------------\n",
      "Épisode 407/1000 terminé. Récompense: 956.70\n",
      "Épisode 408/1000 terminé. Récompense: 456.24\n",
      "Épisode 409/1000 terminé. Récompense: 353.03\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 618         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2125        |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006188087 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.5883595   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.711       |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "Épisode 410/1000 terminé. Récompense: 502.10\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 612         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2125        |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001405427 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.95409703  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "Épisode 411/1000 terminé. Récompense: 796.78\n",
      "Épisode 412/1000 terminé. Récompense: 41.23\n",
      "Épisode 413/1000 terminé. Récompense: 144.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 613          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2125         |\n",
      "|    iterations           | 303          |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 620544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038029156 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.93566763   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.552        |\n",
      "|    n_updates            | 3020         |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "Épisode 414/1000 terminé. Récompense: 744.17\n",
      "Épisode 415/1000 terminé. Récompense: 395.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 613          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2125         |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018631939 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.95728886   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 3030         |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 613          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2125         |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028021967 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.9662551    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.821        |\n",
      "|    n_updates            | 3040         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 2.28         |\n",
      "------------------------------------------\n",
      "Épisode 416/1000 terminé. Récompense: 1303.23\n",
      "Épisode 417/1000 terminé. Récompense: 313.78\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 614         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2125        |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007051489 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.15659714  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.629       |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "Épisode 418/1000 terminé. Récompense: 1152.45\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 616         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002159317 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.96642005  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "Épisode 419/1000 terminé. Récompense: 467.37\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | 615          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011377493 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.9514174    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 2.08         |\n",
      "------------------------------------------\n",
      "Épisode 420/1000 terminé. Récompense: 1006.00\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 625          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 297          |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020460498 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.9572579    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.596        |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "Épisode 421/1000 terminé. Récompense: 868.44\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 631         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003416112 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.95213544  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "Épisode 422/1000 terminé. Récompense: 993.26\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 635          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 311          |\n",
      "|    time_elapsed         | 299          |\n",
      "|    total_timesteps      | 636928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019265679 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.95392317   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.8          |\n",
      "|    n_updates            | 3100         |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "Épisode 423/1000 terminé. Récompense: 504.41\n",
      "Épisode 424/1000 terminé. Récompense: 40.76\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | 628          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024132049 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.9542607    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 3110         |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "Épisode 425/1000 terminé. Récompense: 1128.56\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 639         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001394843 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.9719856   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "Épisode 426/1000 terminé. Récompense: 865.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 639          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 643072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029946484 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.95475423   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.733        |\n",
      "|    n_updates            | 3130         |\n",
      "|    policy_gradient_loss | 0.000634     |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "Épisode 427/1000 terminé. Récompense: 577.34\n",
      "Épisode 428/1000 terminé. Récompense: 657.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 637          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 315          |\n",
      "|    time_elapsed         | 303          |\n",
      "|    total_timesteps      | 645120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027733534 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.9531514    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.695        |\n",
      "|    n_updates            | 3140         |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "Épisode 429/1000 terminé. Récompense: 162.05\n",
      "Épisode 430/1000 terminé. Récompense: 6.55\n",
      "Épisode 431/1000 terminé. Récompense: 609.06\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 636          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017818589 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.9678608    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.877        |\n",
      "|    n_updates            | 3150         |\n",
      "|    policy_gradient_loss | -0.000483    |\n",
      "|    value_loss           | 2.38         |\n",
      "------------------------------------------\n",
      "Épisode 432/1000 terminé. Récompense: 1100.83\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 636         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002680433 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.9711661   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.701       |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 636          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 306          |\n",
      "|    total_timesteps      | 651264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053862147 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.95378137   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 1.77         |\n",
      "------------------------------------------\n",
      "Épisode 433/1000 terminé. Récompense: 967.14\n",
      "Épisode 434/1000 terminé. Récompense: 134.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 633          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2126         |\n",
      "|    iterations           | 319          |\n",
      "|    time_elapsed         | 307          |\n",
      "|    total_timesteps      | 653312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055900216 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.7297024    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.644        |\n",
      "|    n_updates            | 3180         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "Épisode 435/1000 terminé. Récompense: 997.07\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 633         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2126        |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004029563 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.9549673   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.948       |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "Épisode 436/1000 terminé. Récompense: 953.11\n",
      "Épisode 437/1000 terminé. Récompense: 420.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 627          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 657408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032326817 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.9485099    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 3200         |\n",
      "|    policy_gradient_loss | 0.000451     |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "Épisode 438/1000 terminé. Récompense: 166.14\n",
      "Épisode 439/1000 terminé. Récompense: 358.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | 615          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 310          |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047742156 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.96651304   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.944        |\n",
      "|    n_updates            | 3210         |\n",
      "|    policy_gradient_loss | -0.00804     |\n",
      "|    value_loss           | 2.27         |\n",
      "------------------------------------------\n",
      "Épisode 440/1000 terminé. Récompense: 877.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 616         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2127        |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001078919 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.565      |\n",
      "|    explained_variance   | 0.9709607   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "Épisode 441/1000 terminé. Récompense: 974.72\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 624         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2127        |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003697638 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.9595524   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.752       |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "Épisode 442/1000 terminé. Récompense: 621.23\n",
      "Épisode 443/1000 terminé. Récompense: 303.37\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 626         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2127        |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001934174 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.955088    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.000454   |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "Épisode 444/1000 terminé. Récompense: 1100.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 627         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2127        |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001551803 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.574      |\n",
      "|    explained_variance   | 0.97340596  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.89        |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.000711   |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "Épisode 445/1000 terminé. Récompense: 971.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 327          |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 669696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037021758 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.95903987   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.81         |\n",
      "|    n_updates            | 3260         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 328          |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 671744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036149325 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.95897526   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.702        |\n",
      "|    n_updates            | 3270         |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "Épisode 446/1000 terminé. Récompense: 983.13\n",
      "Épisode 447/1000 terminé. Récompense: 368.33\n",
      "Épisode 448/1000 terminé. Récompense: 359.23\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 643          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2127         |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061301067 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.61456954   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.527        |\n",
      "|    n_updates            | 3280         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 449/1000 terminé. Récompense: 480.30\n",
      "Épisode 450/1000 terminé. Récompense: 283.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 642          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 330          |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 675840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018534643 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.9514859    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.897        |\n",
      "|    n_updates            | 3290         |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 2.36         |\n",
      "------------------------------------------\n",
      "Épisode 451/1000 terminé. Récompense: 667.90\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 635          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 677888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028403385 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.9633944    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.67         |\n",
      "|    n_updates            | 3300         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 2.15         |\n",
      "------------------------------------------\n",
      "Épisode 452/1000 terminé. Récompense: 1200.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026307413 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.95829403   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.921        |\n",
      "|    n_updates            | 3310         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.67         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 333          |\n",
      "|    time_elapsed         | 320          |\n",
      "|    total_timesteps      | 681984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031938613 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.9545548    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "Épisode 453/1000 terminé. Récompense: 1036.99\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.47e+03  |\n",
      "|    ep_rew_mean          | 643       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2128      |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 321       |\n",
      "|    total_timesteps      | 684032    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0048963 |\n",
      "|    clip_fraction        | 0.0511    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.479    |\n",
      "|    explained_variance   | 0.8823185 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.698     |\n",
      "|    n_updates            | 3330      |\n",
      "|    policy_gradient_loss | -0.00277  |\n",
      "|    value_loss           | 1.55      |\n",
      "---------------------------------------\n",
      "Épisode 454/1000 terminé. Récompense: 1128.80\n",
      "Épisode 455/1000 terminé. Récompense: 63.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 641          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 322          |\n",
      "|    total_timesteps      | 686080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040736217 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.93905234   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.663        |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | 0.00128      |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "Épisode 456/1000 terminé. Récompense: 940.04\n",
      "Épisode 457/1000 terminé. Récompense: 323.53\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 647         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2128        |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002468964 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.97071755  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.682       |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "Épisode 458/1000 terminé. Récompense: 1136.13\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 337          |\n",
      "|    time_elapsed         | 324          |\n",
      "|    total_timesteps      | 690176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023402362 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.974859     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 3360         |\n",
      "|    policy_gradient_loss | 0.000416     |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "Épisode 459/1000 terminé. Récompense: 652.12\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 692224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021020821 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.951151     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.762        |\n",
      "|    n_updates            | 3370         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 653         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2129        |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002232866 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.9654028   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.706       |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "Épisode 460/1000 terminé. Récompense: 1339.05\n",
      "Épisode 461/1000 terminé. Récompense: 71.04\n",
      "Épisode 462/1000 terminé. Récompense: 354.13\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 661          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 327          |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074586384 |\n",
      "|    clip_fraction        | 0.0926       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.34751195   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.52         |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "Épisode 463/1000 terminé. Récompense: 1190.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 341          |\n",
      "|    time_elapsed         | 328          |\n",
      "|    total_timesteps      | 698368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018226898 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.950443     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 3400         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 2.67         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2128         |\n",
      "|    iterations           | 342          |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 700416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032587948 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.9354545    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 3410         |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "Épisode 464/1000 terminé. Récompense: 1175.29\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 670         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2128        |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004370886 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.1990177   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.731       |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "Épisode 465/1000 terminé. Récompense: 1265.09\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 344          |\n",
      "|    time_elapsed         | 330          |\n",
      "|    total_timesteps      | 704512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015097838 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.94678414   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.92         |\n",
      "|    n_updates            | 3430         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 2.2          |\n",
      "------------------------------------------\n",
      "Épisode 466/1000 terminé. Récompense: 760.66\n",
      "Épisode 467/1000 terminé. Récompense: 440.05\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 331          |\n",
      "|    total_timesteps      | 706560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038766142 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.9482879    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    value_loss           | 1.94         |\n",
      "------------------------------------------\n",
      "Épisode 468/1000 terminé. Récompense: 741.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 332          |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024701115 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.97285795   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34         |\n",
      "|    n_updates            | 3450         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 1.9          |\n",
      "------------------------------------------\n",
      "Épisode 469/1000 terminé. Récompense: 731.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 680          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 347          |\n",
      "|    time_elapsed         | 333          |\n",
      "|    total_timesteps      | 710656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022924086 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.95502543   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.968        |\n",
      "|    n_updates            | 3460         |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.97         |\n",
      "------------------------------------------\n",
      "Épisode 470/1000 terminé. Récompense: 609.44\n",
      "Épisode 471/1000 terminé. Récompense: 384.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 674          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 712704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033621178 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.9595601    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.933        |\n",
      "|    n_updates            | 3470         |\n",
      "|    policy_gradient_loss | -0.000907    |\n",
      "|    value_loss           | 1.75         |\n",
      "------------------------------------------\n",
      "Épisode 472/1000 terminé. Récompense: 1143.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 679         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2129        |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002271498 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.9748053   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 350          |\n",
      "|    time_elapsed         | 336          |\n",
      "|    total_timesteps      | 716800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026754704 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.9577645    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 3490         |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "Épisode 473/1000 terminé. Récompense: 1137.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2129         |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 718848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065266476 |\n",
      "|    clip_fraction        | 0.0743       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.29953265   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.599        |\n",
      "|    n_updates            | 3500         |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "Épisode 474/1000 terminé. Récompense: 967.07\n",
      "Épisode 475/1000 terminé. Récompense: 599.47\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 352          |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 720896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015130041 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.95556074   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 3510         |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "Épisode 476/1000 terminé. Récompense: 228.04\n",
      "Épisode 477/1000 terminé. Récompense: 43.74\n",
      "Épisode 478/1000 terminé. Récompense: 612.32\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 680         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2130        |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005200719 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.9684185   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.873       |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "Épisode 479/1000 terminé. Récompense: 860.48\n",
      "Épisode 480/1000 terminé. Récompense: 52.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 340          |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011000724 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.97575545   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.735        |\n",
      "|    n_updates            | 3530         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 2.43         |\n",
      "------------------------------------------\n",
      "Épisode 481/1000 terminé. Récompense: 832.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 341          |\n",
      "|    total_timesteps      | 727040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041326554 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.9717957    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 3540         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 2.05         |\n",
      "------------------------------------------\n",
      "Épisode 482/1000 terminé. Récompense: 675.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 342          |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031653908 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.95732903   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.509        |\n",
      "|    n_updates            | 3550         |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "Épisode 483/1000 terminé. Récompense: 348.11\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 357          |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 731136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028453278 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.9523886    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.867        |\n",
      "|    n_updates            | 3560         |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "Épisode 484/1000 terminé. Récompense: 1104.58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 358          |\n",
      "|    time_elapsed         | 344          |\n",
      "|    total_timesteps      | 733184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033438466 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.9504317    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.614        |\n",
      "|    n_updates            | 3570         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "Épisode 485/1000 terminé. Récompense: 1028.46\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 359          |\n",
      "|    time_elapsed         | 345          |\n",
      "|    total_timesteps      | 735232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028427118 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.9532027    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.748        |\n",
      "|    n_updates            | 3580         |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "Épisode 486/1000 terminé. Récompense: 1321.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2130         |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 346          |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019258764 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.9667287    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.567        |\n",
      "|    n_updates            | 3590         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | 683         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2130        |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002479672 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.9701454   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.747       |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "Épisode 487/1000 terminé. Récompense: 1358.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 362          |\n",
      "|    time_elapsed         | 347          |\n",
      "|    total_timesteps      | 741376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041714776 |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.23945075   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.958        |\n",
      "|    n_updates            | 3610         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "Épisode 488/1000 terminé. Récompense: 1151.12\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 701          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013259004 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.9610862    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.978        |\n",
      "|    n_updates            | 3620         |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    value_loss           | 1.89         |\n",
      "------------------------------------------\n",
      "Épisode 489/1000 terminé. Récompense: 979.13\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 710          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 364          |\n",
      "|    time_elapsed         | 349          |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020976656 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.9588364    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.697        |\n",
      "|    n_updates            | 3630         |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "Épisode 490/1000 terminé. Récompense: 881.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 717          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018444343 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.95653445   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 3640         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "Épisode 491/1000 terminé. Récompense: 776.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 712          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 351          |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025269056 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.95767826   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.89         |\n",
      "|    n_updates            | 3650         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 1.73         |\n",
      "------------------------------------------\n",
      "Épisode 492/1000 terminé. Récompense: 736.81\n",
      "Épisode 493/1000 terminé. Récompense: 191.85\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 710          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 367          |\n",
      "|    time_elapsed         | 352          |\n",
      "|    total_timesteps      | 751616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016160106 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.94975555   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 3660         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "Épisode 494/1000 terminé. Récompense: 1337.55\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 712          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 368          |\n",
      "|    time_elapsed         | 353          |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013222944 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.979303     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 3670         |\n",
      "|    policy_gradient_loss | -4.18e-05    |\n",
      "|    value_loss           | 2.01         |\n",
      "------------------------------------------\n",
      "Épisode 495/1000 terminé. Récompense: 816.85\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 711          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 369          |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 755712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023463606 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.9594556    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 3680         |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "Épisode 496/1000 terminé. Récompense: 530.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 712          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 757760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029983048 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.96162677   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 3690         |\n",
      "|    policy_gradient_loss | -7.91e-05    |\n",
      "|    value_loss           | 1.69         |\n",
      "------------------------------------------\n",
      "Épisode 497/1000 terminé. Récompense: 630.70\n",
      "Épisode 498/1000 terminé. Récompense: 378.25\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 702          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031691361 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.9653787    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.691        |\n",
      "|    n_updates            | 3700         |\n",
      "|    policy_gradient_loss | -0.000483    |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "Épisode 499/1000 terminé. Récompense: 546.59\n",
      "Épisode 500/1000 terminé. Récompense: 751.52\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 695         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002578116 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.97612715  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.897       |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "Épisode 501/1000 terminé. Récompense: 625.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 700          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 358          |\n",
      "|    total_timesteps      | 763904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027827653 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.524       |\n",
      "|    explained_variance   | 0.976448     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.83         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 700          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 374          |\n",
      "|    time_elapsed         | 359          |\n",
      "|    total_timesteps      | 765952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038368895 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.96880734   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.972        |\n",
      "|    n_updates            | 3730         |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "Épisode 502/1000 terminé. Récompense: 1325.77\n",
      "Épisode 503/1000 terminé. Récompense: 238.15\n",
      "Épisode 504/1000 terminé. Récompense: 89.05\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 696          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 375          |\n",
      "|    time_elapsed         | 360          |\n",
      "|    total_timesteps      | 768000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039500226 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.37158048   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.515        |\n",
      "|    n_updates            | 3740         |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 505/1000 terminé. Récompense: 789.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 691          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 376          |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 770048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008605913 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.95792615   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 3750         |\n",
      "|    policy_gradient_loss | -0.000772    |\n",
      "|    value_loss           | 2.47         |\n",
      "------------------------------------------\n",
      "Épisode 506/1000 terminé. Récompense: 1075.15\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 698          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 377          |\n",
      "|    time_elapsed         | 362          |\n",
      "|    total_timesteps      | 772096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033729505 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.94965047   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.86         |\n",
      "|    n_updates            | 3760         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    value_loss           | 1.67         |\n",
      "------------------------------------------\n",
      "Épisode 507/1000 terminé. Récompense: 1302.00\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 702          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 363          |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026426387 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.9547764    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.661        |\n",
      "|    n_updates            | 3770         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "Épisode 508/1000 terminé. Récompense: 782.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 705          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 379          |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 776192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019301127 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.94934124   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 3780         |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "Épisode 509/1000 terminé. Récompense: 487.93\n",
      "Épisode 510/1000 terminé. Récompense: 299.29\n",
      "Épisode 511/1000 terminé. Récompense: 184.67\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 698          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 778240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021687523 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.94815165   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.479        |\n",
      "|    n_updates            | 3790         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 1.74         |\n",
      "------------------------------------------\n",
      "Épisode 512/1000 terminé. Récompense: 882.58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 707          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 780288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018711282 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.9760087    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.909        |\n",
      "|    n_updates            | 3800         |\n",
      "|    policy_gradient_loss | -0.000246    |\n",
      "|    value_loss           | 2.09         |\n",
      "------------------------------------------\n",
      "Épisode 513/1000 terminé. Récompense: 670.73\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 712          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036946712 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.95197046   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.909        |\n",
      "|    n_updates            | 3810         |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 1.87         |\n",
      "------------------------------------------\n",
      "Épisode 514/1000 terminé. Récompense: 791.80\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 713          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2131         |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 367          |\n",
      "|    total_timesteps      | 784384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020333594 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.95586926   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.691        |\n",
      "|    n_updates            | 3820         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "Épisode 515/1000 terminé. Récompense: 533.99\n",
      "Épisode 516/1000 terminé. Récompense: 580.56\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 707         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2131        |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003316937 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.9615106   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.515       |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | 0.000404    |\n",
      "|    value_loss           | 1.54        |\n",
      "-----------------------------------------\n",
      "Épisode 517/1000 terminé. Récompense: 994.67\n",
      "Épisode 518/1000 terminé. Récompense: 132.57\n",
      "Épisode 519/1000 terminé. Récompense: 43.86\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 369          |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017577005 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.97656596   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "Épisode 520/1000 terminé. Récompense: 763.36\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 697         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2132        |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003409317 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.97866535  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.864       |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022266568 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.9586965    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.646        |\n",
      "|    n_updates            | 3860         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "Épisode 521/1000 terminé. Récompense: 1232.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 700          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 388          |\n",
      "|    time_elapsed         | 372          |\n",
      "|    total_timesteps      | 794624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035771965 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.27784848   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.638        |\n",
      "|    n_updates            | 3870         |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    value_loss           | 1.34         |\n",
      "------------------------------------------\n",
      "Épisode 522/1000 terminé. Récompense: 780.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 698          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 389          |\n",
      "|    time_elapsed         | 373          |\n",
      "|    total_timesteps      | 796672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027035112 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.95002455   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 3880         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "Épisode 523/1000 terminé. Récompense: 896.48\n",
      "Épisode 524/1000 terminé. Récompense: 797.83\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 710          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 798720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034217606 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.9485566    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.758        |\n",
      "|    n_updates            | 3890         |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 1.74         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 710          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 391          |\n",
      "|    time_elapsed         | 375          |\n",
      "|    total_timesteps      | 800768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011080352 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.9736545    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 3900         |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    value_loss           | 2.02         |\n",
      "------------------------------------------\n",
      "Épisode 525/1000 terminé. Récompense: 1387.36\n",
      "Épisode 526/1000 terminé. Récompense: 147.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 705          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 392          |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 802816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051537994 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.75091726   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.603        |\n",
      "|    n_updates            | 3910         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 1.51         |\n",
      "------------------------------------------\n",
      "Épisode 527/1000 terminé. Récompense: 423.76\n",
      "Épisode 528/1000 terminé. Récompense: 326.80\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 700          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 393          |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 804864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014733099 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.97120523   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 3920         |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    value_loss           | 2.35         |\n",
      "------------------------------------------\n",
      "Épisode 529/1000 terminé. Récompense: 1199.62\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 711          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 394          |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 806912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040587434 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.9764111    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.545        |\n",
      "|    n_updates            | 3930         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.6          |\n",
      "------------------------------------------\n",
      "Épisode 530/1000 terminé. Récompense: 873.28\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 719         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2132        |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001916541 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.9620482   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.775       |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "Épisode 531/1000 terminé. Récompense: 746.61\n",
      "Épisode 532/1000 terminé. Récompense: 110.66\n",
      "Épisode 533/1000 terminé. Récompense: 263.67\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 396          |\n",
      "|    time_elapsed         | 380          |\n",
      "|    total_timesteps      | 811008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027367782 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.9601052    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.782        |\n",
      "|    n_updates            | 3950         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 397          |\n",
      "|    time_elapsed         | 381          |\n",
      "|    total_timesteps      | 813056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016777538 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.9839845    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | 0.000307     |\n",
      "|    value_loss           | 2.07         |\n",
      "------------------------------------------\n",
      "Épisode 534/1000 terminé. Récompense: 1327.59\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 716         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2133        |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005037032 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.26682568  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.49        |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "Épisode 535/1000 terminé. Récompense: 873.92\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 714          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 399          |\n",
      "|    time_elapsed         | 383          |\n",
      "|    total_timesteps      | 817152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024187523 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.9607556    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.999        |\n",
      "|    n_updates            | 3980         |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "Épisode 536/1000 terminé. Récompense: 808.73\n",
      "Épisode 537/1000 terminé. Récompense: 631.92\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 715          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 384          |\n",
      "|    total_timesteps      | 819200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031138994 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.96413124   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.539        |\n",
      "|    n_updates            | 3990         |\n",
      "|    policy_gradient_loss | -0.000901    |\n",
      "|    value_loss           | 1.65         |\n",
      "------------------------------------------\n",
      "Épisode 538/1000 terminé. Récompense: 833.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 722          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 401          |\n",
      "|    time_elapsed         | 384          |\n",
      "|    total_timesteps      | 821248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027673962 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.9755707    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.759        |\n",
      "|    n_updates            | 4000         |\n",
      "|    policy_gradient_loss | -0.000544    |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "Épisode 539/1000 terminé. Récompense: 562.69\n",
      "Épisode 540/1000 terminé. Récompense: 441.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 719          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 402          |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 823296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014708195 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.96358305   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.847        |\n",
      "|    n_updates            | 4010         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "Épisode 541/1000 terminé. Récompense: 595.26\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 716          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 403          |\n",
      "|    time_elapsed         | 386          |\n",
      "|    total_timesteps      | 825344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015963919 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.978285     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.83         |\n",
      "|    n_updates            | 4020         |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n",
      "Épisode 542/1000 terminé. Récompense: 1232.18\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | 722          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 404          |\n",
      "|    time_elapsed         | 387          |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061876643 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.96737516   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.648        |\n",
      "|    n_updates            | 4030         |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "Épisode 543/1000 terminé. Récompense: 596.88\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 725          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 388          |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031742568 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.9649529    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.646        |\n",
      "|    n_updates            | 4040         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "Épisode 544/1000 terminé. Récompense: 772.32\n",
      "Épisode 545/1000 terminé. Récompense: 272.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 714          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 406          |\n",
      "|    time_elapsed         | 389          |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039867437 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.9586911    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.937        |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 1.75         |\n",
      "------------------------------------------\n",
      "Épisode 546/1000 terminé. Récompense: 1002.39\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 715          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 407          |\n",
      "|    time_elapsed         | 390          |\n",
      "|    total_timesteps      | 833536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036927206 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.97944933   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.69         |\n",
      "|    n_updates            | 4060         |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "Épisode 547/1000 terminé. Récompense: 861.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 720          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032055718 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.96660733   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 4070         |\n",
      "|    policy_gradient_loss | -0.000965    |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "Épisode 548/1000 terminé. Récompense: 921.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 725          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 409          |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 837632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036540146 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.9658207    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.515        |\n",
      "|    n_updates            | 4080         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 725          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 410          |\n",
      "|    time_elapsed         | 393          |\n",
      "|    total_timesteps      | 839680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020076325 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.9589489    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.792        |\n",
      "|    n_updates            | 4090         |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "Épisode 549/1000 terminé. Récompense: 1113.96\n",
      "Épisode 550/1000 terminé. Récompense: 89.84\n",
      "Épisode 551/1000 terminé. Récompense: 632.94\n",
      "Épisode 552/1000 terminé. Récompense: 100.63\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 718         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2133        |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005134208 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.44060928  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.368       |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "Épisode 553/1000 terminé. Récompense: 211.54\n",
      "Épisode 554/1000 terminé. Récompense: 634.17\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 705          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 412          |\n",
      "|    time_elapsed         | 395          |\n",
      "|    total_timesteps      | 843776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013781963 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.9780658    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 4110         |\n",
      "|    policy_gradient_loss | 3.26e-05     |\n",
      "|    value_loss           | 2.32         |\n",
      "------------------------------------------\n",
      "Épisode 555/1000 terminé. Récompense: 544.60\n",
      "Épisode 556/1000 terminé. Récompense: 145.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 702          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 413          |\n",
      "|    time_elapsed         | 396          |\n",
      "|    total_timesteps      | 845824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017217451 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.977374     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.914        |\n",
      "|    n_updates            | 4120         |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    value_loss           | 1.74         |\n",
      "------------------------------------------\n",
      "Épisode 557/1000 terminé. Récompense: 864.73\n",
      "Épisode 558/1000 terminé. Récompense: 81.11\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027752342 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.9792206    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.604        |\n",
      "|    n_updates            | 4130         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "Épisode 559/1000 terminé. Récompense: 674.84\n",
      "Épisode 560/1000 terminé. Récompense: 197.30\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 415          |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 849920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021590018 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.97844905   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.613        |\n",
      "|    n_updates            | 4140         |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    value_loss           | 1.67         |\n",
      "------------------------------------------\n",
      "Épisode 561/1000 terminé. Récompense: 267.45\n",
      "Épisode 562/1000 terminé. Récompense: 637.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 416          |\n",
      "|    time_elapsed         | 399          |\n",
      "|    total_timesteps      | 851968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024501053 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.97842485   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.471        |\n",
      "|    n_updates            | 4150         |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "Épisode 563/1000 terminé. Récompense: 402.70\n",
      "Épisode 564/1000 terminé. Récompense: 200.13\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 400          |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062403157 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.97868353   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06         |\n",
      "|    n_updates            | 4160         |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "Épisode 565/1000 terminé. Récompense: 1107.84\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 418          |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 856064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034210577 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.97980475   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.643        |\n",
      "|    n_updates            | 4170         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "Épisode 566/1000 terminé. Récompense: 1131.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 419          |\n",
      "|    time_elapsed         | 402          |\n",
      "|    total_timesteps      | 858112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065443236 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.9693073    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.439        |\n",
      "|    n_updates            | 4180         |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "Épisode 567/1000 terminé. Récompense: 627.37\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 420          |\n",
      "|    time_elapsed         | 403          |\n",
      "|    total_timesteps      | 860160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031996763 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.9595792    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.596        |\n",
      "|    n_updates            | 4190         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    value_loss           | 1.68         |\n",
      "------------------------------------------\n",
      "Épisode 568/1000 terminé. Récompense: 833.43\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 678         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005022359 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.607      |\n",
      "|    explained_variance   | 0.9662596   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.951       |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | 7.95e-06    |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "Épisode 569/1000 terminé. Récompense: 799.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 404          |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042918865 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.95878655   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 4210         |\n",
      "|    policy_gradient_loss | -0.00874     |\n",
      "|    value_loss           | 1.83         |\n",
      "------------------------------------------\n",
      "Épisode 570/1000 terminé. Récompense: 1154.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 423          |\n",
      "|    time_elapsed         | 405          |\n",
      "|    total_timesteps      | 866304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025426028 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.96834755   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.519        |\n",
      "|    n_updates            | 4220         |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 406          |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030129855 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.9622119    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.577        |\n",
      "|    n_updates            | 4230         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.67         |\n",
      "------------------------------------------\n",
      "Épisode 571/1000 terminé. Récompense: 1077.47\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+03   |\n",
      "|    ep_rew_mean          | 691        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2134       |\n",
      "|    iterations           | 425        |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 870400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00522794 |\n",
      "|    clip_fraction        | 0.0639     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.525     |\n",
      "|    explained_variance   | 0.36286455 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.47       |\n",
      "|    n_updates            | 4240       |\n",
      "|    policy_gradient_loss | -0.0065    |\n",
      "|    value_loss           | 1.31       |\n",
      "----------------------------------------\n",
      "Épisode 572/1000 terminé. Récompense: 1231.35\n",
      "Épisode 573/1000 terminé. Récompense: 463.81\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 426          |\n",
      "|    time_elapsed         | 408          |\n",
      "|    total_timesteps      | 872448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036555938 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.9623504    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.662        |\n",
      "|    n_updates            | 4250         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 409          |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014563524 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.97549415   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.61         |\n",
      "|    n_updates            | 4260         |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "Épisode 574/1000 terminé. Récompense: 951.77\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 428          |\n",
      "|    time_elapsed         | 410          |\n",
      "|    total_timesteps      | 876544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069894847 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.7127024    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.714        |\n",
      "|    n_updates            | 4270         |\n",
      "|    policy_gradient_loss | -0.00814     |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "Épisode 575/1000 terminé. Récompense: 961.23\n",
      "Épisode 576/1000 terminé. Récompense: 759.04\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 411          |\n",
      "|    total_timesteps      | 878592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029862002 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.9565187    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.843        |\n",
      "|    n_updates            | 4280         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 1.51         |\n",
      "------------------------------------------\n",
      "Épisode 577/1000 terminé. Récompense: 675.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 700          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 430          |\n",
      "|    time_elapsed         | 412          |\n",
      "|    total_timesteps      | 880640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014268752 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.9738073    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.814        |\n",
      "|    n_updates            | 4290         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.83         |\n",
      "------------------------------------------\n",
      "Épisode 578/1000 terminé. Récompense: 841.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 702          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032229188 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.9592489    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.509        |\n",
      "|    n_updates            | 4300         |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "Épisode 579/1000 terminé. Récompense: 882.06\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 702          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 414          |\n",
      "|    total_timesteps      | 884736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013683883 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.96141607   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.714        |\n",
      "|    n_updates            | 4310         |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "Épisode 580/1000 terminé. Récompense: 929.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 711          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 433          |\n",
      "|    time_elapsed         | 415          |\n",
      "|    total_timesteps      | 886784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024239514 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.9635801    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.588        |\n",
      "|    n_updates            | 4320         |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 711          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022861185 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.9703341    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.685        |\n",
      "|    n_updates            | 4330         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "Épisode 581/1000 terminé. Récompense: 1307.95\n",
      "Épisode 582/1000 terminé. Récompense: 813.24\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 717         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006806978 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.4836293   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.602       |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "Épisode 583/1000 terminé. Récompense: 553.53\n",
      "Épisode 584/1000 terminé. Récompense: 20.71\n",
      "Épisode 585/1000 terminé. Récompense: 234.22\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 701          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 436          |\n",
      "|    time_elapsed         | 418          |\n",
      "|    total_timesteps      | 892928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022267709 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.97501576   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.796        |\n",
      "|    n_updates            | 4350         |\n",
      "|    policy_gradient_loss | 0.000298     |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 701         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002474574 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | 0.9847419   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.817       |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "Épisode 586/1000 terminé. Récompense: 1090.95\n",
      "Épisode 587/1000 terminé. Récompense: 81.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 438          |\n",
      "|    time_elapsed         | 420          |\n",
      "|    total_timesteps      | 897024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040894533 |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.46531594   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.539        |\n",
      "|    n_updates            | 4370         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "Épisode 588/1000 terminé. Récompense: 1139.84\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | 685         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002549953 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | 0.97813416  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.94        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "Épisode 589/1000 terminé. Récompense: 620.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 440          |\n",
      "|    time_elapsed         | 422          |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030788037 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.9657746    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.761        |\n",
      "|    n_updates            | 4390         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 1.52         |\n",
      "------------------------------------------\n",
      "Épisode 590/1000 terminé. Récompense: 1013.16\n",
      "Épisode 591/1000 terminé. Récompense: 209.85\n",
      "Épisode 592/1000 terminé. Récompense: 368.10\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 674          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 423          |\n",
      "|    total_timesteps      | 903168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027512426 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.968878     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.723        |\n",
      "|    n_updates            | 4400         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n",
      "Épisode 593/1000 terminé. Récompense: 108.17\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 442          |\n",
      "|    time_elapsed         | 424          |\n",
      "|    total_timesteps      | 905216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010750284 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.986292     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.948        |\n",
      "|    n_updates            | 4410         |\n",
      "|    policy_gradient_loss | 0.000242     |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "Épisode 594/1000 terminé. Récompense: 918.81\n",
      "Épisode 595/1000 terminé. Récompense: 327.89\n",
      "Épisode 596/1000 terminé. Récompense: 458.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 424          |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032383404 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.94549555   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.832        |\n",
      "|    n_updates            | 4420         |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "Épisode 597/1000 terminé. Récompense: 897.63\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 666          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 444          |\n",
      "|    time_elapsed         | 425          |\n",
      "|    total_timesteps      | 909312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015388789 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.98363864   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.704        |\n",
      "|    n_updates            | 4430         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "Épisode 598/1000 terminé. Récompense: 264.39\n",
      "Épisode 599/1000 terminé. Récompense: 264.90\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 445          |\n",
      "|    time_elapsed         | 426          |\n",
      "|    total_timesteps      | 911360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026189256 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.959405     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.683        |\n",
      "|    n_updates            | 4440         |\n",
      "|    policy_gradient_loss | 0.000336     |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "Épisode 600/1000 terminé. Récompense: 922.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 446          |\n",
      "|    time_elapsed         | 427          |\n",
      "|    total_timesteps      | 913408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019608475 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.9772317    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.613        |\n",
      "|    n_updates            | 4450         |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "Épisode 601/1000 terminé. Récompense: 928.37\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 447          |\n",
      "|    time_elapsed         | 428          |\n",
      "|    total_timesteps      | 915456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042417645 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.9586035    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.751        |\n",
      "|    n_updates            | 4460         |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n",
      "Épisode 602/1000 terminé. Récompense: 531.19\n",
      "Épisode 603/1000 terminé. Récompense: 432.40\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 661         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003585435 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.9656017   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.714       |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 661          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 430          |\n",
      "|    total_timesteps      | 919552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039262394 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.9782969    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.931        |\n",
      "|    n_updates            | 4480         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.68         |\n",
      "------------------------------------------\n",
      "Épisode 604/1000 terminé. Récompense: 1174.44\n",
      "Épisode 605/1000 terminé. Récompense: 672.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 670          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 450          |\n",
      "|    time_elapsed         | 431          |\n",
      "|    total_timesteps      | 921600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034087398 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.94794834   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.807        |\n",
      "|    n_updates            | 4490         |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 1.87         |\n",
      "------------------------------------------\n",
      "Épisode 606/1000 terminé. Récompense: 854.86\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 451          |\n",
      "|    time_elapsed         | 432          |\n",
      "|    total_timesteps      | 923648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029096447 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.9700796    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.81         |\n",
      "|    n_updates            | 4500         |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "Épisode 607/1000 terminé. Récompense: 1060.89\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 666         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004813966 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.96737754  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.626       |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "Épisode 608/1000 terminé. Récompense: 342.46\n",
      "Épisode 609/1000 terminé. Récompense: 197.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 434          |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063039134 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.9644354    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.548        |\n",
      "|    n_updates            | 4520         |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    value_loss           | 1.51         |\n",
      "------------------------------------------\n",
      "Épisode 610/1000 terminé. Récompense: 1332.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 669          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 435          |\n",
      "|    total_timesteps      | 929792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033670068 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.9855872    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.694        |\n",
      "|    n_updates            | 4530         |\n",
      "|    policy_gradient_loss | -0.000406    |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "Épisode 611/1000 terminé. Récompense: 737.45\n",
      "Épisode 612/1000 terminé. Récompense: 112.62\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 455          |\n",
      "|    time_elapsed         | 436          |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024702125 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.9682769    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.707        |\n",
      "|    n_updates            | 4540         |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 667         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003293993 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.9794402   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "Épisode 613/1000 terminé. Récompense: 1200.44\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 672         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010396141 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.2212081   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.769       |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "Épisode 614/1000 terminé. Récompense: 1079.69\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 439          |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015887045 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.649       |\n",
      "|    explained_variance   | 0.9619232    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.888        |\n",
      "|    n_updates            | 4570         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 1.73         |\n",
      "------------------------------------------\n",
      "Épisode 615/1000 terminé. Récompense: 1052.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 680          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 459          |\n",
      "|    time_elapsed         | 440          |\n",
      "|    total_timesteps      | 940032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028062763 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.601       |\n",
      "|    explained_variance   | 0.9679115    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.501        |\n",
      "|    n_updates            | 4580         |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "Épisode 616/1000 terminé. Récompense: 775.69\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 441          |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033300773 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.9598645    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.563        |\n",
      "|    n_updates            | 4590         |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "Épisode 617/1000 terminé. Récompense: 1135.98\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+03   |\n",
      "|    ep_rew_mean          | 683        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2135       |\n",
      "|    iterations           | 461        |\n",
      "|    time_elapsed         | 442        |\n",
      "|    total_timesteps      | 944128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00431751 |\n",
      "|    clip_fraction        | 0.0278     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.579     |\n",
      "|    explained_variance   | 0.96510375 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.811      |\n",
      "|    n_updates            | 4600       |\n",
      "|    policy_gradient_loss | -0.00526   |\n",
      "|    value_loss           | 1.43       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | 683         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002256927 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.9632803   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.934       |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "Épisode 618/1000 terminé. Récompense: 970.53\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 692         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004921886 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.4345796   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.715       |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "Épisode 619/1000 terminé. Récompense: 1044.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 702          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 464          |\n",
      "|    time_elapsed         | 445          |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020477192 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.96581244   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.579        |\n",
      "|    n_updates            | 4630         |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "Épisode 620/1000 terminé. Récompense: 1054.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 705          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 465          |\n",
      "|    time_elapsed         | 446          |\n",
      "|    total_timesteps      | 952320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029682796 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.96930015   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.753        |\n",
      "|    n_updates            | 4640         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n",
      "Épisode 621/1000 terminé. Récompense: 1235.58\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 705         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004089469 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.9705014   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.559       |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | 705          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 467          |\n",
      "|    time_elapsed         | 448          |\n",
      "|    total_timesteps      | 956416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036508413 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.59        |\n",
      "|    explained_variance   | 0.9673696    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.743        |\n",
      "|    n_updates            | 4660         |\n",
      "|    policy_gradient_loss | 0.000163     |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "Épisode 622/1000 terminé. Récompense: 1212.21\n",
      "Épisode 623/1000 terminé. Récompense: 46.29\n",
      "Épisode 624/1000 terminé. Récompense: 41.16\n",
      "Épisode 625/1000 terminé. Récompense: 480.51\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.57e+03   |\n",
      "|    ep_rew_mean          | 684        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2133       |\n",
      "|    iterations           | 468        |\n",
      "|    time_elapsed         | 449        |\n",
      "|    total_timesteps      | 958464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00596428 |\n",
      "|    clip_fraction        | 0.0656     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.574     |\n",
      "|    explained_variance   | 0.19267786 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.59       |\n",
      "|    n_updates            | 4670       |\n",
      "|    policy_gradient_loss | -0.00727   |\n",
      "|    value_loss           | 1.42       |\n",
      "----------------------------------------\n",
      "Épisode 626/1000 terminé. Récompense: 828.17\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 691         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2133        |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002640353 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.98323226  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.695       |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "Épisode 627/1000 terminé. Récompense: 928.76\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 696          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 451          |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023815448 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.9614474    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.685        |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "Épisode 628/1000 terminé. Récompense: 463.73\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 452          |\n",
      "|    total_timesteps      | 964608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056701847 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.9630233    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.733        |\n",
      "|    n_updates            | 4700         |\n",
      "|    policy_gradient_loss | -0.00752     |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "Épisode 629/1000 terminé. Récompense: 775.34\n",
      "Épisode 630/1000 terminé. Récompense: 603.01\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 472          |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 966656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020571265 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.95953333   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.541        |\n",
      "|    n_updates            | 4710         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "Épisode 631/1000 terminé. Récompense: 703.89\n",
      "Épisode 632/1000 terminé. Récompense: 164.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021227524 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.97803587   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.627        |\n",
      "|    n_updates            | 4720         |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "Épisode 633/1000 terminé. Récompense: 475.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 474          |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 970752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034548035 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.9765541    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.504        |\n",
      "|    n_updates            | 4730         |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "Épisode 634/1000 terminé. Récompense: 640.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2133         |\n",
      "|    iterations           | 475          |\n",
      "|    time_elapsed         | 455          |\n",
      "|    total_timesteps      | 972800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022766446 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.9595144    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.734        |\n",
      "|    n_updates            | 4740         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "Épisode 635/1000 terminé. Récompense: 1082.42\n",
      "Épisode 636/1000 terminé. Récompense: 335.73\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 683         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2133        |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002003794 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.9631392   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.598       |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "Épisode 637/1000 terminé. Récompense: 257.21\n",
      "Épisode 638/1000 terminé. Récompense: 57.33\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 671         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003436115 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.9787929   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.448       |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "Épisode 639/1000 terminé. Récompense: 1001.87\n",
      "Épisode 640/1000 terminé. Récompense: 532.51\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 478          |\n",
      "|    time_elapsed         | 458          |\n",
      "|    total_timesteps      | 978944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014946669 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.97669584   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.749        |\n",
      "|    n_updates            | 4770         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "Épisode 641/1000 terminé. Récompense: 281.11\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 673          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 479          |\n",
      "|    time_elapsed         | 459          |\n",
      "|    total_timesteps      | 980992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020105692 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.97989726   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.438        |\n",
      "|    n_updates            | 4780         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "Épisode 642/1000 terminé. Récompense: 946.51\n",
      "Épisode 643/1000 terminé. Récompense: 604.42\n",
      "Épisode 644/1000 terminé. Récompense: 96.30\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 460          |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034785683 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.9650302    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.549        |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "Épisode 645/1000 terminé. Récompense: 264.68\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 664         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003677038 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.98456895  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.48        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "Épisode 646/1000 terminé. Récompense: 882.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 462          |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055716187 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.9651816    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.402        |\n",
      "|    n_updates            | 4810         |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "Épisode 647/1000 terminé. Récompense: 796.98\n",
      "Épisode 648/1000 terminé. Récompense: 565.23\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025368966 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.96812046   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.778        |\n",
      "|    n_updates            | 4820         |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "Épisode 649/1000 terminé. Récompense: 503.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 484          |\n",
      "|    time_elapsed         | 464          |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051188897 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.9794349    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.77         |\n",
      "|    n_updates            | 4830         |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "Épisode 650/1000 terminé. Récompense: 1181.97\n",
      "Épisode 651/1000 terminé. Récompense: 190.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 659          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 485          |\n",
      "|    time_elapsed         | 465          |\n",
      "|    total_timesteps      | 993280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029263238 |\n",
      "|    clip_fraction        | 0.0543       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.9659286    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.834        |\n",
      "|    n_updates            | 4840         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "Épisode 652/1000 terminé. Récompense: 452.99\n",
      "Épisode 653/1000 terminé. Récompense: 497.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 665          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 486          |\n",
      "|    time_elapsed         | 466          |\n",
      "|    total_timesteps      | 995328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023437613 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.98181266   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.433        |\n",
      "|    n_updates            | 4850         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 665          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 467          |\n",
      "|    total_timesteps      | 997376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030991118 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.9822211    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.623        |\n",
      "|    n_updates            | 4860         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 654/1000 terminé. Récompense: 1214.64\n",
      "Épisode 655/1000 terminé. Récompense: 431.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 670          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2134         |\n",
      "|    iterations           | 488          |\n",
      "|    time_elapsed         | 468          |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043709846 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.5328059    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.585        |\n",
      "|    n_updates            | 4870         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "Épisode 656/1000 terminé. Récompense: 462.96\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 673         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003895552 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 0.977671    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.414       |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "Épisode 657/1000 terminé. Récompense: 1386.00\n",
      "Épisode 658/1000 terminé. Récompense: 171.87\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 679         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002661084 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.97106236  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.836       |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 491          |\n",
      "|    time_elapsed         | 470          |\n",
      "|    total_timesteps      | 1005568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019565113 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.98376065   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.698        |\n",
      "|    n_updates            | 4900         |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "Épisode 659/1000 terminé. Récompense: 1295.75\n",
      "Épisode 660/1000 terminé. Récompense: 148.84\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 492          |\n",
      "|    time_elapsed         | 471          |\n",
      "|    total_timesteps      | 1007616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037555215 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.29014415   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.643        |\n",
      "|    n_updates            | 4910         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "Épisode 661/1000 terminé. Récompense: 947.14\n",
      "Épisode 662/1000 terminé. Récompense: 372.35\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 689          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 472          |\n",
      "|    total_timesteps      | 1009664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016207356 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.97929466   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.684        |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.000443    |\n",
      "|    value_loss           | 1.63         |\n",
      "------------------------------------------\n",
      "Épisode 663/1000 terminé. Récompense: 761.26\n",
      "Épisode 664/1000 terminé. Récompense: 309.56\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 494          |\n",
      "|    time_elapsed         | 473          |\n",
      "|    total_timesteps      | 1011712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033444501 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.98191977   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.528        |\n",
      "|    n_updates            | 4930         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "Épisode 665/1000 terminé. Récompense: 271.84\n",
      "Épisode 666/1000 terminé. Récompense: 498.74\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.55e+03   |\n",
      "|    ep_rew_mean          | 679        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2135       |\n",
      "|    iterations           | 495        |\n",
      "|    time_elapsed         | 474        |\n",
      "|    total_timesteps      | 1013760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00207785 |\n",
      "|    clip_fraction        | 0.0109     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.533     |\n",
      "|    explained_variance   | 0.98469925 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.663      |\n",
      "|    n_updates            | 4940       |\n",
      "|    policy_gradient_loss | -0.00308   |\n",
      "|    value_loss           | 1.19       |\n",
      "----------------------------------------\n",
      "Épisode 667/1000 terminé. Récompense: 580.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 496          |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025714466 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.98507065   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.634        |\n",
      "|    n_updates            | 4950         |\n",
      "|    policy_gradient_loss | 0.000209     |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "Épisode 668/1000 terminé. Récompense: 1136.68\n",
      "Épisode 669/1000 terminé. Récompense: 250.98\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 476          |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043018986 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.9721314    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.57         |\n",
      "|    n_updates            | 4960         |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n",
      "Épisode 670/1000 terminé. Récompense: 706.06\n",
      "Épisode 671/1000 terminé. Récompense: 24.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 661          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 477          |\n",
      "|    total_timesteps      | 1019904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026243227 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | 0.98232794   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.706        |\n",
      "|    n_updates            | 4970         |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "Épisode 672/1000 terminé. Récompense: 554.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 654         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 478         |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002183327 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | 0.9807816   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.554       |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "Épisode 673/1000 terminé. Récompense: 661.49\n",
      "Épisode 674/1000 terminé. Récompense: 526.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 479          |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050539807 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.970655     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.634        |\n",
      "|    n_updates            | 4990         |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "Épisode 675/1000 terminé. Récompense: 261.04\n",
      "Épisode 676/1000 terminé. Récompense: 780.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 645          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 501          |\n",
      "|    time_elapsed         | 480          |\n",
      "|    total_timesteps      | 1026048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029012254 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.985907     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.52         |\n",
      "|    n_updates            | 5000         |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 645         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003436007 |\n",
      "|    clip_fraction        | 0.0327      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.9806338   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.584       |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "Épisode 677/1000 terminé. Récompense: 1341.65\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 503          |\n",
      "|    time_elapsed         | 482          |\n",
      "|    total_timesteps      | 1030144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066995453 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.25019926   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.761        |\n",
      "|    n_updates            | 5020         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "Épisode 678/1000 terminé. Récompense: 802.76\n",
      "Épisode 679/1000 terminé. Récompense: 460.79\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 647          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 483          |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017519447 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.9666447    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.736        |\n",
      "|    n_updates            | 5030         |\n",
      "|    policy_gradient_loss | -0.000704    |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "Épisode 680/1000 terminé. Récompense: 509.84\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 643         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2135        |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002988863 |\n",
      "|    clip_fraction        | 0.0268      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.9806151   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.804       |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "Épisode 681/1000 terminé. Récompense: 1329.82\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 643          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 506          |\n",
      "|    time_elapsed         | 485          |\n",
      "|    total_timesteps      | 1036288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021130044 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.9763283    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.85         |\n",
      "|    n_updates            | 5050         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "Épisode 682/1000 terminé. Récompense: 741.80\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 643          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 486          |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032613836 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.96434385   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.646        |\n",
      "|    n_updates            | 5060         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "Épisode 683/1000 terminé. Récompense: 538.96\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 642          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2135         |\n",
      "|    iterations           | 508          |\n",
      "|    time_elapsed         | 487          |\n",
      "|    total_timesteps      | 1040384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018333186 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.96905416   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.483        |\n",
      "|    n_updates            | 5070         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n",
      "Épisode 684/1000 terminé. Récompense: 1309.43\n",
      "Épisode 685/1000 terminé. Récompense: 372.92\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 657          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 509          |\n",
      "|    time_elapsed         | 488          |\n",
      "|    total_timesteps      | 1042432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028211041 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.9734434    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.552        |\n",
      "|    n_updates            | 5080         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "Épisode 686/1000 terminé. Récompense: 226.32\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 648          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 510          |\n",
      "|    time_elapsed         | 488          |\n",
      "|    total_timesteps      | 1044480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028826818 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.98427886   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.407        |\n",
      "|    n_updates            | 5090         |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "Épisode 687/1000 terminé. Récompense: 870.82\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 656          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 511          |\n",
      "|    time_elapsed         | 489          |\n",
      "|    total_timesteps      | 1046528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024828487 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.96721673   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.494        |\n",
      "|    n_updates            | 5100         |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 688/1000 terminé. Récompense: 1154.69\n",
      "Épisode 689/1000 terminé. Récompense: 275.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 512          |\n",
      "|    time_elapsed         | 490          |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038803625 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.9666988    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.883        |\n",
      "|    n_updates            | 5110         |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "Épisode 690/1000 terminé. Récompense: 818.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 651          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 513          |\n",
      "|    time_elapsed         | 491          |\n",
      "|    total_timesteps      | 1050624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031411839 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.98439974   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 5120         |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 691/1000 terminé. Récompense: 746.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 656         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2136        |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007381023 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.96385676  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.84        |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "Épisode 692/1000 terminé. Récompense: 822.36\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 661          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 493          |\n",
      "|    total_timesteps      | 1054720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023381067 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.9666723    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.461        |\n",
      "|    n_updates            | 5140         |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "Épisode 693/1000 terminé. Récompense: 565.84\n",
      "Épisode 694/1000 terminé. Récompense: 674.58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 516          |\n",
      "|    time_elapsed         | 494          |\n",
      "|    total_timesteps      | 1056768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034430549 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.98308164   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.402        |\n",
      "|    n_updates            | 5150         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 517          |\n",
      "|    time_elapsed         | 495          |\n",
      "|    total_timesteps      | 1058816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026380615 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.9795273    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.528        |\n",
      "|    n_updates            | 5160         |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "Épisode 695/1000 terminé. Récompense: 1346.97\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 673         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2136        |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005654831 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.22319436  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.505       |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "Épisode 696/1000 terminé. Récompense: 1086.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 519          |\n",
      "|    time_elapsed         | 497          |\n",
      "|    total_timesteps      | 1062912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019027964 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.96120185   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.441        |\n",
      "|    n_updates            | 5180         |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "Épisode 697/1000 terminé. Récompense: 871.65\n",
      "Épisode 698/1000 terminé. Récompense: 536.60\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 520          |\n",
      "|    time_elapsed         | 498          |\n",
      "|    total_timesteps      | 1064960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021991231 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.9641699    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.604        |\n",
      "|    n_updates            | 5190         |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 699/1000 terminé. Récompense: 538.02\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 1067008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017506243 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.9836995    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.493        |\n",
      "|    n_updates            | 5200         |\n",
      "|    policy_gradient_loss | -0.000906    |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "Épisode 700/1000 terminé. Récompense: 1130.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 500          |\n",
      "|    total_timesteps      | 1069056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027264426 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.9713813    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.539        |\n",
      "|    n_updates            | 5210         |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 523          |\n",
      "|    time_elapsed         | 501          |\n",
      "|    total_timesteps      | 1071104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040974114 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.97582036   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.623        |\n",
      "|    n_updates            | 5220         |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "Épisode 701/1000 terminé. Récompense: 1337.41\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.57e+03   |\n",
      "|    ep_rew_mean          | 691        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2136       |\n",
      "|    iterations           | 524        |\n",
      "|    time_elapsed         | 502        |\n",
      "|    total_timesteps      | 1073152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00725579 |\n",
      "|    clip_fraction        | 0.0692     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | 0.19189787 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.56       |\n",
      "|    n_updates            | 5230       |\n",
      "|    policy_gradient_loss | 0.00045    |\n",
      "|    value_loss           | 1.3        |\n",
      "----------------------------------------\n",
      "Épisode 702/1000 terminé. Récompense: 795.55\n",
      "Épisode 703/1000 terminé. Récompense: 615.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 695          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 525          |\n",
      "|    time_elapsed         | 503          |\n",
      "|    total_timesteps      | 1075200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015346035 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.9678492    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.547        |\n",
      "|    n_updates            | 5240         |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 695          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 526          |\n",
      "|    time_elapsed         | 504          |\n",
      "|    total_timesteps      | 1077248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033623278 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.98213      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.472        |\n",
      "|    n_updates            | 5250         |\n",
      "|    policy_gradient_loss | -0.000903    |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 704/1000 terminé. Récompense: 1151.33\n",
      "Épisode 705/1000 terminé. Récompense: 401.64\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 527          |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 1079296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036537875 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.24725276   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.552        |\n",
      "|    n_updates            | 5260         |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "Épisode 706/1000 terminé. Récompense: 352.04\n",
      "Épisode 707/1000 terminé. Récompense: 826.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 528          |\n",
      "|    time_elapsed         | 506          |\n",
      "|    total_timesteps      | 1081344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013935742 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.9822138    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.479        |\n",
      "|    n_updates            | 5270         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "Épisode 708/1000 terminé. Récompense: 482.23\n",
      "Épisode 709/1000 terminé. Récompense: 93.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 507          |\n",
      "|    total_timesteps      | 1083392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015361239 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.97628784   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.676        |\n",
      "|    n_updates            | 5280         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "Épisode 710/1000 terminé. Récompense: 1089.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2136         |\n",
      "|    iterations           | 530          |\n",
      "|    time_elapsed         | 507          |\n",
      "|    total_timesteps      | 1085440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022296747 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.983134     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.557        |\n",
      "|    n_updates            | 5290         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "Épisode 711/1000 terminé. Récompense: 606.44\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 681         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2137        |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 508         |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003808381 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.95995295  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.621       |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "Épisode 712/1000 terminé. Récompense: 738.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 532          |\n",
      "|    time_elapsed         | 509          |\n",
      "|    total_timesteps      | 1089536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026537995 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.9669075    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.485        |\n",
      "|    n_updates            | 5310         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "Épisode 713/1000 terminé. Récompense: 933.13\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 533          |\n",
      "|    time_elapsed         | 510          |\n",
      "|    total_timesteps      | 1091584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035373764 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.96856123   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.465        |\n",
      "|    n_updates            | 5320         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "Épisode 714/1000 terminé. Récompense: 1116.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 511          |\n",
      "|    total_timesteps      | 1093632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041054464 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.9694525    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.359        |\n",
      "|    n_updates            | 5330         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "Épisode 715/1000 terminé. Récompense: 1097.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 512          |\n",
      "|    total_timesteps      | 1095680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038723655 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.9719917    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.594        |\n",
      "|    n_updates            | 5340         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "Épisode 716/1000 terminé. Récompense: 390.63\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 536          |\n",
      "|    time_elapsed         | 513          |\n",
      "|    total_timesteps      | 1097728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025113293 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.9724205    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.551        |\n",
      "|    n_updates            | 5350         |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "Épisode 717/1000 terminé. Récompense: 1190.75\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 682         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2137        |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004802126 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.9666674   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.624       |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "Épisode 718/1000 terminé. Récompense: 542.91\n",
      "Épisode 719/1000 terminé. Récompense: 124.38\n",
      "Épisode 720/1000 terminé. Récompense: 379.67\n",
      "Épisode 721/1000 terminé. Récompense: 50.65\n",
      "Épisode 722/1000 terminé. Récompense: 33.25\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 639          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 538          |\n",
      "|    time_elapsed         | 515          |\n",
      "|    total_timesteps      | 1101824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031038292 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.9732822    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.38         |\n",
      "|    n_updates            | 5370         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 723/1000 terminé. Récompense: 908.37\n",
      "Épisode 724/1000 terminé. Récompense: 123.10\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | 648          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 516          |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033101786 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.9925973    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.355        |\n",
      "|    n_updates            | 5380         |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 648         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2137        |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003094058 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.9837594   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.398       |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "Épisode 725/1000 terminé. Récompense: 1088.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 654          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 541          |\n",
      "|    time_elapsed         | 518          |\n",
      "|    total_timesteps      | 1107968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049830684 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.8814459    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.457        |\n",
      "|    n_updates            | 5400         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Épisode 726/1000 terminé. Récompense: 1196.82\n",
      "Épisode 727/1000 terminé. Récompense: 287.20\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 651          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 542          |\n",
      "|    time_elapsed         | 519          |\n",
      "|    total_timesteps      | 1110016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056103384 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.9618483    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.96         |\n",
      "|    n_updates            | 5410         |\n",
      "|    policy_gradient_loss | 0.000625     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 728/1000 terminé. Récompense: 1082.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 543          |\n",
      "|    time_elapsed         | 520          |\n",
      "|    total_timesteps      | 1112064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019013893 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.98742455   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.592        |\n",
      "|    n_updates            | 5420         |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 544          |\n",
      "|    time_elapsed         | 521          |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033979425 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.9747474    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.463        |\n",
      "|    n_updates            | 5430         |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 1.49         |\n",
      "------------------------------------------\n",
      "Épisode 729/1000 terminé. Récompense: 1385.74\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 522          |\n",
      "|    total_timesteps      | 1116160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066720895 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.24950248   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.7          |\n",
      "|    n_updates            | 5440         |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "Épisode 730/1000 terminé. Récompense: 734.08\n",
      "Épisode 731/1000 terminé. Récompense: 146.12\n",
      "Épisode 732/1000 terminé. Récompense: 151.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 659          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 546          |\n",
      "|    time_elapsed         | 523          |\n",
      "|    total_timesteps      | 1118208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020340942 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.9713201    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.483        |\n",
      "|    n_updates            | 5450         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "Épisode 733/1000 terminé. Récompense: 1377.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2137         |\n",
      "|    iterations           | 547          |\n",
      "|    time_elapsed         | 523          |\n",
      "|    total_timesteps      | 1120256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016233292 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.9891944    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.581        |\n",
      "|    n_updates            | 5460         |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 548          |\n",
      "|    time_elapsed         | 524          |\n",
      "|    total_timesteps      | 1122304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037829669 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.9710976    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.577        |\n",
      "|    n_updates            | 5470         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "Épisode 734/1000 terminé. Récompense: 1121.45\n",
      "Épisode 735/1000 terminé. Récompense: 288.51\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 665          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 549          |\n",
      "|    time_elapsed         | 525          |\n",
      "|    total_timesteps      | 1124352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048523806 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.31432527   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.659        |\n",
      "|    n_updates            | 5480         |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    value_loss           | 1.34         |\n",
      "------------------------------------------\n",
      "Épisode 736/1000 terminé. Récompense: 535.05\n",
      "Épisode 737/1000 terminé. Récompense: 101.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 666          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 526          |\n",
      "|    total_timesteps      | 1126400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018413761 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.98113203   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.366        |\n",
      "|    n_updates            | 5490         |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 738/1000 terminé. Récompense: 1205.60\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027693845 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.97913486   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.65         |\n",
      "|    n_updates            | 5500         |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "Épisode 739/1000 terminé. Récompense: 900.48\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 676         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002319728 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.9641117   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.479       |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 1.52        |\n",
      "-----------------------------------------\n",
      "Épisode 740/1000 terminé. Récompense: 1053.72\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 553          |\n",
      "|    time_elapsed         | 529          |\n",
      "|    total_timesteps      | 1132544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036027788 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.9697165    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.484        |\n",
      "|    n_updates            | 5520         |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Épisode 741/1000 terminé. Récompense: 433.70\n",
      "Épisode 742/1000 terminé. Récompense: 670.90\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 680          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 554          |\n",
      "|    time_elapsed         | 530          |\n",
      "|    total_timesteps      | 1134592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026828796 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.9746567    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.598        |\n",
      "|    n_updates            | 5530         |\n",
      "|    policy_gradient_loss | -0.000828    |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "Épisode 743/1000 terminé. Récompense: 676.86\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 681         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002186268 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.9801187   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.511       |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "Épisode 744/1000 terminé. Récompense: 1189.71\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | 692         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005719835 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.9724598   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.576       |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.000909   |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "Épisode 745/1000 terminé. Récompense: 210.99\n",
      "Épisode 746/1000 terminé. Récompense: 71.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 557          |\n",
      "|    time_elapsed         | 533          |\n",
      "|    total_timesteps      | 1140736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032705064 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.96392983   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.693        |\n",
      "|    n_updates            | 5560         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "Épisode 747/1000 terminé. Récompense: 1105.03\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 558          |\n",
      "|    time_elapsed         | 534          |\n",
      "|    total_timesteps      | 1142784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032661916 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.98358864   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.556        |\n",
      "|    n_updates            | 5570         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "Épisode 748/1000 terminé. Récompense: 1135.59\n",
      "Épisode 749/1000 terminé. Récompense: 240.52\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 689         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008143717 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.97627157  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.699       |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.00064    |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "Épisode 750/1000 terminé. Récompense: 869.46\n",
      "Épisode 751/1000 terminé. Récompense: 71.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 560          |\n",
      "|    time_elapsed         | 536          |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030306196 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.98610526   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.331        |\n",
      "|    n_updates            | 5590         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "Épisode 752/1000 terminé. Récompense: 682.78\n",
      "Épisode 753/1000 terminé. Récompense: 99.10\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 561          |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 1148928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021669315 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.9850487    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.338        |\n",
      "|    n_updates            | 5600         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 562          |\n",
      "|    time_elapsed         | 538          |\n",
      "|    total_timesteps      | 1150976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026009248 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.98643637   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.327        |\n",
      "|    n_updates            | 5610         |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "Épisode 754/1000 terminé. Récompense: 1185.76\n",
      "Épisode 755/1000 terminé. Récompense: 228.63\n",
      "Épisode 756/1000 terminé. Récompense: 528.51\n",
      "Épisode 757/1000 terminé. Récompense: 63.16\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 668         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003367901 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | 0.8761991   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.64        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "Épisode 758/1000 terminé. Récompense: 732.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 674          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 564          |\n",
      "|    time_elapsed         | 540          |\n",
      "|    total_timesteps      | 1155072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024128847 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.99058425   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.699        |\n",
      "|    n_updates            | 5630         |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "Épisode 759/1000 terminé. Récompense: 1145.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 672          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 540          |\n",
      "|    total_timesteps      | 1157120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018633862 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.97102356   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.72         |\n",
      "|    n_updates            | 5640         |\n",
      "|    policy_gradient_loss | -0.000273    |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "Épisode 760/1000 terminé. Récompense: 772.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 1159168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040676473 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.9695186    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.705        |\n",
      "|    n_updates            | 5650         |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 761/1000 terminé. Récompense: 1083.82\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 680         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002783214 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.9722023   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.532       |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "Épisode 762/1000 terminé. Récompense: 167.71\n",
      "Épisode 763/1000 terminé. Récompense: 570.08\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 676         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003851517 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.96855736  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.785       |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "Épisode 764/1000 terminé. Récompense: 1010.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 569          |\n",
      "|    time_elapsed         | 544          |\n",
      "|    total_timesteps      | 1165312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030740947 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.98551184   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.511        |\n",
      "|    n_updates            | 5680         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "Épisode 765/1000 terminé. Récompense: 582.17\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 570          |\n",
      "|    time_elapsed         | 545          |\n",
      "|    total_timesteps      | 1167360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020069643 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.9693083    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.537        |\n",
      "|    n_updates            | 5690         |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n",
      "Épisode 766/1000 terminé. Récompense: 765.77\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.55e+03   |\n",
      "|    ep_rew_mean          | 689        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2139       |\n",
      "|    iterations           | 571        |\n",
      "|    time_elapsed         | 546        |\n",
      "|    total_timesteps      | 1169408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00533784 |\n",
      "|    clip_fraction        | 0.0479     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.431     |\n",
      "|    explained_variance   | 0.9716031  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.615      |\n",
      "|    n_updates            | 5700       |\n",
      "|    policy_gradient_loss | -0.00144   |\n",
      "|    value_loss           | 1.23       |\n",
      "----------------------------------------\n",
      "Épisode 767/1000 terminé. Récompense: 1214.33\n",
      "Épisode 768/1000 terminé. Récompense: 37.75\n",
      "Épisode 769/1000 terminé. Récompense: 0.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 572          |\n",
      "|    time_elapsed         | 547          |\n",
      "|    total_timesteps      | 1171456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017885112 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.96642905   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.646        |\n",
      "|    n_updates            | 5710         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 1.52         |\n",
      "------------------------------------------\n",
      "Épisode 770/1000 terminé. Récompense: 787.88\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 573          |\n",
      "|    time_elapsed         | 548          |\n",
      "|    total_timesteps      | 1173504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032336833 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.98154926   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.752        |\n",
      "|    n_updates            | 5720         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 771/1000 terminé. Récompense: 995.45\n",
      "Épisode 772/1000 terminé. Récompense: 306.03\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 574          |\n",
      "|    time_elapsed         | 549          |\n",
      "|    total_timesteps      | 1175552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030320436 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.9725101    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.666        |\n",
      "|    n_updates            | 5730         |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "Épisode 773/1000 terminé. Récompense: 820.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 691          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 575          |\n",
      "|    time_elapsed         | 550          |\n",
      "|    total_timesteps      | 1177600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024716891 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.98443735   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.595        |\n",
      "|    n_updates            | 5740         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "Épisode 774/1000 terminé. Récompense: 602.11\n",
      "Épisode 775/1000 terminé. Récompense: 187.12\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 691         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002727429 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.9686384   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.751       |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "Épisode 776/1000 terminé. Récompense: 606.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 577          |\n",
      "|    time_elapsed         | 552          |\n",
      "|    total_timesteps      | 1181696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036546742 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.9815627    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.686        |\n",
      "|    n_updates            | 5760         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "Épisode 777/1000 terminé. Récompense: 850.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 578          |\n",
      "|    time_elapsed         | 553          |\n",
      "|    total_timesteps      | 1183744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027170074 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.9714003    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.625        |\n",
      "|    n_updates            | 5770         |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "Épisode 778/1000 terminé. Récompense: 733.13\n",
      "Épisode 779/1000 terminé. Récompense: 759.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 579          |\n",
      "|    time_elapsed         | 554          |\n",
      "|    total_timesteps      | 1185792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024554417 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.9725581    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.645        |\n",
      "|    n_updates            | 5780         |\n",
      "|    policy_gradient_loss | 0.000438     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 780/1000 terminé. Récompense: 758.71\n",
      "Épisode 781/1000 terminé. Récompense: 58.70\n",
      "Épisode 782/1000 terminé. Récompense: 129.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 580          |\n",
      "|    time_elapsed         | 555          |\n",
      "|    total_timesteps      | 1187840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025419449 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.984344     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.875        |\n",
      "|    n_updates            | 5790         |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 581          |\n",
      "|    time_elapsed         | 556          |\n",
      "|    total_timesteps      | 1189888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020409105 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.98861754   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.663        |\n",
      "|    n_updates            | 5800         |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "Épisode 783/1000 terminé. Récompense: 1054.25\n",
      "Épisode 784/1000 terminé. Récompense: 624.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 669          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 582          |\n",
      "|    time_elapsed         | 557          |\n",
      "|    total_timesteps      | 1191936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045224167 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.34479964   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.778        |\n",
      "|    n_updates            | 5810         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 669          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 583          |\n",
      "|    time_elapsed         | 558          |\n",
      "|    total_timesteps      | 1193984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031067743 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.9841448    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.654        |\n",
      "|    n_updates            | 5820         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "Épisode 785/1000 terminé. Récompense: 1344.63\n",
      "Épisode 786/1000 terminé. Récompense: 577.60\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 584          |\n",
      "|    time_elapsed         | 559          |\n",
      "|    total_timesteps      | 1196032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038853697 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.2400459    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.744        |\n",
      "|    n_updates            | 5830         |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n",
      "Épisode 787/1000 terminé. Récompense: 587.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 560          |\n",
      "|    total_timesteps      | 1198080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012570745 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.98286927   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.699        |\n",
      "|    n_updates            | 5840         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "Épisode 788/1000 terminé. Récompense: 507.71\n",
      "Épisode 789/1000 terminé. Récompense: 851.52\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 586          |\n",
      "|    time_elapsed         | 561          |\n",
      "|    total_timesteps      | 1200128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015340485 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.97445536   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.593        |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 587          |\n",
      "|    time_elapsed         | 562          |\n",
      "|    total_timesteps      | 1202176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024778042 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.98464596   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.706        |\n",
      "|    n_updates            | 5860         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "Épisode 790/1000 terminé. Récompense: 1078.02\n",
      "Épisode 791/1000 terminé. Récompense: 448.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 588          |\n",
      "|    time_elapsed         | 563          |\n",
      "|    total_timesteps      | 1204224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061626327 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.3362087    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.819        |\n",
      "|    n_updates            | 5870         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "Épisode 792/1000 terminé. Récompense: 1188.56\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 589          |\n",
      "|    time_elapsed         | 564          |\n",
      "|    total_timesteps      | 1206272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010528258 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.98626614   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.619        |\n",
      "|    n_updates            | 5880         |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 0.971        |\n",
      "------------------------------------------\n",
      "Épisode 793/1000 terminé. Récompense: 494.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 564          |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020978118 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.97262      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.483        |\n",
      "|    n_updates            | 5890         |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "Épisode 794/1000 terminé. Récompense: 1155.86\n",
      "Épisode 795/1000 terminé. Récompense: 227.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 591          |\n",
      "|    time_elapsed         | 565          |\n",
      "|    total_timesteps      | 1210368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027615584 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.9760634    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.532        |\n",
      "|    n_updates            | 5900         |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "Épisode 796/1000 terminé. Récompense: 312.02\n",
      "Épisode 797/1000 terminé. Récompense: 358.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 592          |\n",
      "|    time_elapsed         | 566          |\n",
      "|    total_timesteps      | 1212416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018067985 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.9853722    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.556        |\n",
      "|    n_updates            | 5910         |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 567          |\n",
      "|    total_timesteps      | 1214464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019141877 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.9883376    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.52         |\n",
      "|    n_updates            | 5920         |\n",
      "|    policy_gradient_loss | 0.000799     |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 798/1000 terminé. Récompense: 1401.15\n",
      "Épisode 799/1000 terminé. Récompense: 638.45\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 672         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004276953 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.40282226  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.692       |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "Épisode 800/1000 terminé. Récompense: 378.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 595          |\n",
      "|    time_elapsed         | 569          |\n",
      "|    total_timesteps      | 1218560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026139712 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.98381317   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.654        |\n",
      "|    n_updates            | 5940         |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "Épisode 801/1000 terminé. Récompense: 1152.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 596          |\n",
      "|    time_elapsed         | 570          |\n",
      "|    total_timesteps      | 1220608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031727017 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.97461784   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.552        |\n",
      "|    n_updates            | 5950         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "Épisode 802/1000 terminé. Récompense: 1172.82\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.49e+03   |\n",
      "|    ep_rew_mean          | 666        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2139       |\n",
      "|    iterations           | 597        |\n",
      "|    time_elapsed         | 571        |\n",
      "|    total_timesteps      | 1222656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00403497 |\n",
      "|    clip_fraction        | 0.0304     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.431     |\n",
      "|    explained_variance   | 0.9745641  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.519      |\n",
      "|    n_updates            | 5960       |\n",
      "|    policy_gradient_loss | -0.00338   |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "Épisode 803/1000 terminé. Récompense: 410.97\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 664         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003801178 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.9718798   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.731       |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "Épisode 804/1000 terminé. Récompense: 989.18\n",
      "Épisode 805/1000 terminé. Récompense: 35.55\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 659          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 573          |\n",
      "|    total_timesteps      | 1226752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036744226 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.9743813    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.353        |\n",
      "|    n_updates            | 5980         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "Épisode 806/1000 terminé. Récompense: 648.44\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 574          |\n",
      "|    total_timesteps      | 1228800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018006903 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.9869829    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.325        |\n",
      "|    n_updates            | 5990         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "Épisode 807/1000 terminé. Récompense: 1334.85\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 601          |\n",
      "|    time_elapsed         | 575          |\n",
      "|    total_timesteps      | 1230848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042191707 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.9651738    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.534        |\n",
      "|    n_updates            | 6000         |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 808/1000 terminé. Récompense: 1392.12\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 576          |\n",
      "|    total_timesteps      | 1232896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024850895 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.98007715   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.739        |\n",
      "|    n_updates            | 6010         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 809/1000 terminé. Récompense: 905.12\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 603          |\n",
      "|    time_elapsed         | 577          |\n",
      "|    total_timesteps      | 1234944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038299088 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.9697276    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.777        |\n",
      "|    n_updates            | 6020         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "Épisode 810/1000 terminé. Récompense: 213.16\n",
      "Épisode 811/1000 terminé. Récompense: 489.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 674          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 604          |\n",
      "|    time_elapsed         | 578          |\n",
      "|    total_timesteps      | 1236992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030228626 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.9707909    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.492        |\n",
      "|    n_updates            | 6030         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Épisode 812/1000 terminé. Récompense: 721.54\n",
      "Épisode 813/1000 terminé. Récompense: 289.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 579          |\n",
      "|    total_timesteps      | 1239040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028376332 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.9840229    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.918        |\n",
      "|    n_updates            | 6040         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Épisode 814/1000 terminé. Récompense: 903.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 665          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 606          |\n",
      "|    time_elapsed         | 580          |\n",
      "|    total_timesteps      | 1241088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021252758 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.9858758    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.273        |\n",
      "|    n_updates            | 6050         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "Épisode 815/1000 terminé. Récompense: 845.23\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 663         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044926 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.9719106   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.396       |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 663         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005509884 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.97072726  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.693       |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00077    |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "Épisode 816/1000 terminé. Récompense: 1229.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 671          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 583          |\n",
      "|    total_timesteps      | 1247232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042431187 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.60734415   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.773        |\n",
      "|    n_updates            | 6080         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "Épisode 817/1000 terminé. Récompense: 1067.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 670          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 584          |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022497019 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.9671337    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.417        |\n",
      "|    n_updates            | 6090         |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 818/1000 terminé. Récompense: 1235.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 611          |\n",
      "|    time_elapsed         | 585          |\n",
      "|    total_timesteps      | 1251328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025079595 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.96607625   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.875        |\n",
      "|    n_updates            | 6100         |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "Épisode 819/1000 terminé. Récompense: 374.70\n",
      "Épisode 820/1000 terminé. Récompense: 570.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 612          |\n",
      "|    time_elapsed         | 586          |\n",
      "|    total_timesteps      | 1253376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033062343 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.9720362    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.53         |\n",
      "|    n_updates            | 6110         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 821/1000 terminé. Récompense: 475.55\n",
      "Épisode 822/1000 terminé. Récompense: 457.82\n",
      "Épisode 823/1000 terminé. Récompense: 182.04\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 587          |\n",
      "|    total_timesteps      | 1255424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051854434 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.9840144    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.562        |\n",
      "|    n_updates            | 6120         |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 614          |\n",
      "|    time_elapsed         | 587          |\n",
      "|    total_timesteps      | 1257472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025590856 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.99136907   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.4          |\n",
      "|    n_updates            | 6130         |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    value_loss           | 0.855        |\n",
      "------------------------------------------\n",
      "Épisode 824/1000 terminé. Récompense: 1043.33\n",
      "Épisode 825/1000 terminé. Récompense: 155.35\n",
      "Épisode 826/1000 terminé. Récompense: 526.07\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 676         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2138        |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004368498 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 0.47289646  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.628       |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 616          |\n",
      "|    time_elapsed         | 589          |\n",
      "|    total_timesteps      | 1261568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038947323 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.9896087    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.482        |\n",
      "|    n_updates            | 6150         |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "Épisode 827/1000 terminé. Récompense: 1289.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2138         |\n",
      "|    iterations           | 617          |\n",
      "|    time_elapsed         | 590          |\n",
      "|    total_timesteps      | 1263616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059645693 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.24753088   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.5          |\n",
      "|    n_updates            | 6160         |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "Épisode 828/1000 terminé. Récompense: 1005.18\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.53e+03   |\n",
      "|    ep_rew_mean          | 685        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2138       |\n",
      "|    iterations           | 618        |\n",
      "|    time_elapsed         | 591        |\n",
      "|    total_timesteps      | 1265664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00368861 |\n",
      "|    clip_fraction        | 0.0324     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.504     |\n",
      "|    explained_variance   | 0.97356266 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.532      |\n",
      "|    n_updates            | 6170       |\n",
      "|    policy_gradient_loss | -0.00414   |\n",
      "|    value_loss           | 1.22       |\n",
      "----------------------------------------\n",
      "Épisode 829/1000 terminé. Récompense: 814.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 592          |\n",
      "|    total_timesteps      | 1267712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028299405 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.9709513    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.347        |\n",
      "|    n_updates            | 6180         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "Épisode 830/1000 terminé. Récompense: 785.14\n",
      "Épisode 831/1000 terminé. Récompense: 275.64\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 620          |\n",
      "|    time_elapsed         | 593          |\n",
      "|    total_timesteps      | 1269760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031092912 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.97157776   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.567        |\n",
      "|    n_updates            | 6190         |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "Épisode 832/1000 terminé. Récompense: 1213.14\n",
      "Épisode 833/1000 terminé. Récompense: 112.24\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 679         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004791754 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.98464286  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.609       |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "Épisode 834/1000 terminé. Récompense: 578.77\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 674         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003182335 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.98606867  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.442       |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "Épisode 835/1000 terminé. Récompense: 1084.79\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 623          |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 1275904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023607663 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.9749088    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.586        |\n",
      "|    n_updates            | 6220         |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "Épisode 836/1000 terminé. Récompense: 986.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 597          |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024204552 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.9730821    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.641        |\n",
      "|    n_updates            | 6230         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "Épisode 837/1000 terminé. Récompense: 499.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 625          |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033209822 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.97312504   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.485        |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 838/1000 terminé. Récompense: 656.32\n",
      "Épisode 839/1000 terminé. Récompense: 403.30\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 680         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002146055 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.97711444  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.527       |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "Épisode 840/1000 terminé. Récompense: 958.16\n",
      "Épisode 841/1000 terminé. Récompense: 95.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 675          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 600          |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021479959 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.9821677    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.64         |\n",
      "|    n_updates            | 6260         |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "Épisode 842/1000 terminé. Récompense: 716.57\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 676          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 628          |\n",
      "|    time_elapsed         | 601          |\n",
      "|    total_timesteps      | 1286144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025691418 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.9851064    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.686        |\n",
      "|    n_updates            | 6270         |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "Épisode 843/1000 terminé. Récompense: 536.67\n",
      "Épisode 844/1000 terminé. Récompense: 163.30\n",
      "Épisode 845/1000 terminé. Récompense: 101.80\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 1288192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028371545 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.97842073   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.471        |\n",
      "|    n_updates            | 6280         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "Épisode 846/1000 terminé. Récompense: 952.35\n",
      "Épisode 847/1000 terminé. Récompense: 337.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 630          |\n",
      "|    time_elapsed         | 603          |\n",
      "|    total_timesteps      | 1290240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027787238 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.9888083    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.653        |\n",
      "|    n_updates            | 6290         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "Épisode 848/1000 terminé. Récompense: 586.71\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 659         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002332702 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.403      |\n",
      "|    explained_variance   | 0.9860603   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.423       |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "Épisode 849/1000 terminé. Récompense: 1220.29\n",
      "Épisode 850/1000 terminé. Récompense: 152.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 661          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 604          |\n",
      "|    total_timesteps      | 1294336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026132287 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.9763056    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.569        |\n",
      "|    n_updates            | 6310         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 661         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003938252 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.435      |\n",
      "|    explained_variance   | 0.9849896   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.71        |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.000432   |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "Épisode 851/1000 terminé. Récompense: 1103.62\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 671         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004071739 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.434      |\n",
      "|    explained_variance   | 0.87321174  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.722       |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "Épisode 852/1000 terminé. Récompense: 938.96\n",
      "Épisode 853/1000 terminé. Récompense: 604.88\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 635          |\n",
      "|    time_elapsed         | 607          |\n",
      "|    total_timesteps      | 1300480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028111357 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.9619648    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.465        |\n",
      "|    n_updates            | 6340         |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "Épisode 854/1000 terminé. Récompense: 782.23\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.51e+03   |\n",
      "|    ep_rew_mean          | 675        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2139       |\n",
      "|    iterations           | 636        |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 1302528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00207364 |\n",
      "|    clip_fraction        | 0.0209     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.462     |\n",
      "|    explained_variance   | 0.98042154 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.614      |\n",
      "|    n_updates            | 6350       |\n",
      "|    policy_gradient_loss | -0.00175   |\n",
      "|    value_loss           | 1.52       |\n",
      "----------------------------------------\n",
      "Épisode 855/1000 terminé. Récompense: 889.11\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 609          |\n",
      "|    total_timesteps      | 1304576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030469447 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.96672636   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.677        |\n",
      "|    n_updates            | 6360         |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "Épisode 856/1000 terminé. Récompense: 569.92\n",
      "Épisode 857/1000 terminé. Récompense: 140.24\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 683         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002977951 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.438      |\n",
      "|    explained_variance   | 0.9713761   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.483       |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Épisode 858/1000 terminé. Récompense: 1244.48\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 639          |\n",
      "|    time_elapsed         | 611          |\n",
      "|    total_timesteps      | 1308672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019551718 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.985873     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.426        |\n",
      "|    n_updates            | 6380         |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "Épisode 859/1000 terminé. Récompense: 982.59\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 640          |\n",
      "|    time_elapsed         | 612          |\n",
      "|    total_timesteps      | 1310720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027586399 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.9719252    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.522        |\n",
      "|    n_updates            | 6390         |\n",
      "|    policy_gradient_loss | -0.000503    |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Épisode 860/1000 terminé. Récompense: 1078.59\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 689          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 641          |\n",
      "|    time_elapsed         | 613          |\n",
      "|    total_timesteps      | 1312768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035369084 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.97198737   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.562        |\n",
      "|    n_updates            | 6400         |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 861/1000 terminé. Récompense: 817.51\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 642          |\n",
      "|    time_elapsed         | 614          |\n",
      "|    total_timesteps      | 1314816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021680433 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.97327876   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.769        |\n",
      "|    n_updates            | 6410         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "Épisode 862/1000 terminé. Récompense: 820.39\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 693         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003942618 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.9720412   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.676       |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 693          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 644          |\n",
      "|    time_elapsed         | 616          |\n",
      "|    total_timesteps      | 1318912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031892671 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.97525746   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.513        |\n",
      "|    n_updates            | 6430         |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "Épisode 863/1000 terminé. Récompense: 1329.02\n",
      "Épisode 864/1000 terminé. Récompense: 179.27\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 693         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008453619 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.494      |\n",
      "|    explained_variance   | 0.3396278   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.57        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "Épisode 865/1000 terminé. Récompense: 962.63\n",
      "Épisode 866/1000 terminé. Récompense: 184.77\n",
      "Épisode 867/1000 terminé. Récompense: 307.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 681          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 646          |\n",
      "|    time_elapsed         | 618          |\n",
      "|    total_timesteps      | 1323008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026334943 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.9840598    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.47         |\n",
      "|    n_updates            | 6450         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "Épisode 868/1000 terminé. Récompense: 95.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 682          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 647          |\n",
      "|    time_elapsed         | 619          |\n",
      "|    total_timesteps      | 1325056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033434464 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.9912511    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.286        |\n",
      "|    n_updates            | 6460         |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 0.861        |\n",
      "------------------------------------------\n",
      "Épisode 869/1000 terminé. Récompense: 1096.08\n",
      "Épisode 870/1000 terminé. Récompense: 188.50\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 648          |\n",
      "|    time_elapsed         | 620          |\n",
      "|    total_timesteps      | 1327104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030822633 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.96239537   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.726        |\n",
      "|    n_updates            | 6470         |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 871/1000 terminé. Récompense: 1030.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 649          |\n",
      "|    time_elapsed         | 621          |\n",
      "|    total_timesteps      | 1329152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019555353 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.9870562    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.4          |\n",
      "|    n_updates            | 6480         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "Épisode 872/1000 terminé. Récompense: 448.61\n",
      "Épisode 873/1000 terminé. Récompense: 114.46\n",
      "Épisode 874/1000 terminé. Récompense: 759.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 650          |\n",
      "|    time_elapsed         | 621          |\n",
      "|    total_timesteps      | 1331200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018513452 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.9770655    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.433        |\n",
      "|    n_updates            | 6490         |\n",
      "|    policy_gradient_loss | -0.000655    |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 622          |\n",
      "|    total_timesteps      | 1333248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022567124 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.9904699    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.593        |\n",
      "|    n_updates            | 6500         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "Épisode 875/1000 terminé. Récompense: 1051.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 652          |\n",
      "|    time_elapsed         | 623          |\n",
      "|    total_timesteps      | 1335296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038119808 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.38833433   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.497        |\n",
      "|    n_updates            | 6510         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "Épisode 876/1000 terminé. Récompense: 1273.82\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 653          |\n",
      "|    time_elapsed         | 624          |\n",
      "|    total_timesteps      | 1337344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028475537 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.9708998    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.548        |\n",
      "|    n_updates            | 6520         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "Épisode 877/1000 terminé. Récompense: 558.54\n",
      "Épisode 878/1000 terminé. Récompense: 205.52\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 654          |\n",
      "|    time_elapsed         | 625          |\n",
      "|    total_timesteps      | 1339392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016545899 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.97606426   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.435        |\n",
      "|    n_updates            | 6530         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "Épisode 879/1000 terminé. Récompense: 649.71\n",
      "Épisode 880/1000 terminé. Récompense: 365.06\n",
      "Épisode 881/1000 terminé. Récompense: 105.67\n",
      "Épisode 882/1000 terminé. Récompense: 357.83\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 655          |\n",
      "|    time_elapsed         | 626          |\n",
      "|    total_timesteps      | 1341440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032916039 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.9870429    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 6540         |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "Épisode 883/1000 terminé. Récompense: 191.61\n",
      "Épisode 884/1000 terminé. Récompense: 207.15\n",
      "Épisode 885/1000 terminé. Récompense: 304.15\n",
      "Épisode 886/1000 terminé. Récompense: 161.58\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 661          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 656          |\n",
      "|    time_elapsed         | 627          |\n",
      "|    total_timesteps      | 1343488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039418396 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.9949332    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.288        |\n",
      "|    n_updates            | 6550         |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 0.655        |\n",
      "------------------------------------------\n",
      "Épisode 887/1000 terminé. Récompense: 712.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 657          |\n",
      "|    time_elapsed         | 628          |\n",
      "|    total_timesteps      | 1345536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036070654 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.9945824    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.343        |\n",
      "|    n_updates            | 6560         |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    value_loss           | 0.668        |\n",
      "------------------------------------------\n",
      "Épisode 888/1000 terminé. Récompense: 698.74\n",
      "Épisode 889/1000 terminé. Récompense: 449.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 660          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 629          |\n",
      "|    total_timesteps      | 1347584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040604323 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.96858174   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 6570         |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 1.34         |\n",
      "------------------------------------------\n",
      "Épisode 890/1000 terminé. Récompense: 803.21\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 657         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2140        |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002656371 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.421      |\n",
      "|    explained_variance   | 0.9868235   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.376       |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "Épisode 891/1000 terminé. Récompense: 1070.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 660          |\n",
      "|    time_elapsed         | 631          |\n",
      "|    total_timesteps      | 1351680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065829027 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.973294     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.309        |\n",
      "|    n_updates            | 6590         |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "Épisode 892/1000 terminé. Récompense: 561.34\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 657         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2140        |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002348091 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.395      |\n",
      "|    explained_variance   | 0.97346485  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.483       |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Épisode 893/1000 terminé. Récompense: 1184.10\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 662          |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 1355776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029449014 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.9761134    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.485        |\n",
      "|    n_updates            | 6610         |\n",
      "|    policy_gradient_loss | -0.000838    |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "Épisode 894/1000 terminé. Récompense: 805.18\n",
      "Épisode 895/1000 terminé. Récompense: 119.37\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 659          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 634          |\n",
      "|    total_timesteps      | 1357824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027441361 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.9739502    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.738        |\n",
      "|    n_updates            | 6620         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "Épisode 896/1000 terminé. Récompense: 850.97\n",
      "Épisode 897/1000 terminé. Récompense: 140.90\n",
      "Épisode 898/1000 terminé. Récompense: 8.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 649          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 635          |\n",
      "|    total_timesteps      | 1359872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028158934 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.98557246   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.54         |\n",
      "|    n_updates            | 6630         |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "Épisode 899/1000 terminé. Récompense: 862.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 651          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 665          |\n",
      "|    time_elapsed         | 636          |\n",
      "|    total_timesteps      | 1361920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027952516 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.9893836    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.467        |\n",
      "|    n_updates            | 6640         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 651          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 666          |\n",
      "|    time_elapsed         | 637          |\n",
      "|    total_timesteps      | 1363968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022185596 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.9761111    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.479        |\n",
      "|    n_updates            | 6650         |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "Épisode 900/1000 terminé. Récompense: 1318.35\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 660          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 667          |\n",
      "|    time_elapsed         | 638          |\n",
      "|    total_timesteps      | 1366016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031681713 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.3183244    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.581        |\n",
      "|    n_updates            | 6660         |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "Épisode 901/1000 terminé. Récompense: 741.16\n",
      "Épisode 902/1000 terminé. Récompense: 94.19\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 645          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 668          |\n",
      "|    time_elapsed         | 639          |\n",
      "|    total_timesteps      | 1368064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035306131 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.9789791    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.402        |\n",
      "|    n_updates            | 6670         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "Épisode 903/1000 terminé. Récompense: 1380.56\n",
      "Épisode 904/1000 terminé. Récompense: 89.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 669          |\n",
      "|    time_elapsed         | 639          |\n",
      "|    total_timesteps      | 1370112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025156704 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.9881675    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.634        |\n",
      "|    n_updates            | 6680         |\n",
      "|    policy_gradient_loss | -0.00097     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "Épisode 905/1000 terminé. Récompense: 379.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 650          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 640          |\n",
      "|    total_timesteps      | 1372160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037130327 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.98974764   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.264        |\n",
      "|    n_updates            | 6690         |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    value_loss           | 0.823        |\n",
      "------------------------------------------\n",
      "Épisode 906/1000 terminé. Récompense: 1226.30\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 655         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2140        |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005687488 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.537      |\n",
      "|    explained_variance   | 0.9727504   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.525       |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "Épisode 907/1000 terminé. Récompense: 1349.74\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 656         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2140        |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004453442 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.9818261   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.532       |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 656         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 643         |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004504039 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.9723372   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "Épisode 908/1000 terminé. Récompense: 1027.98\n",
      "Épisode 909/1000 terminé. Récompense: 755.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 650          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 674          |\n",
      "|    time_elapsed         | 644          |\n",
      "|    total_timesteps      | 1380352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033516476 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.74377596   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.879        |\n",
      "|    n_updates            | 6730         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "Épisode 910/1000 terminé. Récompense: 786.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | 656          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 645          |\n",
      "|    total_timesteps      | 1382400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024539675 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.98349357   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.855        |\n",
      "|    n_updates            | 6740         |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Épisode 911/1000 terminé. Récompense: 546.96\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 657         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003871033 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.97120726  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.473       |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "Épisode 912/1000 terminé. Récompense: 1272.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 662          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 677          |\n",
      "|    time_elapsed         | 647          |\n",
      "|    total_timesteps      | 1386496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031005046 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.97460526   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.504        |\n",
      "|    n_updates            | 6760         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "Épisode 913/1000 terminé. Récompense: 514.38\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 664         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002287222 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | 0.97095186  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.452       |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "Épisode 914/1000 terminé. Récompense: 917.96\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 665          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 679          |\n",
      "|    time_elapsed         | 649          |\n",
      "|    total_timesteps      | 1390592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040505757 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.9703734    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.538        |\n",
      "|    n_updates            | 6780         |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "Épisode 915/1000 terminé. Récompense: 1053.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 650          |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058207237 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.972358     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.532        |\n",
      "|    n_updates            | 6790         |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 916/1000 terminé. Récompense: 933.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 681          |\n",
      "|    time_elapsed         | 651          |\n",
      "|    total_timesteps      | 1394688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036624824 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.9703929    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.677        |\n",
      "|    n_updates            | 6800         |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 917/1000 terminé. Récompense: 805.20\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 661         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003471743 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.9685595   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.76        |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "Épisode 918/1000 terminé. Récompense: 881.37\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 658         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002714374 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.9720838   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.764       |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "Épisode 919/1000 terminé. Récompense: 1005.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | 664          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 684          |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 1400832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034446523 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.9717715    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.653        |\n",
      "|    n_updates            | 6830         |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "Épisode 920/1000 terminé. Récompense: 1243.75\n",
      "Épisode 921/1000 terminé. Récompense: 102.21\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 667         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002721576 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.464      |\n",
      "|    explained_variance   | 0.9720235   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.786       |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 667         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001849587 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.98545283  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.434       |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Épisode 922/1000 terminé. Récompense: 1159.70\n",
      "Épisode 923/1000 terminé. Récompense: 551.00\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 687          |\n",
      "|    time_elapsed         | 657          |\n",
      "|    total_timesteps      | 1406976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052951835 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.2770338    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.546        |\n",
      "|    n_updates            | 6860         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 688          |\n",
      "|    time_elapsed         | 657          |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023705168 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.9857713    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.435        |\n",
      "|    n_updates            | 6870         |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 924/1000 terminé. Récompense: 1141.68\n",
      "Épisode 925/1000 terminé. Récompense: 806.18\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 685         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003061133 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.47083622  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.607       |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 659          |\n",
      "|    total_timesteps      | 1413120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012585679 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.9857559    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.427        |\n",
      "|    n_updates            | 6890         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "Épisode 926/1000 terminé. Récompense: 1096.12\n",
      "Épisode 927/1000 terminé. Récompense: 134.92\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 691          |\n",
      "|    time_elapsed         | 660          |\n",
      "|    total_timesteps      | 1415168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034894606 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.29549223   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.49         |\n",
      "|    n_updates            | 6900         |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "Épisode 928/1000 terminé. Récompense: 1018.09\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 679          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 661          |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027509585 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.97776556   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.584        |\n",
      "|    n_updates            | 6910         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "Épisode 929/1000 terminé. Récompense: 1389.64\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 693          |\n",
      "|    time_elapsed         | 662          |\n",
      "|    total_timesteps      | 1419264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021146315 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.98055786   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.511        |\n",
      "|    n_updates            | 6920         |\n",
      "|    policy_gradient_loss | -0.000894    |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 930/1000 terminé. Récompense: 637.15\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 694          |\n",
      "|    time_elapsed         | 663          |\n",
      "|    total_timesteps      | 1421312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038481373 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.96636546   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.412        |\n",
      "|    n_updates            | 6930         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Épisode 931/1000 terminé. Récompense: 1118.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 664          |\n",
      "|    total_timesteps      | 1423360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028228704 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.97344726   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.49         |\n",
      "|    n_updates            | 6940         |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "Épisode 932/1000 terminé. Récompense: 199.09\n",
      "Épisode 933/1000 terminé. Récompense: 570.95\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 686         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002046479 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.9780462   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.494       |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "Épisode 934/1000 terminé. Récompense: 1086.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 697          |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 1427456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025106855 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.98378634   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.299        |\n",
      "|    n_updates            | 6960         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "Épisode 935/1000 terminé. Récompense: 459.18\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 685         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003073506 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.9695657   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.63        |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "Épisode 936/1000 terminé. Récompense: 1185.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 687          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 699          |\n",
      "|    time_elapsed         | 668          |\n",
      "|    total_timesteps      | 1431552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029772536 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.9755559    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.443        |\n",
      "|    n_updates            | 6980         |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "Épisode 937/1000 terminé. Récompense: 701.07\n",
      "Épisode 938/1000 terminé. Récompense: 507.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 700          |\n",
      "|    time_elapsed         | 669          |\n",
      "|    total_timesteps      | 1433600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065639312 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.97287387   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.521        |\n",
      "|    n_updates            | 6990         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 939/1000 terminé. Récompense: 692.72\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | 691        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2142       |\n",
      "|    iterations           | 701        |\n",
      "|    time_elapsed         | 670        |\n",
      "|    total_timesteps      | 1435648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00312907 |\n",
      "|    clip_fraction        | 0.0324     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.476     |\n",
      "|    explained_variance   | 0.9865179  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.529      |\n",
      "|    n_updates            | 7000       |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    value_loss           | 0.989      |\n",
      "----------------------------------------\n",
      "Épisode 940/1000 terminé. Récompense: 978.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 691          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 702          |\n",
      "|    time_elapsed         | 671          |\n",
      "|    total_timesteps      | 1437696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027208002 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.9711479    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.655        |\n",
      "|    n_updates            | 7010         |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "Épisode 941/1000 terminé. Récompense: 730.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 672          |\n",
      "|    total_timesteps      | 1439744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029962116 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.96862847   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.851        |\n",
      "|    n_updates            | 7020         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "Épisode 942/1000 terminé. Récompense: 385.58\n",
      "Épisode 943/1000 terminé. Récompense: 105.07\n",
      "Épisode 944/1000 terminé. Récompense: 706.52\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 695          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 704          |\n",
      "|    time_elapsed         | 673          |\n",
      "|    total_timesteps      | 1441792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029864185 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.9814191    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.571        |\n",
      "|    n_updates            | 7030         |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "Épisode 945/1000 terminé. Récompense: 220.78\n",
      "Épisode 946/1000 terminé. Récompense: 520.27\n",
      "Épisode 947/1000 terminé. Récompense: 264.46\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 691          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 673          |\n",
      "|    total_timesteps      | 1443840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028183428 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.9885128    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.463        |\n",
      "|    n_updates            | 7040         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Épisode 948/1000 terminé. Récompense: 806.80\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 693         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003321243 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.435      |\n",
      "|    explained_variance   | 0.9916603   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.431       |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    value_loss           | 0.89        |\n",
      "-----------------------------------------\n",
      "Épisode 949/1000 terminé. Récompense: 1029.66\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 692         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003051549 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.426      |\n",
      "|    explained_variance   | 0.9726453   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.705       |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "Épisode 950/1000 terminé. Récompense: 582.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 696          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 708          |\n",
      "|    time_elapsed         | 676          |\n",
      "|    total_timesteps      | 1449984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038727007 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.9718793    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.722        |\n",
      "|    n_updates            | 7070         |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "Épisode 951/1000 terminé. Récompense: 741.30\n",
      "Épisode 952/1000 terminé. Récompense: 101.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 709          |\n",
      "|    time_elapsed         | 677          |\n",
      "|    total_timesteps      | 1452032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044425563 |\n",
      "|    clip_fraction        | 0.0591       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.96985555   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.556        |\n",
      "|    n_updates            | 7080         |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "Épisode 953/1000 terminé. Récompense: 1039.90\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 688          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 710          |\n",
      "|    time_elapsed         | 678          |\n",
      "|    total_timesteps      | 1454080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029272642 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.98768955   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.555        |\n",
      "|    n_updates            | 7090         |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "Épisode 954/1000 terminé. Récompense: 473.52\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 711          |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 1456128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030607767 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.9718151    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.615        |\n",
      "|    n_updates            | 7100         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "Épisode 955/1000 terminé. Récompense: 1367.15\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 690          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 680          |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025819931 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.9771504    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.557        |\n",
      "|    n_updates            | 7110         |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "Épisode 956/1000 terminé. Récompense: 977.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 713          |\n",
      "|    time_elapsed         | 681          |\n",
      "|    total_timesteps      | 1460224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034092758 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.97357744   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.371        |\n",
      "|    n_updates            | 7120         |\n",
      "|    policy_gradient_loss | 0.000122     |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "Épisode 957/1000 terminé. Récompense: 947.43\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 702         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003187179 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.9727815   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.447       |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "Épisode 958/1000 terminé. Récompense: 543.46\n",
      "Épisode 959/1000 terminé. Récompense: 148.92\n",
      "Épisode 960/1000 terminé. Récompense: 218.51\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 678          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 683          |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030436744 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.9731883    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.52         |\n",
      "|    n_updates            | 7140         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "Épisode 961/1000 terminé. Récompense: 607.57\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.51e+03   |\n",
      "|    ep_rew_mean          | 676        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2142       |\n",
      "|    iterations           | 716        |\n",
      "|    time_elapsed         | 684        |\n",
      "|    total_timesteps      | 1466368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00398455 |\n",
      "|    clip_fraction        | 0.0345     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.475     |\n",
      "|    explained_variance   | 0.9903567  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.506      |\n",
      "|    n_updates            | 7150       |\n",
      "|    policy_gradient_loss | -0.00676   |\n",
      "|    value_loss           | 0.985      |\n",
      "----------------------------------------\n",
      "Épisode 962/1000 terminé. Récompense: 1389.80\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 682         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002711696 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.98144096  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.488       |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "Épisode 963/1000 terminé. Récompense: 584.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 674          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 718          |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 1470464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027165264 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.970901     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.505        |\n",
      "|    n_updates            | 7170         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "Épisode 964/1000 terminé. Récompense: 866.47\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 681         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003656799 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.9755104   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.449       |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "Épisode 965/1000 terminé. Récompense: 1353.60\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 688          |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030598566 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.98162735   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.589        |\n",
      "|    n_updates            | 7190         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 685         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 689         |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002931415 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.474      |\n",
      "|    explained_variance   | 0.97366226  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.477       |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "Épisode 966/1000 terminé. Récompense: 1040.55\n",
      "Épisode 967/1000 terminé. Récompense: 15.39\n",
      "Épisode 968/1000 terminé. Récompense: 481.56\n",
      "Épisode 969/1000 terminé. Récompense: 330.42\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 687         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047525 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.9306489   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.51        |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "Épisode 970/1000 terminé. Récompense: 249.34\n",
      "Épisode 971/1000 terminé. Récompense: 608.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 683          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 723          |\n",
      "|    time_elapsed         | 691          |\n",
      "|    total_timesteps      | 1480704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026981959 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.9919636    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.366        |\n",
      "|    n_updates            | 7220         |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 0.858        |\n",
      "------------------------------------------\n",
      "Épisode 972/1000 terminé. Récompense: 717.22\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 724          |\n",
      "|    time_elapsed         | 691          |\n",
      "|    total_timesteps      | 1482752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028798943 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.9844759    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.667        |\n",
      "|    n_updates            | 7230         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "Épisode 973/1000 terminé. Récompense: 951.11\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 694          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 692          |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026554863 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.97281975   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.554        |\n",
      "|    n_updates            | 7240         |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "Épisode 974/1000 terminé. Récompense: 1119.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | 698          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2142         |\n",
      "|    iterations           | 726          |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 1486848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018213481 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.97346246   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.326        |\n",
      "|    n_updates            | 7250         |\n",
      "|    policy_gradient_loss | 0.000875     |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "Épisode 975/1000 terminé. Récompense: 857.14\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 696         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 694         |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002998583 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.9719774   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.585       |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 696         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004352673 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.96894574  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.588       |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "Épisode 976/1000 terminé. Récompense: 1215.84\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 695         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2142        |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010243112 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.32446915  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.637       |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | 0.000982    |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "Épisode 977/1000 terminé. Récompense: 1339.32\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 703          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 730          |\n",
      "|    time_elapsed         | 698          |\n",
      "|    total_timesteps      | 1495040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029780997 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.9752714    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.551        |\n",
      "|    n_updates            | 7290         |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 1.55         |\n",
      "------------------------------------------\n",
      "Épisode 978/1000 terminé. Récompense: 915.04\n",
      "Épisode 979/1000 terminé. Récompense: 182.30\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | 706          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 731          |\n",
      "|    time_elapsed         | 699          |\n",
      "|    total_timesteps      | 1497088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030241278 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.9735647    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.394        |\n",
      "|    n_updates            | 7300         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "Épisode 980/1000 terminé. Récompense: 385.24\n",
      "Épisode 981/1000 terminé. Récompense: 522.74\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 710          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2141         |\n",
      "|    iterations           | 732          |\n",
      "|    time_elapsed         | 699          |\n",
      "|    total_timesteps      | 1499136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020725843 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.9874776    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.27         |\n",
      "|    n_updates            | 7310         |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    value_loss           | 0.906        |\n",
      "------------------------------------------\n",
      "Épisode 982/1000 terminé. Récompense: 264.88\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 709          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2140         |\n",
      "|    iterations           | 733          |\n",
      "|    time_elapsed         | 701          |\n",
      "|    total_timesteps      | 1501184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026883301 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.9879238    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.387        |\n",
      "|    n_updates            | 7320         |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    value_loss           | 0.905        |\n",
      "------------------------------------------\n",
      "Épisode 983/1000 terminé. Récompense: 1283.92\n",
      "Épisode 984/1000 terminé. Récompense: 39.57\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 718          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 1503232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030440227 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.97134984   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.622        |\n",
      "|    n_updates            | 7330         |\n",
      "|    policy_gradient_loss | -0.000763    |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "Épisode 985/1000 terminé. Récompense: 578.41\n",
      "Épisode 986/1000 terminé. Récompense: 38.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 720          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 735          |\n",
      "|    time_elapsed         | 703          |\n",
      "|    total_timesteps      | 1505280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029667807 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.985841     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.41         |\n",
      "|    n_updates            | 7340         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "Épisode 987/1000 terminé. Récompense: 1156.78\n",
      "Épisode 988/1000 terminé. Récompense: 9.26\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 717          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 736          |\n",
      "|    time_elapsed         | 704          |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041650664 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.9839859    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.604        |\n",
      "|    n_updates            | 7350         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "Épisode 989/1000 terminé. Récompense: 1028.53\n",
      "Épisode 990/1000 terminé. Récompense: 41.90\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 716          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 705          |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035982267 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.9828563    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.424        |\n",
      "|    n_updates            | 7360         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "Épisode 991/1000 terminé. Récompense: 856.27\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 713          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 738          |\n",
      "|    time_elapsed         | 706          |\n",
      "|    total_timesteps      | 1511424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033356887 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.9851911    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.421        |\n",
      "|    n_updates            | 7370         |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "Épisode 992/1000 terminé. Récompense: 877.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 717          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 707          |\n",
      "|    total_timesteps      | 1513472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022473475 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.96954733   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.673        |\n",
      "|    n_updates            | 7380         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "Épisode 993/1000 terminé. Récompense: 384.12\n",
      "Épisode 994/1000 terminé. Récompense: 671.76\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 707          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 708          |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033370713 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.98406065   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.328        |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 0.804        |\n",
      "------------------------------------------\n",
      "Épisode 995/1000 terminé. Récompense: 785.08\n",
      "Épisode 996/1000 terminé. Récompense: 204.66\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | 707          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 741          |\n",
      "|    time_elapsed         | 709          |\n",
      "|    total_timesteps      | 1517568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054187365 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.98147863   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.569        |\n",
      "|    n_updates            | 7400         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "Épisode 997/1000 terminé. Récompense: 406.89\n",
      "Épisode 998/1000 terminé. Récompense: 598.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 716         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2139        |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002215643 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.987705    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.379       |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    value_loss           | 0.915       |\n",
      "-----------------------------------------\n",
      "Épisode 999/1000 terminé. Récompense: 983.81\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 717          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 743          |\n",
      "|    time_elapsed         | 711          |\n",
      "|    total_timesteps      | 1521664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065855393 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.98927814   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.271        |\n",
      "|    n_updates            | 7420         |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    value_loss           | 0.813        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | 717          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2139         |\n",
      "|    iterations           | 744          |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 1523712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060368115 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.97281885   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.474        |\n",
      "|    n_updates            | 7430         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "Épisode 1000/1000 terminé. Récompense: 1007.16\n",
      "\n",
      "1000 épisodes complétés!\n",
      "\n",
      "Entraînement terminé!\n",
      "Nombre total d'épisodes: 1000\n",
      "Récompense moyenne: 659.17\n",
      "Récompense max: 1401.15\n",
      "Récompense min: -146.38\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test de l'agent ---\n",
      "État 0 → Action choisie: 0\n",
      "État 1 → Action choisie: 3\n",
      "État 2 → Action choisie: 3\n",
      "État 3 → Action choisie: 0\n",
      "État 4 → Action choisie: 3\n",
      "État 5 → Action choisie: 3\n",
      "État 6 → Action choisie: 3\n",
      "État 7 → Action choisie: 0\n",
      "État 8 → Action choisie: 0\n",
      "État 9 → Action choisie: 3\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Chargement et préparation des données ======\n",
    "df = pd.read_csv(\"tomato irrigation dataset.csv\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = [\"Temperature [C]\", \"Humidity [%]\", \"Soil moisture\",\n",
    "            \"Reference evapotranspiration\", \"Evapotranspiration\",\n",
    "            \"Crop Coefficient\",\n",
    "            \"Nitrogen [mg/kg]\", \"Phosphorus [mg/kg]\", \"Potassium\",\n",
    "            \"Solar Radiation ghi\", \"Wind Speed\", \"Days of planted\"]\n",
    "df_norm = scaler.fit_transform(df[features])\n",
    "states = df_norm\n",
    "\n",
    "# ====== Classe d'environnement ======\n",
    "class TomatoIrrigationEnv(gym.Env):\n",
    "    def __init__(self, states):\n",
    "        super(TomatoIrrigationEnv, self).__init__()\n",
    "        self.states = states\n",
    "        self.n_samples = len(states)\n",
    "        self.index = 0\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, \n",
    "                                           shape=(states.shape[1],), \n",
    "                                           dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "    \n",
    "    def compute_reward(self, soil_moisture, action):\n",
    "        irrigation_amount = action / 3\n",
    "        water_cost = 0.4 * irrigation_amount\n",
    "        \n",
    "        if soil_moisture < 0.5:\n",
    "            reward = (soil_moisture + irrigation_amount) - water_cost\n",
    "        elif soil_moisture > 0.65:\n",
    "            reward = -(irrigation_amount * 2) - water_cost\n",
    "        else:\n",
    "            reward = 0.45 - water_cost - abs(soil_moisture - 0.57)\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.index = np.random.randint(0, self.n_samples)\n",
    "        return self.states[self.index], {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        state = self.states[self.index]\n",
    "        soil_moisture = state[2]\n",
    "        reward = self.compute_reward(soil_moisture, action)\n",
    "        \n",
    "        self.index += 1\n",
    "        terminated = self.index >= self.n_samples\n",
    "        truncated = False\n",
    "        next_state = self.states[self.index % self.n_samples]\n",
    "        \n",
    "        return next_state, reward, terminated, truncated, {}\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        pass\n",
    "\n",
    "# ====== Callback pour suivre les épisodes ======\n",
    "class EpisodeCounterCallback(BaseCallback):\n",
    "    def __init__(self, n_episodes, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.n_episodes = n_episodes\n",
    "        self.episode_count = 0\n",
    "        self.episode_rewards = []\n",
    "        self.current_episode_reward = 0\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        self.current_episode_reward += self.locals['rewards'][0]\n",
    "        \n",
    "        if self.locals['dones'][0]:\n",
    "            self.episode_count += 1\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.current_episode_reward = 0\n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                print(f\"Épisode {self.episode_count}/{self.n_episodes} terminé. \"\n",
    "                      f\"Récompense: {self.episode_rewards[-1]:.2f}\")\n",
    "            \n",
    "            # Arrêter l'entraînement si le nombre d'épisodes est atteint\n",
    "            if self.episode_count >= self.n_episodes:\n",
    "                print(f\"\\n{self.n_episodes} épisodes complétés!\")\n",
    "                return False  # Stop training\n",
    "        \n",
    "        return True  # Continue training\n",
    "\n",
    "# ====== Fonction d'entraînement avec nombre d'épisodes ======\n",
    "def train_ppo_with_episodes(env, n_episodes=100, ent_coef=0.01, verbose=1):\n",
    "    \"\"\"\n",
    "    Entraîne un agent PPO pour un nombre spécifique d'épisodes\n",
    "    \n",
    "    Args:\n",
    "        env: L'environnement gymnasium\n",
    "        n_episodes: Nombre d'épisodes d'entraînement\n",
    "        ent_coef: Coefficient d'entropie pour PPO\n",
    "        verbose: Niveau de verbosité\n",
    "    \n",
    "    Returns:\n",
    "        model: Le modèle entraîné\n",
    "        callback: Le callback contenant les statistiques\n",
    "    \"\"\"\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=verbose, ent_coef=ent_coef)\n",
    "    \n",
    "    # Créer le callback\n",
    "    episode_callback = EpisodeCounterCallback(n_episodes=n_episodes, verbose=1)\n",
    "    \n",
    "    # Estimer le nombre de timesteps nécessaires\n",
    "    # On utilise une grande valeur, le callback s'arrêtera au bon nombre d'épisodes\n",
    "    estimated_timesteps = n_episodes * env.n_samples * 2\n",
    "    \n",
    "    print(f\"Début de l'entraînement pour {n_episodes} épisodes...\")\n",
    "    model.learn(total_timesteps=estimated_timesteps, callback=episode_callback)\n",
    "    \n",
    "    return model, episode_callback\n",
    "\n",
    "# ====== Entraînement et visualisation ======\n",
    "if __name__ == \"__main__\":\n",
    "    env = TomatoIrrigationEnv(states)\n",
    "    \n",
    "    # PARAMÈTRES À AJUSTER\n",
    "    N_EPISODES = 1000  # Nombre d'épisodes souhaité\n",
    "    ENT_COEF = 0.1   # Coefficient d'entropie\n",
    "    \n",
    "    # Entraînement\n",
    "    model, callback = train_ppo_with_episodes(\n",
    "        env, \n",
    "        n_episodes=N_EPISODES, \n",
    "        ent_coef=ENT_COEF,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEntraînement terminé!\")\n",
    "    print(f\"Nombre total d'épisodes: {callback.episode_count}\")\n",
    "    print(f\"Récompense moyenne: {np.mean(callback.episode_rewards):.2f}\")\n",
    "    print(f\"Récompense max: {np.max(callback.episode_rewards):.2f}\")\n",
    "    print(f\"Récompense min: {np.min(callback.episode_rewards):.2f}\")\n",
    "    \n",
    "    # Visualisation des récompenses par épisode\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(callback.episode_rewards)\n",
    "    plt.xlabel('Épisode')\n",
    "    plt.ylabel('Récompense')\n",
    "    plt.title('Récompense par épisode')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    window = min(10, len(callback.episode_rewards))\n",
    "    if window > 1:\n",
    "        moving_avg = np.convolve(callback.episode_rewards, \n",
    "                                np.ones(window)/window, \n",
    "                                mode='valid')\n",
    "        plt.plot(moving_avg)\n",
    "        plt.xlabel('Épisode')\n",
    "        plt.ylabel('Récompense moyenne mobile')\n",
    "        plt.title(f'Moyenne mobile (fenêtre={window})')\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Test de l'agent entraîné\n",
    "    print(\"\\n--- Test de l'agent ---\")\n",
    "    obs, _ = env.reset()\n",
    "    for i in range(10):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        print(f\"État {i} → Action choisie: {action}\")\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        if terminated:\n",
    "            obs, _ = env.reset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb3_env (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
